import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import JSZip from "https://esm.sh/jszip@3.10.1";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// ============================================
// NCS V2.0 - "LA GRANDE MESSE DE LIB√âRATION"
// ============================================

// PHASE 1: SOVEREIGNTY MANIFEST (SHA-256 SIGNED)
interface SovereigntyManifest {
  version: string;
  projectName: string;
  generatedAt: string;
  certification: {
    openSourceCompliance: boolean;
    portableCompliance: boolean;
    coolifyCompliance: boolean;
    bigTechDependency: number;
  };
  audit: {
    score: number;
    criticalIssues: number;
    warnings: number;
    owaspScore: number;
    securityScore: number;
  };
  statistics: {
    filesCount: number;
    linesOfCode: number;
    testsGenerated: number;
    routesConverted: number;
  };
  signature: string;
  signedAt: string;
}

async function generateSovereigntyManifest(
  projectName: string,
  audit: { score: number; criticalIssues: string[]; warnings: string[]; isClean: boolean },
  files: Record<string, string>,
  owaspScore: number = 100,
  testsGenerated: number = 0,
  routesConverted: number = 0
): Promise<SovereigntyManifest> {
  const manifest: SovereigntyManifest = {
    version: '2.0',
    projectName,
    generatedAt: new Date().toISOString(),
    certification: {
      openSourceCompliance: audit.score >= 90,
      portableCompliance: audit.isClean,
      coolifyCompliance: audit.score >= 70,
      bigTechDependency: audit.criticalIssues.length,
    },
    audit: {
      score: audit.score,
      criticalIssues: audit.criticalIssues.length,
      warnings: audit.warnings.length,
      owaspScore,
      securityScore: Math.max(0, 100 - audit.criticalIssues.length * 10),
    },
    statistics: {
      filesCount: Object.keys(files).length,
      linesOfCode: Object.values(files).reduce((sum, content) => sum + content.split('\n').length, 0),
      testsGenerated,
      routesConverted,
    },
    signature: '',
    signedAt: '',
  };

  const manifestData = JSON.stringify({ ...manifest, signature: undefined, signedAt: undefined });
  const encoder = new TextEncoder();
  const data = encoder.encode(manifestData);
  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  manifest.signature = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  manifest.signedAt = new Date().toISOString();

  return manifest;
}

function generateSovereigntyBadge(score: number, projectName: string): string {
  const getColor = () => {
    if (score >= 90) return { bg: '#22c55e', text: 'SOUVERAIN' };
    if (score >= 70) return { bg: '#eab308', text: 'EN COURS' };
    return { bg: '#ef4444', text: '√Ä PURIFIER' };
  };
  const { bg, text } = getColor();
  
  return `<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" width="240" height="48" viewBox="0 0 240 48">
  <defs>
    <linearGradient id="grad" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:${bg};stop-opacity:1" />
      <stop offset="100%" style="stop-color:${bg}dd;stop-opacity:1" />
    </linearGradient>
    <filter id="shadow"><feDropShadow dx="0" dy="2" stdDeviation="2" flood-opacity="0.3"/></filter>
  </defs>
  <rect width="240" height="48" rx="8" fill="url(#grad)" filter="url(#shadow)"/>
  <rect x="2" y="2" width="236" height="44" rx="6" fill="none" stroke="white" stroke-opacity="0.3" stroke-width="1"/>
  <text x="20" y="22" font-family="system-ui, -apple-system, sans-serif" font-size="11" fill="white" opacity="0.9">${text}</text>
  <text x="20" y="38" font-family="system-ui, -apple-system, sans-serif" font-size="16" font-weight="bold" fill="white">${score}% ‚Ä¢ ${projectName.slice(0, 15)}</text>
  <circle cx="210" cy="24" r="16" fill="white" fill-opacity="0.2"/>
  <text x="210" y="28" font-family="system-ui" font-size="12" font-weight="bold" fill="white" text-anchor="middle">NCS</text>
</svg>`;
}

// PHASE 2: MULTI-DEPLOYMENT CONFIGS
function generateFlyConfig(projectName: string, hasBackend: boolean, hasDatabase: boolean): string {
  const appName = projectName.toLowerCase().replace(/[^a-z0-9-]/g, '-').slice(0, 63);
  return `# Fly.io Configuration - Generated by InoPay NCS 2.0
app = "${appName}"
primary_region = "cdg"
kill_signal = "SIGINT"
kill_timeout = 5

[build]
  dockerfile = "Dockerfile"

[env]
  NODE_ENV = "production"
  PORT = "80"

[http_service]
  internal_port = 80
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 1

[[services]]
  protocol = "tcp"
  internal_port = 80
  [[services.ports]]
    port = 80
    handlers = ["http"]
  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]
${hasBackend ? `
[[services]]
  protocol = "tcp"
  internal_port = 3000
  [[services.ports]]
    port = 3000
    handlers = ["http"]
` : ''}${hasDatabase ? `
# PostgreSQL: fly postgres create && fly postgres attach
` : ''}
`;
}

function generateRenderConfig(projectName: string, hasBackend: boolean): string {
  const serviceName = projectName.toLowerCase().replace(/[^a-z0-9-]/g, '-');
  return `# Render Blueprint - Generated by InoPay NCS 2.0
services:
  - type: web
    name: ${serviceName}-frontend
    env: docker
    dockerfilePath: ./Dockerfile
    dockerContext: .
    healthCheckPath: /
    autoDeploy: false
    scaling:
      minInstances: 1
      maxInstances: 3
${hasBackend ? `
  - type: web
    name: ${serviceName}-api
    env: docker
    dockerfilePath: ./backend/Dockerfile
    dockerContext: ./backend
    healthCheckPath: /health
    autoDeploy: false
` : ''}
databases:
  - name: ${serviceName}-db
    plan: starter
    databaseName: ${serviceName.replace(/-/g, '_')}_db
`;
}

function generateRailwayConfig(): string {
  return JSON.stringify({
    "$schema": "https://railway.app/railway.schema.json",
    "build": { "builder": "DOCKERFILE", "dockerfilePath": "Dockerfile" },
    "deploy": { "restartPolicyType": "ON_FAILURE", "restartPolicyMaxRetries": 3, "healthcheckPath": "/" }
  }, null, 2);
}

function generateHelmChart(projectName: string): Record<string, string> {
  const chartName = projectName.toLowerCase().replace(/[^a-z0-9-]/g, '-');
  return {
    'Chart.yaml': `apiVersion: v2\nname: ${chartName}\ndescription: ${projectName} - Helm Chart by InoPay NCS 2.0\ntype: application\nversion: 1.0.0\nappVersion: "1.0.0"`,
    'values.yaml': `replicaCount: 2\nimage:\n  repository: ${chartName}\n  pullPolicy: IfNotPresent\n  tag: "latest"\nservice:\n  type: ClusterIP\n  port: 80\ningress:\n  enabled: true\n  className: nginx\n  hosts:\n    - host: ${chartName}.example.com\n      paths:\n        - path: /\n          pathType: Prefix\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\nautoscaling:\n  enabled: true\n  minReplicas: 2\n  maxReplicas: 10`,
    'templates/deployment.yaml': `apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include "${chartName}.fullname" . }}\nspec:\n  replicas: {{ .Values.replicaCount }}\n  selector:\n    matchLabels:\n      app: {{ .Chart.Name }}\n  template:\n    metadata:\n      labels:\n        app: {{ .Chart.Name }}\n    spec:\n      containers:\n        - name: {{ .Chart.Name }}\n          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"\n          ports:\n            - containerPort: 80`,
    'templates/service.yaml': `apiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include "${chartName}.fullname" . }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.port }}\n      targetPort: 80\n  selector:\n    app: {{ .Chart.Name }}`,
  };
}

function generateAnsiblePlaybook(projectName: string): string {
  const appName = projectName.toLowerCase().replace(/[^a-z0-9_-]/g, '-');
  return `---
# Ansible Playbook - Generated by InoPay NCS 2.0
- name: Deploy ${projectName} to VPS
  hosts: web_servers
  become: yes
  vars:
    app_name: "${appName}"
    app_dir: "/opt/apps/{{ app_name }}"
  tasks:
    - name: Update apt cache
      apt: update_cache=yes cache_valid_time=3600
      when: ansible_os_family == "Debian"
    - name: Install Docker
      apt: name=docker.io state=present
      when: ansible_os_family == "Debian"
    - name: Start Docker
      systemd: name=docker state=started enabled=yes
    - name: Create app directory
      file: path="{{ app_dir }}" state=directory mode='0755'
    - name: Copy application files
      synchronize: src=../ dest="{{ app_dir }}/" rsync_opts=["--exclude=.git","--exclude=node_modules"]
      delegate_to: localhost
    - name: Build and start
      command: docker compose up -d --build
      args:
        chdir: "{{ app_dir }}"
    - name: Verify health
      uri: url="http://localhost/" status_code=200
      register: health_check
      retries: 5
      delay: 5
`;
}

// PHASE 3: OWASP COMPLIANCE
interface OwaspIssue {
  category: string;
  severity: 'critical' | 'high' | 'medium' | 'low';
  file: string;
  description: string;
  fix: string;
}

interface OwaspReport {
  score: number;
  passed: boolean;
  issues: OwaspIssue[];
  summary: { total: number; critical: number; high: number; medium: number; low: number; };
}

const OWASP_PATTERNS = {
  A01_BrokenAccessControl: [
    { pattern: /\/api\/.*\?.*id=\$\{/gi, severity: 'high' as const, description: 'IDOR potentiel - ID utilisateur dans URL', fix: 'Validez que l\'utilisateur a acc√®s √† cette ressource' },
  ],
  A02_CryptographicFailures: [
    { pattern: /MD5|SHA1(?!-)/gi, severity: 'medium' as const, description: 'Algorithme de hash faible', fix: 'Utilisez SHA-256 ou bcrypt' },
    { pattern: /http:\/\/(?!localhost|127\.0\.0\.1)/gi, severity: 'medium' as const, description: 'Connexion non-HTTPS', fix: 'Utilisez HTTPS pour toutes les connexions' },
  ],
  A03_Injection: [
    { pattern: /\$\{.*\}.*(?:SELECT|INSERT|UPDATE|DELETE)/gi, severity: 'critical' as const, description: 'SQL Injection potentielle', fix: 'Utilisez des requ√™tes param√©tr√©es' },
    { pattern: /dangerouslySetInnerHTML/g, severity: 'high' as const, description: 'XSS potentiel via dangerouslySetInnerHTML', fix: 'Sanitisez avec DOMPurify' },
    { pattern: /innerHTML\s*=/g, severity: 'high' as const, description: 'XSS potentiel via innerHTML', fix: 'Utilisez textContent ou sanitisez' },
  ],
  A07_IdentificationFailures: [
    { pattern: /password.*=.*['"][^'"]{1,7}['"]/gi, severity: 'medium' as const, description: 'Mot de passe faible potentiel', fix: 'Exigez des mots de passe forts' },
  ],
  A09_SecurityLogging: [
    { pattern: /console\.log\([^)]*(?:password|token|secret|key)/gi, severity: 'high' as const, description: 'Log de donn√©es sensibles', fix: 'Ne loggez jamais de donn√©es sensibles' },
  ],
};

function runOwaspAudit(files: Record<string, string>): OwaspReport {
  const issues: OwaspIssue[] = [];
  let score = 100;
  
  for (const [filePath, content] of Object.entries(files)) {
    if (!filePath.match(/\.(ts|tsx|js|jsx)$/) || filePath.includes('node_modules')) continue;
    
    for (const [category, patterns] of Object.entries(OWASP_PATTERNS)) {
      for (const check of patterns) {
        if (check.pattern.test(content)) {
          issues.push({ category, severity: check.severity, file: filePath, description: check.description, fix: check.fix });
          score -= check.severity === 'critical' ? 15 : check.severity === 'high' ? 10 : 5;
        }
      }
    }
  }
  
  score = Math.max(0, score);
  const summary = {
    total: issues.length,
    critical: issues.filter(i => i.severity === 'critical').length,
    high: issues.filter(i => i.severity === 'high').length,
    medium: issues.filter(i => i.severity === 'medium').length,
    low: issues.filter(i => i.severity === 'low').length,
  };
  
  return { score, passed: summary.critical === 0 && summary.high === 0, issues, summary };
}

// PHASE 4: AUTO-GENERATED TESTS
function generateUnitTests(components: string[], projectName: string): string {
  return `/**
 * Unit Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 */
import { describe, it, expect, vi } from 'vitest';
import { render, screen } from '@testing-library/react';

${components.slice(0, 10).map(comp => {
  const name = comp.replace(/\.tsx?$/, '').split('/').pop();
  return `
describe('${name}', () => {
  it('should be defined', () => {
    expect(true).toBe(true); // Placeholder - import and test component
  });
});`;
}).join('\n')}
`;
}

function generateIntegrationTests(routes: string[], projectName: string): string {
  return `/**
 * Integration Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 */
import { describe, it, expect } from 'vitest';

const API_URL = process.env.API_URL || 'http://localhost:3000';

describe('API Integration Tests', () => {
  it('health check should respond', async () => {
    const res = await fetch(\`\${API_URL}/health\`);
    expect(res.ok).toBe(true);
  });
${routes.slice(0, 10).map(route => `
  it('${route} should respond', async () => {
    const res = await fetch(\`\${API_URL}/api/${route}\`, { method: 'OPTIONS' });
    expect([200, 204, 401, 405]).toContain(res.status);
  });`).join('')}
});
`;
}

function generateSecurityTests(projectName: string): string {
  return `/**
 * Security Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 */
import { describe, it, expect } from 'vitest';

const API_URL = process.env.API_URL || 'http://localhost:3000';

describe('Security Tests', () => {
  it('should reject SQL injection', async () => {
    const res = await fetch(\`\${API_URL}/api/users?id=1; DROP TABLE users;--\`);
    expect(res.status).not.toBe(200);
  });
  
  it('should have CORS headers', async () => {
    const res = await fetch(\`\${API_URL}/health\`, { method: 'OPTIONS' });
    expect(res.headers.get('access-control-allow-origin')).toBeDefined();
  });
  
  it('should reject XSS attempts', async () => {
    const res = await fetch(\`\${API_URL}/api/search?q=<script>alert(1)</script>\`);
    const text = await res.text();
    expect(text).not.toContain('<script>');
  });
});
`;
}

// PHASE 4B: ADDITIONAL TEST GENERATORS
function generateHookTests(hooks: string[], projectName: string): string {
  return `/**
 * Hook Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 */
import { describe, it, expect } from 'vitest';
import { renderHook, act } from '@testing-library/react';

${hooks.slice(0, 10).map(hook => {
  const name = hook.replace(/\.tsx?$/, '').split('/').pop();
  return `
describe('${name}', () => {
  it('should be importable', () => {
    expect(true).toBe(true); // Placeholder - import and test hook
  });
});`;
}).join('\n')}
`;
}

function generateOwaspTests(projectName: string): string {
  return `/**
 * OWASP Security Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 * Based on OWASP Top 10 vulnerabilities
 */
import { describe, it, expect } from 'vitest';

const API_URL = process.env.API_URL || 'http://localhost:3000';

describe('OWASP Top 10 Security Tests', () => {
  // A01:2021 ‚Äì Broken Access Control
  it('should not expose admin endpoints without auth', async () => {
    const res = await fetch(\`\${API_URL}/api/admin\`, { method: 'GET' });
    expect([401, 403, 404]).toContain(res.status);
  });
  
  // A02:2021 ‚Äì Cryptographic Failures
  it('should use HTTPS headers', async () => {
    const res = await fetch(\`\${API_URL}/health\`);
    const csp = res.headers.get('content-security-policy');
    // In dev, CSP might not be set, but should exist in production
    expect(res.ok).toBe(true);
  });
  
  // A03:2021 ‚Äì Injection
  it('should sanitize path traversal', async () => {
    const res = await fetch(\`\${API_URL}/api/../../../etc/passwd\`);
    expect([400, 403, 404]).toContain(res.status);
  });
  
  // A05:2021 ‚Äì Security Misconfiguration
  it('should not expose server version', async () => {
    const res = await fetch(\`\${API_URL}/health\`);
    const server = res.headers.get('server') || '';
    expect(server).not.toMatch(/express|nginx.*\\/\\d/i);
  });
  
  // A07:2021 ‚Äì Identification and Authentication Failures
  it('should rate limit auth attempts', async () => {
    const attempts = await Promise.all(
      Array(10).fill(null).map(() => 
        fetch(\`\${API_URL}/api/auth\`, { 
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ email: 'test@test.com', password: 'wrong' })
        })
      )
    );
    const lastStatus = attempts[attempts.length - 1].status;
    expect([401, 429]).toContain(lastStatus);
  });
});
`;
}

function generateE2ETests(projectName: string, routes: string[]): string {
  return `/**
 * E2E Smoke Tests - ${projectName}
 * Generated by InoPay NCS 2.0
 */
import { describe, it, expect, beforeAll } from 'vitest';

const API_URL = process.env.API_URL || 'http://localhost:3000';
const APP_URL = process.env.APP_URL || 'http://localhost:5173';

describe('E2E Smoke Tests', () => {
  beforeAll(async () => {
    // Wait for services to be ready
    let attempts = 0;
    while (attempts < 30) {
      try {
        const res = await fetch(\`\${API_URL}/health\`);
        if (res.ok) break;
      } catch (e) {
        await new Promise(r => setTimeout(r, 1000));
        attempts++;
      }
    }
  });
  
  it('API health check passes', async () => {
    const res = await fetch(\`\${API_URL}/health\`);
    expect(res.ok).toBe(true);
    const data = await res.json();
    expect(data.status).toBe('healthy');
  });
  
  it('Frontend serves HTML', async () => {
    const res = await fetch(APP_URL);
    expect(res.ok).toBe(true);
    expect(res.headers.get('content-type')).toContain('text/html');
  });
${routes.slice(0, 5).map(route => `
  it('Route ${route} is reachable', async () => {
    const res = await fetch(\`\${API_URL}/api/${route}\`, { method: 'OPTIONS' });
    expect([200, 204, 401, 405]).toContain(res.status);
  });`).join('')}
});
`;
}

function generateVitestConfig(projectName: string): string {
  return `// Vitest Configuration - ${projectName}
// Generated by InoPay NCS 2.0
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    setupFiles: ['./setup.ts'],
    include: ['**/*.test.ts'],
    exclude: ['node_modules', 'dist'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: ['node_modules', 'dist', '**/*.test.ts'],
    },
    testTimeout: 30000,
  },
});
`;
}

function generateTestSetup(): string {
  return `// Test Setup - Generated by InoPay NCS 2.0
import { beforeAll, afterAll, vi } from 'vitest';

// Mock fetch if running in Node without native fetch
if (typeof globalThis.fetch === 'undefined') {
  // @ts-ignore - fetch is polyfilled in Node 18+
  global.fetch = vi.fn();
}

beforeAll(() => {
  console.log('üß™ Starting test suite...');
});

afterAll(() => {
  console.log('‚úÖ Test suite completed');
});
`;
}

// PHASE 4C: DEPENDENCY REPORT
interface DependencyReportResult {
  npm: {
    total: number;
    production: Record<string, string>;
    devDependencies: Record<string, string>;
    proprietary: string[];
    replacements: Array<{ from: string; to: string; reason: string }>;
  };
  imports: {
    external: string[];
    internal: string[];
    proprietary: string[];
  };
  analysis: {
    hasProprietaryDeps: boolean;
    hasVulnerabilities: boolean;
    suggestions: string[];
  };
}

function generateDependencyReport(files: Record<string, string>, projectName: string): DependencyReportResult {
  const report: DependencyReportResult = {
    npm: {
      total: 0,
      production: {},
      devDependencies: {},
      proprietary: [],
      replacements: [],
    },
    imports: {
      external: [],
      internal: [],
      proprietary: [],
    },
    analysis: {
      hasProprietaryDeps: false,
      hasVulnerabilities: false,
      suggestions: [],
    },
  };
  
  // Parse package.json if exists
  for (const [path, content] of Object.entries(files)) {
    if (path.endsWith('package.json') && !path.includes('node_modules')) {
      try {
        const pkg = JSON.parse(content);
        report.npm.production = pkg.dependencies || {};
        report.npm.devDependencies = pkg.devDependencies || {};
        report.npm.total = Object.keys(report.npm.production).length + Object.keys(report.npm.devDependencies).length;
        
        // Check for proprietary packages
        const PROPRIETARY = ['lovable-tagger', '@lovable/', '@gptengineer/', '@bolt/', '@v0/', '@cursor/', '@replit/', '@codeium/'];
        for (const dep of Object.keys({ ...pkg.dependencies, ...pkg.devDependencies })) {
          if (PROPRIETARY.some(p => dep.includes(p) || dep.startsWith(p))) {
            report.npm.proprietary.push(dep);
            report.analysis.hasProprietaryDeps = true;
          }
        }
        
        // Suggest replacements
        if (report.npm.production['openai'] || report.npm.devDependencies['openai']) {
          report.npm.replacements.push({ from: 'openai', to: 'ollama-js', reason: 'Use local Ollama for cost-free AI' });
        }
        if (report.npm.production['@pinecone-database/pinecone']) {
          report.npm.replacements.push({ from: '@pinecone-database/pinecone', to: 'pg + pgvector', reason: 'Use PostgreSQL with pgvector extension' });
        }
        if (report.npm.production['algoliasearch']) {
          report.npm.replacements.push({ from: 'algoliasearch', to: 'meilisearch', reason: 'Use self-hosted Meilisearch' });
        }
      } catch (e) {
        // Invalid JSON, skip
      }
    }
    
    // Scan imports in source files
    if (path.match(/\.(tsx?|jsx?)$/) && !path.includes('node_modules')) {
      const importMatches = content.matchAll(/import\s+.*\s+from\s+['"]([^'"]+)['"]/g);
      for (const match of importMatches) {
        const importPath = match[1];
        if (importPath.startsWith('.') || importPath.startsWith('@/')) {
          report.imports.internal.push(importPath);
        } else if (importPath.match(/@lovable|@gptengineer|@bolt|@v0|@cursor|lovable-tagger/)) {
          report.imports.proprietary.push(importPath);
        } else {
          report.imports.external.push(importPath);
        }
      }
    }
  }
  
  // Dedupe and count
  report.imports.external = [...new Set(report.imports.external)];
  report.imports.internal = [...new Set(report.imports.internal)];
  report.imports.proprietary = [...new Set(report.imports.proprietary)];
  
  // Generate suggestions
  if (report.imports.proprietary.length > 0) {
    report.analysis.suggestions.push('Remove ' + report.imports.proprietary.length + ' proprietary imports');
  }
  if (report.npm.replacements.length > 0) {
    report.analysis.suggestions.push('Consider ' + report.npm.replacements.length + ' open-source replacements');
  }
  
  return report;
}

// PHASE 8: DOCKER BUILD VALIDATION
interface DockerValidationResult {
  isValid: boolean;
  score: number;
  checks: {
    dockerfile: { passed: boolean; issues: string[] };
    dependencies: { passed: boolean; missing: string[] };
    envVars: { passed: boolean; required: string[]; missing: string[] };
    ports: { passed: boolean; exposed: number[] };
    healthcheck: { passed: boolean; configured: boolean };
    multiStage: { passed: boolean; stages: number };
    security: { passed: boolean; issues: string[] };
  };
  recommendations: string[];
}

function validateDockerBuild(files: Record<string, string>, hasBackend: boolean, hasDatabase: boolean): DockerValidationResult {
  const result: DockerValidationResult = {
    isValid: true,
    score: 100,
    checks: {
      dockerfile: { passed: true, issues: [] },
      dependencies: { passed: true, missing: [] },
      envVars: { passed: true, required: [], missing: [] },
      ports: { passed: true, exposed: [80] },
      healthcheck: { passed: true, configured: true },
      multiStage: { passed: true, stages: 2 },
      security: { passed: true, issues: [] },
    },
    recommendations: [],
  };
  
  // Check for package.json
  let hasPackageJson = false;
  for (const path of Object.keys(files)) {
    if (path.endsWith('package.json') && !path.includes('node_modules')) {
      hasPackageJson = true;
      try {
        const pkg = JSON.parse(files[path]);
        if (!pkg.scripts?.build) {
          result.checks.dependencies.passed = false;
          result.checks.dependencies.missing.push('build script');
          result.score -= 10;
        }
        if (!pkg.scripts?.start && !pkg.scripts?.preview) {
          result.recommendations.push('Add a start script for production');
        }
      } catch (e) {
        result.checks.dependencies.passed = false;
        result.checks.dependencies.missing.push('valid package.json');
        result.score -= 15;
      }
    }
  }
  
  if (!hasPackageJson) {
    result.checks.dependencies.passed = false;
    result.checks.dependencies.missing.push('package.json');
    result.score -= 20;
    result.isValid = false;
  }
  
  // Check required env vars
  const requiredEnvVars = ['VITE_SUPABASE_URL', 'VITE_SUPABASE_ANON_KEY'];
  if (hasBackend) {
    requiredEnvVars.push('DATABASE_URL', 'JWT_SECRET');
  }
  result.checks.envVars.required = requiredEnvVars;
  
  // Port checks
  if (hasBackend) {
    result.checks.ports.exposed.push(3000);
  }
  if (hasDatabase) {
    result.checks.ports.exposed.push(5432);
  }
  
  // Security checks
  for (const [path, content] of Object.entries(files)) {
    if (path.match(/\.(tsx?|jsx?)$/) && !path.includes('node_modules')) {
      // Check for hardcoded secrets
      if (content.match(/sk_live_|sk_test_|ghp_[a-zA-Z0-9]{36}|password\s*=\s*['"][^'"]{8,}['"]/gi)) {
        result.checks.security.passed = false;
        result.checks.security.issues.push('Potential hardcoded secret in ' + path);
        result.score -= 15;
      }
    }
  }
  
  result.isValid = result.score >= 70;
  
  if (result.score < 100) {
    result.recommendations.push('Review and fix all flagged issues before deployment');
  }
  
  return result;
}

// ============================================
// PHASE PRODUCTION READY - VALIDATION COMPL√àTE
// ============================================

interface ProductionReadyReport {
  isProductionReady: boolean;
  overallScore: number;
  timestamp: string;
  projectName: string;
  checklist: {
    build: { passed: boolean; details: string[]; score: number };
    runtime: { passed: boolean; details: string[]; score: number };
    database: { passed: boolean; details: string[]; score: number };
    api: { passed: boolean; details: string[]; score: number };
    security: { passed: boolean; details: string[]; score: number };
    coolify: { passed: boolean; details: string[]; score: number };
    integrity: { passed: boolean; details: string[]; score: number };
    documentation: { passed: boolean; details: string[]; score: number };
  };
  criticalBlockers: string[];
  warnings: string[];
  recommendations: string[];
  certifications: {
    coolifyReady: boolean;
    dockerReady: boolean;
    sovereigntyCompliant: boolean;
    securityAudited: boolean;
  };
}

function validateProductionReady(
  files: Record<string, string>,
  projectName: string,
  hasBackend: boolean,
  hasDatabase: boolean,
  sovereigntyScore: number,
  securityScore: number
): ProductionReadyReport {
  const report: ProductionReadyReport = {
    isProductionReady: true,
    overallScore: 100,
    timestamp: new Date().toISOString(),
    projectName,
    checklist: {
      build: { passed: true, details: [], score: 100 },
      runtime: { passed: true, details: [], score: 100 },
      database: { passed: true, details: [], score: 100 },
      api: { passed: true, details: [], score: 100 },
      security: { passed: true, details: [], score: 100 },
      coolify: { passed: true, details: [], score: 100 },
      integrity: { passed: true, details: [], score: 100 },
      documentation: { passed: true, details: [], score: 100 },
    },
    criticalBlockers: [],
    warnings: [],
    recommendations: [],
    certifications: {
      coolifyReady: true,
      dockerReady: true,
      sovereigntyCompliant: sovereigntyScore >= 90,
      securityAudited: securityScore >= 80,
    },
  };

  // ==========================================
  // TEST 1: BUILD VALIDATION
  // ==========================================
  let hasPackageJson = false;
  let hasBuildScript = false;
  let hasStartScript = false;
  let packageJsonContent: any = null;

  for (const [path, content] of Object.entries(files)) {
    if ((path === 'package.json' || path.endsWith('/package.json')) && !path.includes('node_modules')) {
      hasPackageJson = true;
      try {
        packageJsonContent = JSON.parse(content);
        if (packageJsonContent.scripts?.build) {
          hasBuildScript = true;
          report.checklist.build.details.push('‚úÖ Script build pr√©sent');
        } else {
          report.checklist.build.passed = false;
          report.checklist.build.score -= 30;
          report.checklist.build.details.push('‚ùå Script build manquant');
          report.criticalBlockers.push('package.json: script "build" manquant');
        }
        if (packageJsonContent.scripts?.start || packageJsonContent.scripts?.preview) {
          hasStartScript = true;
          report.checklist.build.details.push('‚úÖ Script start/preview pr√©sent');
        } else {
          report.checklist.build.score -= 10;
          report.warnings.push('Aucun script start/preview - utiliser nginx pour servir');
        }
        
        // Check dependencies are not empty
        const depsCount = Object.keys(packageJsonContent.dependencies || {}).length;
        if (depsCount > 0) {
          report.checklist.build.details.push('‚úÖ ' + depsCount + ' d√©pendances d√©clar√©es');
        } else {
          report.checklist.build.score -= 20;
          report.warnings.push('Aucune d√©pendance d√©clar√©e dans package.json');
        }
      } catch (e) {
        report.checklist.build.passed = false;
        report.checklist.build.score -= 50;
        report.criticalBlockers.push('package.json invalide (JSON malform√©)');
      }
    }
  }

  if (!hasPackageJson) {
    report.checklist.build.passed = false;
    report.checklist.build.score = 0;
    report.criticalBlockers.push('package.json manquant');
  }

  // ==========================================
  // TEST 2: RUNTIME VALIDATION
  // ==========================================
  let hasIndexHtml = false;
  let hasEntryPoint = false;
  let hasViteConfig = false;

  for (const path of Object.keys(files)) {
    if (path.includes('index.html')) hasIndexHtml = true;
    if (path.match(/main\.(tsx?|jsx?)$/) || path.match(/index\.(tsx?|jsx?)$/)) hasEntryPoint = true;
    if (path.includes('vite.config')) hasViteConfig = true;
  }

  if (hasIndexHtml) {
    report.checklist.runtime.details.push('‚úÖ index.html pr√©sent');
  } else {
    report.checklist.runtime.score -= 30;
    report.warnings.push('index.html manquant - v√©rifier la structure');
  }

  if (hasEntryPoint) {
    report.checklist.runtime.details.push('‚úÖ Point d\'entr√©e JS/TS d√©tect√©');
  } else {
    report.checklist.runtime.score -= 20;
    report.warnings.push('Point d\'entr√©e main.tsx/index.tsx non d√©tect√©');
  }

  if (hasViteConfig) {
    report.checklist.runtime.details.push('‚úÖ Configuration Vite pr√©sente');
  }

  // Check for broken imports
  let brokenImports = 0;
  for (const [path, content] of Object.entries(files)) {
    if (path.match(/\.(tsx?|jsx?)$/) && !path.includes('node_modules')) {
      // Simple check for obviously broken imports
      const imports = content.match(/from\s+['"]([^'"]+)['"]/g) || [];
      for (const imp of imports) {
        if (imp.includes('undefined') || imp.includes('null')) {
          brokenImports++;
        }
      }
    }
  }

  if (brokenImports > 0) {
    report.checklist.runtime.passed = false;
    report.checklist.runtime.score -= 20;
    report.criticalBlockers.push(brokenImports + ' imports cass√©s d√©tect√©s');
  } else {
    report.checklist.runtime.details.push('‚úÖ Aucun import cass√© d√©tect√©');
  }

  // ==========================================
  // TEST 3: DATABASE VALIDATION
  // ==========================================
  if (hasDatabase) {
    let hasSchemaFile = false;
    let hasMigrations = false;

    for (const path of Object.keys(files)) {
      if (path.includes('migrations/') && path.endsWith('.sql')) hasMigrations = true;
      if (path.includes('schema.sql') || path.includes('001_')) hasSchemaFile = true;
    }

    if (hasSchemaFile || hasMigrations) {
      report.checklist.database.details.push('‚úÖ Fichiers SQL pr√©sents');
    } else {
      report.checklist.database.score -= 20;
      report.warnings.push('Aucun fichier de migration SQL d√©tect√©');
    }

    // Check for RLS policies in SQL
    let hasRLSPolicies = false;
    for (const [path, content] of Object.entries(files)) {
      if (path.endsWith('.sql') && content.includes('POLICY')) {
        hasRLSPolicies = true;
        break;
      }
    }

    if (hasRLSPolicies) {
      report.checklist.database.details.push('‚úÖ Politiques RLS d√©tect√©es');
    } else {
      report.checklist.database.score -= 10;
      report.recommendations.push('Ajouter des politiques RLS pour s√©curiser les donn√©es');
    }
  } else {
    report.checklist.database.details.push('‚ÑπÔ∏è Base de donn√©es non incluse');
    report.checklist.database.score = 100; // N/A
  }

  // ==========================================
  // TEST 4: API VALIDATION
  // ==========================================
  if (hasBackend) {
    let hasHealthEndpoint = false;
    let routeCount = 0;

    for (const [path, content] of Object.entries(files)) {
      if (path.includes('backend/') && path.endsWith('.ts')) {
        if (content.includes('/health') || content.includes('healthcheck')) {
          hasHealthEndpoint = true;
        }
        if (content.includes('Router()') || content.includes('router.')) {
          routeCount++;
        }
      }
    }

    if (hasHealthEndpoint) {
      report.checklist.api.details.push('‚úÖ Endpoint /health pr√©sent');
    } else {
      report.checklist.api.score -= 15;
      report.recommendations.push('Ajouter un endpoint /health pour les healthchecks');
    }

    if (routeCount > 0) {
      report.checklist.api.details.push('‚úÖ ' + routeCount + ' routes d√©tect√©es');
    }
  } else {
    report.checklist.api.details.push('‚ÑπÔ∏è Backend non inclus');
    report.checklist.api.score = 100;
  }

  // ==========================================
  // TEST 5: SECURITY VALIDATION
  // ==========================================
  let hardcodedSecrets = 0;
  let consoleLogsInProd = 0;
  let evalUsage = 0;

  for (const [path, content] of Object.entries(files)) {
    if (path.match(/\.(tsx?|jsx?)$/) && !path.includes('node_modules') && !path.includes('.test.')) {
      // Hardcoded secrets
      if (content.match(/sk_live_|sk_test_|ghp_[a-zA-Z0-9]{36}|password\s*[:=]\s*['"][^'"]{8,}['"]/gi)) {
        hardcodedSecrets++;
      }
      // Console.log in production code
      const consoleLogs = (content.match(/console\.(log|debug|info)\(/g) || []).length;
      consoleLogsInProd += consoleLogs;
      // Eval usage
      if (content.match(/\beval\s*\(|new\s+Function\s*\(/g)) {
        evalUsage++;
      }
    }
  }

  if (hardcodedSecrets > 0) {
    report.checklist.security.passed = false;
    report.checklist.security.score -= 40;
    report.criticalBlockers.push(hardcodedSecrets + ' secrets cod√©s en dur d√©tect√©s');
  } else {
    report.checklist.security.details.push('‚úÖ Aucun secret cod√© en dur');
  }

  if (consoleLogsInProd > 10) {
    report.checklist.security.score -= 10;
    report.warnings.push(consoleLogsInProd + ' console.log √† retirer pour la production');
  }

  if (evalUsage > 0) {
    report.checklist.security.passed = false;
    report.checklist.security.score -= 30;
    report.criticalBlockers.push('Usage de eval() d√©tect√© - risque d\'injection');
  } else {
    report.checklist.security.details.push('‚úÖ Aucun usage de eval()');
  }

  report.checklist.security.score = Math.min(100, securityScore);

  // ==========================================
  // TEST 6: COOLIFY COMPLIANCE
  // ==========================================
  let hasDockerfile = false;
  let hasDockerCompose = false;
  let hasEnvExample = false;
  let dockerfileValid = true;

  for (const [path, content] of Object.entries(files)) {
    if (path.toLowerCase().includes('dockerfile') && !path.includes('node_modules')) {
      hasDockerfile = true;
      // Validate Dockerfile basics
      if (!content.includes('FROM')) {
        dockerfileValid = false;
        report.criticalBlockers.push('Dockerfile invalide: instruction FROM manquante');
      }
      if (!content.includes('EXPOSE')) {
        report.warnings.push('Dockerfile: instruction EXPOSE recommand√©e');
      }
      if (!content.includes('HEALTHCHECK') && !content.includes('health')) {
        report.recommendations.push('Ajouter HEALTHCHECK au Dockerfile');
      }
    }
    if (path.includes('docker-compose') && path.endsWith('.yml')) {
      hasDockerCompose = true;
    }
    if (path.includes('.env.example') || path.includes('env.example')) {
      hasEnvExample = true;
    }
  }

  if (hasDockerfile && dockerfileValid) {
    report.checklist.coolify.details.push('‚úÖ Dockerfile valide');
  } else if (hasDockerfile) {
    report.checklist.coolify.passed = false;
    report.checklist.coolify.score -= 40;
  } else {
    report.checklist.coolify.passed = false;
    report.checklist.coolify.score -= 50;
    report.criticalBlockers.push('Dockerfile manquant');
  }

  if (hasDockerCompose) {
    report.checklist.coolify.details.push('‚úÖ docker-compose.yml pr√©sent');
  } else {
    report.checklist.coolify.score -= 20;
    report.warnings.push('docker-compose.yml recommand√© pour d√©ploiement local');
  }

  if (hasEnvExample) {
    report.checklist.coolify.details.push('‚úÖ .env.example pr√©sent');
  } else {
    report.checklist.coolify.score -= 10;
    report.recommendations.push('Cr√©er .env.example pour documenter les variables');
  }

  report.certifications.coolifyReady = report.checklist.coolify.score >= 70;
  report.certifications.dockerReady = hasDockerfile && dockerfileValid;

  // ==========================================
  // TEST 7: INTEGRITY VALIDATION
  // ==========================================
  let emptyFiles = 0;
  let truncatedFiles = 0;
  let syntaxErrors = 0;

  for (const [path, content] of Object.entries(files)) {
    // Empty files
    if (content.trim().length === 0) {
      emptyFiles++;
    }
    // Truncated files (ends mid-code)
    if (path.match(/\.(tsx?|jsx?)$/) && content.length > 100) {
      const lastChars = content.trim().slice(-10);
      if (!lastChars.match(/[};)\]'"]/)) {
        truncatedFiles++;
      }
    }
    // Basic syntax validation for JSON
    if (path.endsWith('.json')) {
      try {
        JSON.parse(content);
      } catch (e) {
        syntaxErrors++;
        report.checklist.integrity.details.push('‚ùå JSON invalide: ' + path);
      }
    }
  }

  if (emptyFiles > 0) {
    report.checklist.integrity.score -= emptyFiles * 2;
    report.warnings.push(emptyFiles + ' fichiers vides d√©tect√©s');
  } else {
    report.checklist.integrity.details.push('‚úÖ Aucun fichier vide');
  }

  if (truncatedFiles > 0) {
    report.checklist.integrity.passed = false;
    report.checklist.integrity.score -= truncatedFiles * 10;
    report.criticalBlockers.push(truncatedFiles + ' fichiers potentiellement tronqu√©s');
  } else {
    report.checklist.integrity.details.push('‚úÖ Aucun fichier tronqu√©');
  }

  if (syntaxErrors > 0) {
    report.checklist.integrity.passed = false;
    report.checklist.integrity.score -= syntaxErrors * 15;
  } else {
    report.checklist.integrity.details.push('‚úÖ Tous les JSON sont valides');
  }

  // ==========================================
  // TEST 8: DOCUMENTATION VALIDATION
  // ==========================================
  let hasReadme = false;
  let hasDeployGuide = false;
  let hasEnvDocs = false;

  for (const path of Object.keys(files)) {
    if (path.toLowerCase().includes('readme')) hasReadme = true;
    if (path.toLowerCase().includes('deploy') || path.toLowerCase().includes('install')) hasDeployGuide = true;
    if (path.includes('.env.example') || path.includes('ENV')) hasEnvDocs = true;
  }

  if (hasReadme) {
    report.checklist.documentation.details.push('‚úÖ README pr√©sent');
  } else {
    report.checklist.documentation.score -= 20;
    report.warnings.push('README manquant');
  }

  if (hasDeployGuide) {
    report.checklist.documentation.details.push('‚úÖ Guide de d√©ploiement pr√©sent');
  } else {
    report.checklist.documentation.score -= 15;
    report.recommendations.push('Ajouter un guide de d√©ploiement');
  }

  // ==========================================
  // CALCULATE OVERALL SCORE
  // ==========================================
  const checkScores = Object.values(report.checklist).map(c => c.score);
  report.overallScore = Math.round(checkScores.reduce((a, b) => a + b, 0) / checkScores.length);
  
  // Adjust for critical blockers
  if (report.criticalBlockers.length > 0) {
    report.overallScore = Math.min(report.overallScore, 60);
    report.isProductionReady = false;
  }

  // Final certification
  report.isProductionReady = 
    report.overallScore >= 70 &&
    report.criticalBlockers.length === 0 &&
    report.certifications.dockerReady;

  report.certifications.sovereigntyCompliant = sovereigntyScore >= 90;
  report.certifications.securityAudited = securityScore >= 80;

  return report;
}

// Generate ZIP integrity checksum list
function generateZipIntegrityReport(files: Record<string, string>): string {
  const lines: string[] = [
    '# ZIP INTEGRITY REPORT',
    '# Generated: ' + new Date().toISOString(),
    '# Total files: ' + Object.keys(files).length,
    '',
    '## File List with Sizes',
    '',
  ];

  const sortedPaths = Object.keys(files).sort();
  let totalSize = 0;

  for (const path of sortedPaths) {
    const size = files[path].length;
    totalSize += size;
    lines.push('- ' + path + ' (' + size + ' bytes)');
  }

  lines.push('');
  lines.push('## Summary');
  lines.push('- Total files: ' + sortedPaths.length);
  lines.push('- Total size: ' + (totalSize / 1024).toFixed(2) + ' KB');
  lines.push('');
  lines.push('## Required Files Checklist');
  
  const requiredFiles = [
    'package.json',
    'Dockerfile',
    'docker-compose.yml',
    '.env.example',
    'README.md',
  ];

  for (const req of requiredFiles) {
    const exists = sortedPaths.some(p => p.includes(req));
    lines.push((exists ? '‚úÖ' : '‚ùå') + ' ' + req);
  }

  return lines.join('\n');
}

// PHASE 5: FULL LIBERATION REPORT
function generateFullLiberationReport(
  projectName: string,
  manifest: SovereigntyManifest,
  owaspReport: OwaspReport,
  securityAudit: SecurityAuditResult
): string {
  const date = new Date().toLocaleDateString('fr-FR', { year: 'numeric', month: 'long', day: 'numeric' });
  
  return `<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport de Lib√©ration - ${projectName}</title>
  <style>
    @page { size: A4; margin: 2cm; }
    * { box-sizing: border-box; }
    body { font-family: 'Segoe UI', system-ui, sans-serif; line-height: 1.6; color: #1a1a2e; max-width: 800px; margin: 0 auto; padding: 40px 20px; }
    .cover { text-align: center; padding: 60px 0; border-bottom: 3px solid #22c55e; margin-bottom: 40px; }
    .cover h1 { font-size: 2.5rem; margin: 0; background: linear-gradient(135deg, #22c55e, #16a34a); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    .cover .project-name { font-size: 1.5rem; color: #666; margin: 20px 0; }
    .cover .score { font-size: 4rem; font-weight: bold; color: ${manifest.audit.score >= 90 ? '#22c55e' : manifest.audit.score >= 70 ? '#eab308' : '#ef4444'}; }
    .section { margin: 40px 0; padding: 20px; background: #f8fafc; border-radius: 12px; page-break-inside: avoid; }
    .section h2 { color: #1a1a2e; border-bottom: 2px solid #e2e8f0; padding-bottom: 10px; }
    .stat-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 20px; }
    .stat { background: white; padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    .stat .value { font-size: 2rem; font-weight: bold; color: #22c55e; }
    .stat .label { color: #666; font-size: 0.9rem; }
    .badge { display: inline-block; padding: 4px 12px; border-radius: 20px; font-size: 0.8rem; font-weight: 600; }
    .badge.success { background: #dcfce7; color: #16a34a; }
    .badge.warning { background: #fef3c7; color: #d97706; }
    .badge.error { background: #fee2e2; color: #dc2626; }
    table { width: 100%; border-collapse: collapse; margin: 20px 0; }
    th, td { padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; }
    th { background: #f1f5f9; font-weight: 600; }
    .signature-box { background: #1a1a2e; color: white; padding: 20px; border-radius: 8px; font-family: monospace; word-break: break-all; font-size: 0.8rem; }
    .footer { text-align: center; color: #666; margin-top: 60px; padding-top: 20px; border-top: 1px solid #e2e8f0; }
    @media print { body { padding: 0; } .section { break-inside: avoid; } }
  </style>
</head>
<body>
  <div class="cover">
    <h1>üõ°Ô∏è RAPPORT DE LIB√âRATION</h1>
    <div class="project-name">${projectName}</div>
    <div class="score">${manifest.audit.score}%</div>
    <p>Score de Souverainet√© Num√©rique</p>
    <p style="color:#666;">G√©n√©r√© le ${date}</p>
  </div>

  <div class="section">
    <h2>üìä R√©sum√© Ex√©cutif</h2>
    <div class="stat-grid">
      <div class="stat"><div class="value">${manifest.statistics.filesCount}</div><div class="label">Fichiers analys√©s</div></div>
      <div class="stat"><div class="value">${manifest.statistics.linesOfCode.toLocaleString()}</div><div class="label">Lignes de code</div></div>
      <div class="stat"><div class="value">${manifest.statistics.routesConverted}</div><div class="label">Routes converties</div></div>
      <div class="stat"><div class="value">${manifest.audit.criticalIssues}</div><div class="label">Probl√®mes critiques</div></div>
    </div>
  </div>

  <div class="section">
    <h2>‚úÖ Certifications</h2>
    <table>
      <tr><th>Certification</th><th>Statut</th></tr>
      <tr><td>Open Source Compliance</td><td><span class="badge ${manifest.certification.openSourceCompliance ? 'success' : 'error'}">${manifest.certification.openSourceCompliance ? 'CONFORME' : 'NON CONFORME'}</span></td></tr>
      <tr><td>Portable Compliance</td><td><span class="badge ${manifest.certification.portableCompliance ? 'success' : 'error'}">${manifest.certification.portableCompliance ? 'CONFORME' : 'NON CONFORME'}</span></td></tr>
      <tr><td>Coolify Ready</td><td><span class="badge ${manifest.certification.coolifyCompliance ? 'success' : 'warning'}">${manifest.certification.coolifyCompliance ? 'PR√äT' : '√Ä OPTIMISER'}</span></td></tr>
      <tr><td>BigTech Dependencies</td><td><span class="badge ${manifest.certification.bigTechDependency === 0 ? 'success' : 'warning'}">${manifest.certification.bigTechDependency} d√©pendance(s)</span></td></tr>
    </table>
  </div>

  <div class="section">
    <h2>üîí Audit OWASP</h2>
    <p>Score: <strong>${owaspReport.score}%</strong> - ${owaspReport.passed ? '‚úÖ Conforme' : '‚ö†Ô∏è Am√©liorations n√©cessaires'}</p>
    <div class="stat-grid">
      <div class="stat"><div class="value" style="color:#dc2626">${owaspReport.summary.critical}</div><div class="label">Critiques</div></div>
      <div class="stat"><div class="value" style="color:#f97316">${owaspReport.summary.high}</div><div class="label">√âlev√©s</div></div>
      <div class="stat"><div class="value" style="color:#eab308">${owaspReport.summary.medium}</div><div class="label">Moyens</div></div>
      <div class="stat"><div class="value" style="color:#22c55e">${owaspReport.summary.low}</div><div class="label">Faibles</div></div>
    </div>
  </div>

  <div class="section">
    <h2>üõ°Ô∏è Audit de S√©curit√©</h2>
    <p>Score: <strong>${securityAudit.score}%</strong> - ${securityAudit.isSecure ? '‚úÖ S√©curis√©' : '‚ö†Ô∏è Vuln√©rabilit√©s d√©tect√©es'}</p>
    <p>${securityAudit.summary}</p>
  </div>

  <div class="section">
    <h2>üîê Signature Cryptographique</h2>
    <p>Ce rapport est sign√© cryptographiquement (SHA-256) pour garantir son int√©grit√©.</p>
    <div class="signature-box">
      <strong>Signature:</strong><br/>
      ${manifest.signature}<br/><br/>
      <strong>Sign√© le:</strong> ${manifest.signedAt}
    </div>
  </div>

  <div class="footer">
    <p>üõ°Ô∏è G√©n√©r√© par <strong>InoPay NCS 2.0</strong> - La Grande Messe de Lib√©ration Num√©rique</p>
    <p><a href="https://inopay.fr">inopay.fr</a></p>
  </div>
</body>
</html>`;
}

// PHASE 6: ENHANCED SECURITY AUDIT
interface SecurityAuditResult {
  isSecure: boolean;
  score: number;
  categories: {
    dangerousFunctions: SecurityIssue[];
    suspiciousDNS: SecurityIssue[];
    credentialLeaks: SecurityIssue[];
    hiddenTelemetry: SecurityIssue[];
    backdoors: SecurityIssue[];
  };
  summary: string;
}

interface SecurityIssue {
  severity: 'critical' | 'high' | 'medium' | 'low';
  file: string;
  description: string;
  remediation: string;
}

const SECURITY_AUDIT_PATTERNS = {
  dangerousFunctions: [
    { pattern: /\beval\s*\(/g, severity: 'critical' as const, description: 'eval() - Ex√©cution de code arbitraire', remediation: 'Utilisez JSON.parse()' },
    { pattern: /new\s+Function\s*\(/g, severity: 'critical' as const, description: 'new Function() - Code dynamique', remediation: '√âvitez la cr√©ation dynamique' },
    { pattern: /\bexec\s*\(/g, severity: 'high' as const, description: 'exec() - Commandes syst√®me', remediation: 'Validez strictement les entr√©es' },
    { pattern: /child_process/g, severity: 'high' as const, description: 'child_process - Spawn de processus', remediation: 'Limitez et validez' },
  ],
  suspiciousDNS: [
    { pattern: /fetch\s*\([^)]*(?:pastebin|hastebin|0x0\.st)/gi, severity: 'critical' as const, description: 'Fetch vers service suspect', remediation: 'Supprimez' },
    { pattern: /(?:ngrok|localtunnel)\.io/gi, severity: 'medium' as const, description: 'Tunnel externe', remediation: 'Supprimez en production' },
  ],
  credentialLeaks: [
    { pattern: /(?:api[_-]?key|apikey)\s*[:=]\s*['"][A-Za-z0-9_-]{20,}['"]/gi, severity: 'critical' as const, description: 'Cl√© API hardcod√©e', remediation: 'Variables d\'environnement' },
    { pattern: /sk_live_[A-Za-z0-9]{20,}/g, severity: 'critical' as const, description: 'Cl√© Stripe expos√©e', remediation: 'Variables d\'environnement' },
    { pattern: /ghp_[A-Za-z0-9]{36}/g, severity: 'critical' as const, description: 'Token GitHub expos√©', remediation: 'R√©g√©n√©rez le token' },
  ],
  hiddenTelemetry: [
    { pattern: /sentry\.io|bugsnag|rollbar/gi, severity: 'medium' as const, description: 'Monitoring tiers', remediation: 'Utilisez Glitchtip self-hosted' },
    { pattern: /google-analytics|gtag/gi, severity: 'medium' as const, description: 'Google Analytics', remediation: 'Utilisez Plausible/Umami' },
  ],
  backdoors: [
    { pattern: /atob\s*\([^)]*\)\s*\(/g, severity: 'critical' as const, description: 'Code base64 ex√©cut√©', remediation: 'Analysez le code d√©cod√©' },
    { pattern: /document\.cookie.*fetch/gi, severity: 'critical' as const, description: 'Exfiltration de cookies', remediation: 'Supprimez imm√©diatement' },
  ],
};

function runSecurityAudit(files: Record<string, string>): SecurityAuditResult {
  const result: SecurityAuditResult = {
    isSecure: true,
    score: 100,
    categories: { dangerousFunctions: [], suspiciousDNS: [], credentialLeaks: [], hiddenTelemetry: [], backdoors: [] },
    summary: '',
  };
  
  for (const [filePath, content] of Object.entries(files)) {
    if (!filePath.match(/\.(ts|tsx|js|jsx|json|env)$/) || filePath.includes('node_modules')) continue;
    
    for (const [category, patterns] of Object.entries(SECURITY_AUDIT_PATTERNS)) {
      for (const check of patterns) {
        if (check.pattern.test(content)) {
          (result.categories as any)[category].push({ severity: check.severity, file: filePath, description: check.description, remediation: check.remediation });
          result.score -= check.severity === 'critical' ? 15 : check.severity === 'high' ? 10 : 5;
          if (check.severity === 'critical') result.isSecure = false;
        }
      }
    }
  }
  
  result.score = Math.max(0, result.score);
  const totalIssues = Object.values(result.categories).flat().length;
  result.summary = totalIssues === 0 ? '‚úÖ Aucune vuln√©rabilit√© d√©tect√©e' : `‚ö†Ô∏è ${totalIssues} probl√®me(s) de s√©curit√©`;
  return result;
}

// PHASE 7: ARCHITECTURE DIAGRAMS
function generateArchitectureDiagram(projectName: string, hasBackend: boolean, hasDatabase: boolean, edgeFunctions: string[]): string {
  return `# Architecture - ${projectName}

## Diagramme Principal

\`\`\`mermaid
graph TD
    subgraph Frontend["üñ•Ô∏è Frontend (React)"]
        UI[Interface Utilisateur]
        Components[Composants React]
        Hooks[Hooks & State]
    end
    
    ${hasBackend ? `subgraph Backend["‚öôÔ∏è Backend (Express)"]
        API[API REST]
        ${edgeFunctions.slice(0, 5).map(f => `${f.replace(/-/g, '_')}[${f}]`).join('\n        ')}
    end` : ''}
    
    ${hasDatabase ? `subgraph Database["üóÑÔ∏è Database"]
        DB[(PostgreSQL)]
    end` : ''}
    
    UI --> Components
    Components --> Hooks
    ${hasBackend ? 'Hooks --> API' : ''}
    ${hasBackend && hasDatabase ? 'API --> DB' : ''}
\`\`\`

## Flux de Donn√©es

\`\`\`mermaid
sequenceDiagram
    participant U as Utilisateur
    participant F as Frontend
    ${hasBackend ? 'participant A as API' : ''}
    ${hasDatabase ? 'participant D as Database' : ''}
    
    U->>F: Action utilisateur
    ${hasBackend ? 'F->>A: Requ√™te API' : ''}
    ${hasBackend && hasDatabase ? 'A->>D: Query SQL' : ''}
    ${hasBackend && hasDatabase ? 'D-->>A: R√©sultat' : ''}
    ${hasBackend ? 'A-->>F: Response JSON' : ''}
    F-->>U: Mise √† jour UI
\`\`\`
`;
}

// PHASE 9: SECRETS VAULT INTEGRATION
function generateVaultPolicy(projectName: string, envVars: string[]): string {
  const appName = projectName.toLowerCase().replace(/[^a-z0-9_-]/g, '-');
  return `# Hashicorp Vault Policy - ${projectName}
# Generated by InoPay NCS 2.0

path "secret/data/${appName}/*" {
  capabilities = ["read", "list"]
}

path "secret/metadata/${appName}/*" {
  capabilities = ["read", "list"]
}

# Environment variables to store:
${envVars.map(v => `# - ${v}`).join('\n')}
`;
}

function generateVaultImportScript(projectName: string, envVars: string[]): string {
  const appName = projectName.toLowerCase().replace(/[^a-z0-9_-]/g, '-');
  return `#!/bin/bash
# Import secrets to Hashicorp Vault - ${projectName}
# Generated by InoPay NCS 2.0

set -e

VAULT_ADDR=\${VAULT_ADDR:-http://localhost:8200}
PROJECT_NAME="${appName}"

echo "üîê Importing secrets to Vault..."

# Read from .env and import
while IFS='=' read -r key value; do
  if [[ ! -z "$key" && ! "$key" =~ ^# ]]; then
    echo "  ‚Üí Storing $key"
    vault kv put "secret/$PROJECT_NAME/$key" value="$value"
  fi
done < .env

echo "‚úÖ Secrets imported successfully!"
echo "   Path: secret/$PROJECT_NAME/"
`;
}

function generateDopplerConfig(projectName: string): string {
  const appName = projectName.toLowerCase().replace(/[^a-z0-9_-]/g, '-');
  return `# Doppler Configuration - ${projectName}
# Generated by InoPay NCS 2.0

setup:
  project: ${appName}
  config: prd

# Commands:
# doppler setup
# doppler run -- npm start
# doppler secrets download --no-file --format env > .env
`;
}

// PHASE 10: ZIP SIGNATURE
async function generateZipSignature(zipBuffer: Uint8Array): Promise<string> {
  const hashBuffer = await crypto.subtle.digest('SHA-256', zipBuffer.buffer as ArrayBuffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
}

function generateChecksumFile(signature: string, files: string[]): string {
  return `# SHA-256 Checksum - Liberation Pack
# Generated by InoPay NCS 2.0
# Verification: sha256sum -c CHECKSUM.sha256

${signature}  liberation-pack.zip

# Files included: ${files.length}
# Generated: ${new Date().toISOString()}

# To verify integrity:
# 1. sha256sum -c CHECKSUM.sha256
# 2. All files should show "OK"
`;
}

// ============================================
// TEMPLATES DOCKER
// ============================================

// ============================================
// COOLIFY-COMPATIBLE DOCKERFILE AVEC BUILD ARGS
// ============================================
const FRONTEND_DOCKERFILE = `# Stage 1: Build
FROM node:20-alpine AS builder
WORKDIR /app

# Accept build args for Vite env vars (Coolify compatible)
ARG VITE_SUPABASE_URL
ARG VITE_SUPABASE_ANON_KEY
ARG VITE_SUPABASE_PROJECT_ID
ARG VITE_APP_URL

# Set as env vars for build
ENV VITE_SUPABASE_URL=\${VITE_SUPABASE_URL}
ENV VITE_SUPABASE_ANON_KEY=\${VITE_SUPABASE_ANON_KEY}
ENV VITE_SUPABASE_PROJECT_ID=\${VITE_SUPABASE_PROJECT_ID}
ENV VITE_APP_URL=\${VITE_APP_URL}

# Install dependencies (with fallback if no lockfile)
COPY package*.json ./
RUN npm install --legacy-peer-deps || npm install

# Copy source and build
COPY . .
RUN npm run build

# Stage 2: Production avec Caddy (meilleur support HTTPS automatique)
FROM caddy:2-alpine
COPY --from=builder /app/dist /usr/share/caddy
COPY Caddyfile /etc/caddy/Caddyfile
EXPOSE 80 443
CMD ["caddy", "run", "--config", "/etc/caddy/Caddyfile"]
`;

// ============================================
// SERVER-SIDE POLYFILLS (CENTRALIZED)
// Pour √©viter les erreurs TypeScript dans le pack
// ============================================

const POLYFILL_SUPABASE = `// Client Supabase configurable - G√©n√©r√© par InoPay Liberation Pack
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = import.meta.env.VITE_SUPABASE_URL || '';
const supabaseKey = import.meta.env.VITE_SUPABASE_ANON_KEY || '';

if (!supabaseUrl || !supabaseKey) {
  console.warn('[supabase] Missing VITE_SUPABASE_URL or VITE_SUPABASE_ANON_KEY in environment');
}

export const supabase = createClient(supabaseUrl, supabaseKey);
export default supabase;
`;

const POLYFILL_DATABASE = `// Types Database g√©n√©riques - G√©n√©r√© par InoPay Liberation Pack
// Remplacez par vos types sp√©cifiques si n√©cessaire

export type Json =
  | string
  | number
  | boolean
  | null
  | { [key: string]: Json | undefined }
  | Json[];

export interface Database {
  public: {
    Tables: Record<string, {
      Row: Record<string, unknown>;
      Insert: Record<string, unknown>;
      Update: Record<string, unknown>;
    }>;
    Views: Record<string, never>;
    Functions: Record<string, never>;
    Enums: Record<string, string[]>;
    CompositeTypes: Record<string, never>;
  };
}

export type Tables<T extends keyof Database['public']['Tables']> = 
  Database['public']['Tables'][T]['Row'];

export type TablesInsert<T extends keyof Database['public']['Tables']> = 
  Database['public']['Tables'][T]['Insert'];

export type TablesUpdate<T extends keyof Database['public']['Tables']> = 
  Database['public']['Tables'][T]['Update'];
`;

const POLYFILL_USE_MOBILE = `// Hook useIsMobile - G√©n√©r√© par InoPay Liberation Pack
import { useState, useEffect } from 'react';

const MOBILE_BREAKPOINT = 768;

export function useIsMobile(): boolean {
  const [isMobile, setIsMobile] = useState(false);

  useEffect(() => {
    const checkMobile = () => {
      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT);
    };
    
    checkMobile();
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  return isMobile;
}
`;

const POLYFILL_USE_TOAST = `// Hook useToast - Wrapper Sonner - G√©n√©r√© par InoPay Liberation Pack
import { toast as sonnerToast } from 'sonner';

export interface ToastProps {
  title?: string;
  description?: string;
  variant?: 'default' | 'destructive';
}

export function toast(props: ToastProps) {
  const { title, description, variant } = props;
  
  if (variant === 'destructive') {
    sonnerToast.error(title || description, {
      description: title ? description : undefined,
    });
  } else {
    sonnerToast(title || description, {
      description: title ? description : undefined,
    });
  }
}

export function useToast() {
  return { toast };
}
`;

interface PolyfillConfig {
  path: string;
  content: string;
  detectPatterns: string[];
}

const SERVER_POLYFILLS: Record<string, PolyfillConfig> = {
  supabase: {
    path: 'src/lib/supabase.ts',
    detectPatterns: [
      "@/lib/supabase",
      "@/integrations/supabase/client",
      "supabase.from(",
      "supabase.auth.",
    ],
    content: POLYFILL_SUPABASE
  },
  database: {
    path: 'src/types/database.ts',
    detectPatterns: [
      "@/types/database",
      "@/integrations/supabase/types",
      "Database[",
      "Tables<",
    ],
    content: POLYFILL_DATABASE
  },
  useMobile: {
    path: 'src/hooks/use-mobile.tsx',
    detectPatterns: [
      "@/hooks/use-mobile",
      "useIsMobile(",
    ],
    content: POLYFILL_USE_MOBILE
  },
  useToast: {
    path: 'src/hooks/use-toast.ts',
    detectPatterns: [
      "@/hooks/use-toast",
      "useToast()",
    ],
    content: POLYFILL_USE_TOAST
  }
};

// ============================================
// D√âPENDANCES REQUISES POUR LE PACK
// ============================================

interface RequiredDependency {
  name: string;
  version: string;
  detectPatterns: string[];
  description: string;
}

const REQUIRED_DEPENDENCIES: RequiredDependency[] = [
  {
    name: '@supabase/supabase-js',
    version: '^2.39.0',
    detectPatterns: ['supabase.from(', 'supabase.auth.', "@/lib/supabase", "createClient("],
    description: 'Supabase client for database and auth'
  },
  {
    name: 'sonner',
    version: '^1.4.0',
    detectPatterns: ['sonner', 'toast(', 'useToast()', "@/hooks/use-toast"],
    description: 'Toast notifications'
  },
  {
    name: 'react',
    version: '^18.2.0',
    detectPatterns: ['from "react"', "from 'react'", 'React.', 'useState', 'useEffect'],
    description: 'React library'
  },
  {
    name: 'react-dom',
    version: '^18.2.0',
    detectPatterns: ['from "react-dom"', "from 'react-dom'", 'ReactDOM'],
    description: 'React DOM'
  },
  {
    name: 'react-router-dom',
    version: '^6.20.0',
    detectPatterns: ['useNavigate', 'useParams', 'BrowserRouter', '<Route', '<Link'],
    description: 'React Router'
  }
];

/**
 * Valide et corrige le package.json pour s'assurer que toutes les d√©pendances
 * n√©cessaires sont pr√©sentes (notamment @supabase/supabase-js et sonner)
 */
function validateAndFixPackageJson(
  files: Record<string, string>,
  allContent: string
): { fixed: boolean; added: string[]; errors: string[] } {
  const result = { fixed: false, added: [] as string[], errors: [] as string[] };
  
  // Trouver le package.json
  const packageJsonPath = Object.keys(files).find(p => p === 'package.json' || p.endsWith('/package.json'));
  
  if (!packageJsonPath) {
    result.errors.push('No package.json found in project');
    return result;
  }
  
  try {
    const packageJsonContent = files[packageJsonPath];
    const packageJson = JSON.parse(packageJsonContent);
    
    // S'assurer que dependencies existe
    if (!packageJson.dependencies) {
      packageJson.dependencies = {};
    }
    
    // V√©rifier chaque d√©pendance requise
    for (const dep of REQUIRED_DEPENDENCIES) {
      const isUsed = dep.detectPatterns.some(pattern => allContent.includes(pattern));
      
      if (isUsed && !packageJson.dependencies[dep.name]) {
        packageJson.dependencies[dep.name] = dep.version;
        result.added.push(dep.name);
        result.fixed = true;
        console.log(`[package.json] Added missing dependency: ${dep.name}@${dep.version}`);
      }
    }
    
    // Mettre √† jour le fichier si modifi√©
    if (result.fixed) {
      files[packageJsonPath] = JSON.stringify(packageJson, null, 2);
    }
    
  } catch (error) {
    result.errors.push(`Failed to parse package.json: ${error}`);
  }
  
  return result;
}

/**
 * D√©tecte les polyfills n√©cessaires en analysant les fichiers du projet
 */
function detectRequiredPolyfills(files: Record<string, string>): Record<string, string> {
  const required: Record<string, string> = {};
  const allContent = Object.values(files).join('\n');
  
  for (const [name, polyfill] of Object.entries(SERVER_POLYFILLS)) {
    const needsPolyfill = polyfill.detectPatterns.some(pattern => allContent.includes(pattern));
    
    if (needsPolyfill) {
      required[polyfill.path] = polyfill.content;
      console.log(`[generate-liberation-pack] Polyfill needed: ${name} -> ${polyfill.path}`);
    }
  }
  
  // Si on a besoin de supabase, on a besoin de database types aussi
  if (required['src/lib/supabase.ts'] && !required['src/types/database.ts']) {
    required['src/types/database.ts'] = SERVER_POLYFILLS.database.content;
    console.log('[generate-liberation-pack] Adding database types (dependency of supabase)');
  }
  
  return required;
}

/**
 * Ajoute les polyfills d√©tect√©s au dossier frontend du ZIP
 */
function addPolyfillsToFrontend(
  frontendFolder: JSZip, 
  files: Record<string, string>
): { added: string[]; count: number } {
  const polyfills = detectRequiredPolyfills(files);
  const added: string[] = [];
  
  for (const [path, content] of Object.entries(polyfills)) {
    // V√©rifier que le fichier n'existe pas d√©j√†
    if (!files[path]) {
      frontendFolder.file(path, content);
      added.push(path);
    }
  }
  
  return { added, count: added.length };
}

const BACKEND_DOCKERFILE = `FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY --from=builder /app/dist ./dist
ENV NODE_ENV=production
ENV PORT=3000
EXPOSE 3000
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
  CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1
CMD ["node", "dist/index.js"]
`;

const NGINX_CONF = `server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml text/javascript;

    location / {
        try_files $uri $uri/ /index.html;
    }

    location ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
`;

// ============================================
// TEMPLATES SERVICES OPEN SOURCE
// ============================================

const OLLAMA_DOCKER_COMPOSE = `# Service Ollama - IA locale
# Ajoutez ce service √† votre docker-compose.yml principal

ollama:
  image: ollama/ollama:latest
  container_name: ollama
  restart: unless-stopped
  ports:
    - "11434:11434"
  volumes:
    - ollama_data:/root/.ollama
  environment:
    - OLLAMA_HOST=0.0.0.0
  networks:
    - app-network
  # D√©commentez pour GPU NVIDIA
  # deploy:
  #   resources:
  #     reservations:
  #       devices:
  #         - driver: nvidia
  #           count: all
  #           capabilities: [gpu]

# Ajoutez √† volumes:
#   ollama_data:
`;

const MEILISEARCH_DOCKER_COMPOSE = `# Service Meilisearch - Recherche full-text
# Ajoutez ce service √† votre docker-compose.yml principal

meilisearch:
  image: getmeili/meilisearch:latest
  container_name: meilisearch
  restart: unless-stopped
  ports:
    - "7700:7700"
  volumes:
    - meilisearch_data:/meili_data
  environment:
    - MEILI_MASTER_KEY=\${MEILISEARCH_MASTER_KEY}
    - MEILI_ENV=production
  networks:
    - app-network
  healthcheck:
    test: ["CMD", "wget", "--spider", "-q", "http://localhost:7700/health"]
    interval: 30s
    timeout: 10s
    retries: 3

# Ajoutez √† volumes:
#   meilisearch_data:

# Ajoutez √† .env:
#   MEILISEARCH_MASTER_KEY=votre_cle_secrete
`;

const MINIO_DOCKER_COMPOSE = `# Service MinIO - Stockage S3-compatible
# Ajoutez ce service √† votre docker-compose.yml principal

minio:
  image: minio/minio:latest
  container_name: minio
  restart: unless-stopped
  ports:
    - "9000:9000"
    - "9001:9001"
  volumes:
    - minio_data:/data
  environment:
    - MINIO_ROOT_USER=\${MINIO_ACCESS_KEY}
    - MINIO_ROOT_PASSWORD=\${MINIO_SECRET_KEY}
  command: server /data --console-address ":9001"
  networks:
    - app-network
  healthcheck:
    test: ["CMD", "mc", "ready", "local"]
    interval: 30s
    timeout: 10s
    retries: 3

# Ajoutez √† volumes:
#   minio_data:

# Ajoutez √† .env:
#   MINIO_ACCESS_KEY=minioadmin
#   MINIO_SECRET_KEY=votre_mot_de_passe_securise
`;

const OPEN_SOURCE_SERVICES_GUIDE = `# üîì Guide des Services Open Source

Ce pack inclut des templates pour remplacer les services propri√©taires par des alternatives 100% open source.

## ü§ñ Ollama - IA Locale

**Remplace:** OpenAI API, Claude API, services IA propri√©taires

### Installation

1. Ajoutez le service √† \`docker-compose.yml\` (voir \`services/ollama/docker-compose.yml\`)
2. D√©marrez: \`docker compose up -d ollama\`
3. T√©l√©chargez un mod√®le:
   \`\`\`bash
   docker exec ollama ollama pull llama2
   docker exec ollama ollama pull mistral
   docker exec ollama ollama pull codellama  # Pour le code
   \`\`\`

### Utilisation dans votre code

\`\`\`typescript
// Remplacez vos appels OpenAI par:
const response = await fetch('http://ollama:11434/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model: 'llama2',
    messages: [{ role: 'user', content: 'Bonjour!' }],
    stream: false
  })
});
\`\`\`

### Mod√®les recommand√©s
- **llama2** / **llama3**: Usage g√©n√©ral
- **mistral** / **mixtral**: Excellent √©quilibre qualit√©/vitesse
- **codellama**: G√©n√©ration de code
- **phi**: Petit mais efficace

---

## üîç Meilisearch - Recherche Full-Text

**Remplace:** Algolia, Elasticsearch (plus simple)

### Installation

1. Ajoutez le service (voir \`services/meilisearch/docker-compose.yml\`)
2. Configurez \`MEILISEARCH_MASTER_KEY\` dans \`.env\`
3. D√©marrez: \`docker compose up -d meilisearch\`

### Utilisation

\`\`\`typescript
import { MeiliSearch } from 'meilisearch';

const client = new MeiliSearch({
  host: 'http://meilisearch:7700',
  apiKey: process.env.MEILISEARCH_MASTER_KEY
});

// Indexer
await client.index('products').addDocuments(products);

// Rechercher
const results = await client.index('products').search('requ√™te');
\`\`\`

---

## üì¶ MinIO - Stockage S3-Compatible

**Remplace:** AWS S3, Supabase Storage, Cloudflare R2

### Installation

1. Ajoutez le service (voir \`services/minio/docker-compose.yml\`)
2. Configurez les credentials dans \`.env\`
3. D√©marrez: \`docker compose up -d minio\`
4. Console admin: \`http://votre-ip:9001\`

### Utilisation

\`\`\`typescript
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';

const s3 = new S3Client({
  endpoint: 'http://minio:9000',
  region: 'us-east-1',
  credentials: {
    accessKeyId: process.env.MINIO_ACCESS_KEY,
    secretAccessKey: process.env.MINIO_SECRET_KEY
  },
  forcePathStyle: true
});

// Upload
await s3.send(new PutObjectCommand({
  Bucket: 'mon-bucket',
  Key: 'fichier.pdf',
  Body: buffer
}));
\`\`\`

---

## üìß Mailhog - Email en D√©veloppement

**Remplace:** Services SMTP pour le dev

\`\`\`yaml
mailhog:
  image: mailhog/mailhog
  ports:
    - "1025:1025"  # SMTP
    - "8025:8025"  # Web UI
\`\`\`

---

## üîÑ Soketi - WebSocket Pusher-Compatible

**Remplace:** Pusher, Ably

\`\`\`yaml
soketi:
  image: quay.io/soketi/soketi:latest
  ports:
    - "6001:6001"
  environment:
    - SOKETI_DEFAULT_APP_ID=app-id
    - SOKETI_DEFAULT_APP_KEY=app-key
    - SOKETI_DEFAULT_APP_SECRET=app-secret
\`\`\`

---

## üìä Tableau Comparatif

| Propri√©taire | Alternative Open Source | Effort Migration |
|-------------|------------------------|------------------|
| OpenAI API | Ollama + Llama/Mistral | ‚≠ê‚≠ê Moyen |
| Algolia | Meilisearch | ‚≠ê Facile |
| AWS S3 | MinIO | ‚≠ê Facile |
| Pusher | Soketi | ‚≠ê Facile |
| Supabase Auth | Self-hosted Supabase | ‚≠ê‚≠ê‚≠ê Complexe |

---

*G√©n√©r√© par InoPay Liberation Pack*
`;

// ============================================
// TEMPLATE AI CLIENT CONFIGURABLE
// ============================================

const AI_CLIENT_TEMPLATE = `/**
 * Client IA Configurable - Compatible Ollama, OpenRouter, OpenAI
 * G√©n√©r√© par InoPay Liberation Pack
 */

export interface AIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface AIConfig {
  provider: 'ollama' | 'openrouter' | 'openai' | 'custom';
  baseUrl?: string;
  apiKey?: string;
  model?: string;
}

const DEFAULT_CONFIGS: Record<string, Partial<AIConfig>> = {
  ollama: {
    baseUrl: process.env.OLLAMA_URL || 'http://localhost:11434',
    model: process.env.OLLAMA_MODEL || 'llama2'
  },
  openrouter: {
    baseUrl: 'https://openrouter.ai/api/v1',
    apiKey: process.env.OPENROUTER_API_KEY,
    model: process.env.OPENROUTER_MODEL || 'meta-llama/llama-3.1-8b-instruct:free'
  },
  openai: {
    baseUrl: 'https://api.openai.com/v1',
    apiKey: process.env.OPENAI_API_KEY,
    model: process.env.OPENAI_MODEL || 'gpt-4o-mini'
  }
};

export class AIClient {
  private config: AIConfig;

  constructor(config?: Partial<AIConfig>) {
    const provider = config?.provider || (process.env.AI_PROVIDER as any) || 'ollama';
    this.config = {
      provider,
      ...DEFAULT_CONFIGS[provider],
      ...config
    };
  }

  async chat(messages: AIMessage[], options?: { stream?: boolean }): Promise<string> {
    const { provider, baseUrl, apiKey, model } = this.config;

    if (provider === 'ollama') {
      return this.chatOllama(messages);
    }

    // OpenAI-compatible API (OpenRouter, OpenAI, etc.)
    const response = await fetch(\`\${baseUrl}/chat/completions\`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(apiKey && { 'Authorization': \`Bearer \${apiKey}\` }),
        ...(provider === 'openrouter' && { 'HTTP-Referer': process.env.APP_URL || 'http://localhost' })
      },
      body: JSON.stringify({
        model,
        messages,
        stream: options?.stream || false
      })
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(\`AI Error: \${error}\`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  private async chatOllama(messages: AIMessage[]): Promise<string> {
    const response = await fetch(\`\${this.config.baseUrl}/api/chat\`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: this.config.model,
        messages,
        stream: false
      })
    });

    if (!response.ok) {
      throw new Error(\`Ollama Error: \${await response.text()}\`);
    }

    const data = await response.json();
    return data.message.content;
  }

  async *streamChat(messages: AIMessage[]): AsyncGenerator<string> {
    const { provider, baseUrl, apiKey, model } = this.config;

    if (provider === 'ollama') {
      yield* this.streamOllama(messages);
      return;
    }

    const response = await fetch(\`\${baseUrl}/chat/completions\`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(apiKey && { 'Authorization': \`Bearer \${apiKey}\` })
      },
      body: JSON.stringify({ model, messages, stream: true })
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();

    while (reader) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\\n').filter(line => line.startsWith('data: '));

      for (const line of lines) {
        const json = line.slice(6);
        if (json === '[DONE]') return;
        try {
          const parsed = JSON.parse(json);
          const content = parsed.choices?.[0]?.delta?.content;
          if (content) yield content;
        } catch {}
      }
    }
  }

  private async *streamOllama(messages: AIMessage[]): AsyncGenerator<string> {
    const response = await fetch(\`\${this.config.baseUrl}/api/chat\`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: this.config.model,
        messages,
        stream: true
      })
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();

    while (reader) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      try {
        const parsed = JSON.parse(chunk);
        if (parsed.message?.content) yield parsed.message.content;
      } catch {}
    }
  }
}

// Instance par d√©faut
export const ai = new AIClient();

// Usage:
// import { ai } from '@/lib/ai-client';
// const response = await ai.chat([{ role: 'user', content: 'Bonjour!' }]);
`;

// ============================================
// SOVEREIGNTY VERIFICATION
// ============================================

interface SovereigntyCheck {
  isClean: boolean;
  score: number;
  criticalIssues: string[];
  warnings: string[];
}

/**
 * CRITICAL FILES ONLY - Server-side cleaning is now minimal
 * Files are already cleaned client-side, we only verify critical patterns
 */
const CRITICAL_FILE_PATTERNS = [
  '.env',
  'package.json',
  'vite.config.ts',
  'vite.config.js',
  'index.html',
  'supabase/config.toml',
];

function shouldCleanServerSide(filePath: string): boolean {
  return CRITICAL_FILE_PATTERNS.some(p => filePath.includes(p));
}

function serverSideDeepClean(content: string, filePath: string): { cleaned: string; changes: string[] } {
  const changes: string[] = [];
  let cleaned = content;

  // FAST PATH: Skip heavy cleaning for non-critical files (already cleaned client-side)
  if (!shouldCleanServerSide(filePath)) {
    // Only do minimal security-critical replacements
    const before1 = cleaned;
    cleaned = cleaned.replace(/eyJ[A-Za-z0-9_-]{100,}\.[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+/g, 'YOUR_SUPABASE_KEY');
    if (cleaned !== before1) changes.push('Token JWT remplac√©');
    
    const before2 = cleaned;
    cleaned = cleaned.replace(/sk_live_[A-Za-z0-9]{20,}/g, 'sk_live_YOUR_KEY');
    if (cleaned !== before2) changes.push('Cl√© Stripe live remplac√©e');
    
    return { cleaned, changes };
  }

  // CRITICAL FILES: Full cleaning (package.json, .env, vite.config, etc.)
  
  // === PASS 1: Replace ALL @/integrations/supabase imports ===
  const supabaseImportPatterns = [
    { pattern: /from\s*['"]@\/integrations\/supabase\/client['"]/g, replacement: "from '@/lib/supabase-client'" },
    { pattern: /from\s*['"]@\/integrations\/supabase\/types['"]/g, replacement: "from '@/lib/supabase-types'" },
    { pattern: /from\s*['"]@\/integrations\/supabase[^'"]*['"]/g, replacement: "from '@/lib/supabase-client'" },
  ];

  for (const { pattern, replacement } of supabaseImportPatterns) {
    const before = cleaned;
    cleaned = cleaned.replace(pattern, replacement);
    if (cleaned !== before) changes.push('Import Supabase remplac√©');
  }

  // === PASS 2: Remove proprietary imports ===
  const proprietaryImports = [
    /import\s*{\s*componentTagger\s*}\s*from\s*['"]lovable-tagger['"]\s*;?\n?/g,
    /import\s*[^;]*\s*from\s*['"]@lovable\/[^'"]*['"]\s*;?\n?/g,
    /import\s*[^;]*\s*from\s*['"]lovable-[^'"]*['"]\s*;?\n?/g,
  ];

  for (const pattern of proprietaryImports) {
    const before = cleaned;
    cleaned = cleaned.replace(pattern, '');
    if (cleaned !== before) changes.push('Import propri√©taire supprim√©');
  }

  // === PASS 3: Remove plugin usage in vite.config ===
  const pluginPatterns = [
    /mode\s*===\s*['"]development['"]\s*&&\s*componentTagger\(\)\s*,?\n?/g,
    /componentTagger\(\)\s*,?\n?/g,
  ];

  for (const pattern of pluginPatterns) {
    const before = cleaned;
    cleaned = cleaned.replace(pattern, '');
    if (cleaned !== before) changes.push('Plugin Lovable supprim√©');
  }

  // === PASS 4: Replace hardcoded Supabase project IDs ===
  const before3 = cleaned;
  cleaned = cleaned.replace(/[a-z]{20}\.supabase\.co/g, 'your-project.supabase.co');
  if (cleaned !== before3) changes.push('ID Supabase remplac√©');

  // === PASS 5: Replace exposed JWT tokens ===
  const before4 = cleaned;
  cleaned = cleaned.replace(/eyJ[A-Za-z0-9_-]{100,}\.[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+/g, 'YOUR_SUPABASE_KEY');
  if (cleaned !== before4) changes.push('Token JWT remplac√©');

  // === PASS 6: Replace Stripe keys ===
  const stripePatterns = [
    { pattern: /sk_live_[A-Za-z0-9]{20,}/g, replacement: 'sk_live_YOUR_KEY' },
    { pattern: /pk_live_[A-Za-z0-9]{20,}/g, replacement: 'pk_live_YOUR_KEY' },
  ];

  for (const { pattern, replacement } of stripePatterns) {
    const before = cleaned;
    cleaned = cleaned.replace(pattern, replacement);
    if (cleaned !== before) changes.push('Cl√© Stripe remplac√©e');
  }

  // === FINAL: Clean empty imports ===
  cleaned = cleaned.replace(/import\s*{\s*}\s*from\s*['"][^'"]*['"]\s*;?\n?/g, '');
  cleaned = cleaned.replace(/\n{3,}/g, '\n\n');

  return { cleaned, changes: [...new Set(changes)] };
}

/**
 * FAST sovereignty verification - samples files instead of checking all
 * Optimized to avoid CPU timeout in edge functions
 */
function verifySovereignty(files: Record<string, string>): SovereigntyCheck {
  const criticalIssues: string[] = [];
  const warnings: string[] = [];
  let score = 100;

  const criticalPatterns = [
    { pattern: /@\/integrations\/supabase/g, name: 'Import Supabase auto-g√©n√©r√©', penalty: 20 },
    { pattern: /lovable\.app|lovable\.dev|gptengineer\.app/gi, name: 'Domaine Lovable', penalty: 20 },
    { pattern: /eyJ[A-Za-z0-9_-]{100,}/g, name: 'Token JWT hardcod√©', penalty: 20 },
    { pattern: /sk_live_[A-Za-z0-9]+/g, name: 'Cl√© Stripe live expos√©e', penalty: 25 },
  ];

  const warningPatterns = [
    { pattern: /data-lov|data-gpt|data-bolt/g, name: 'Data attribute propri√©taire', penalty: 5 },
    { pattern: /componentTagger|lovable-tagger/g, name: 'Plugin Lovable', penalty: 10 },
  ];

  // FAST: Only check critical file types, and limit to first 50 files
  const entries = Object.entries(files);
  const sourceFiles = entries.filter(([path]) => 
    path.match(/\.(ts|tsx|js|jsx|json|html)$/) && 
    !path.includes('node_modules') &&
    !path.includes('_original')
  );
  
  // Sample: check max 50 files for speed
  const sample = sourceFiles.slice(0, 50);
  
  for (const [path, content] of sample) {
    for (const { pattern, name, penalty } of criticalPatterns) {
      const freshPattern = new RegExp(pattern.source, pattern.flags);
      if (freshPattern.test(content)) {
        criticalIssues.push(`${path}: ${name}`);
        score -= penalty;
      }
    }

    for (const { pattern, name, penalty } of warningPatterns) {
      const freshPattern = new RegExp(pattern.source, pattern.flags);
      if (freshPattern.test(content)) {
        warnings.push(`${path}: ${name}`);
        score -= penalty;
      }
    }
  }

  return {
    isClean: criticalIssues.length === 0,
    score: Math.max(0, Math.min(100, score)),
    criticalIssues,
    warnings,
  };
}

// ============================================
// SQL SCHEMA EXTRACTION FROM MIGRATIONS/TYPES
// ============================================

interface ExtractedTable {
  name: string;
  columns: { name: string; type: string; nullable: boolean; default?: string }[];
  primaryKey?: string;
  foreignKeys: { column: string; references: string; onDelete?: string }[];
  indexes: string[];
  rlsPolicies: string[];
}

interface ExtractedSchema {
  tables: ExtractedTable[];
  enums: { name: string; values: string[] }[];
  functions: { name: string; sql: string }[];
  triggers: { name: string; table: string; sql: string }[];
  rawMigrations: string[];
}

/**
 * Parse TypeScript types.ts to extract table schema
 */
function parseTypesFile(typesContent: string): ExtractedTable[] {
  const tables: ExtractedTable[] = [];
  
  // Match table definitions in Tables: { ... }
  const tablesMatch = typesContent.match(/Tables:\s*{([\s\S]*?)}\s*Views:/);
  if (!tablesMatch) return tables;
  
  const tablesBlock = tablesMatch[1];
  
  // Find each table block
  const tablePattern = /(\w+):\s*{\s*Row:\s*{([^}]+)}/g;
  let match;
  
  while ((match = tablePattern.exec(tablesBlock)) !== null) {
    const tableName = match[1];
    const rowContent = match[2];
    
    const columns: ExtractedTable['columns'] = [];
    
    // Parse columns
    const columnPattern = /(\w+):\s*([^|]+)(\|\s*null)?/g;
    let colMatch;
    
    while ((colMatch = columnPattern.exec(rowContent)) !== null) {
      const colName = colMatch[1].trim();
      let colType = colMatch[2].trim();
      const nullable = !!colMatch[3];
      
      // Map TypeScript types to PostgreSQL
      const typeMap: Record<string, string> = {
        'string': 'TEXT',
        'number': 'INTEGER',
        'boolean': 'BOOLEAN',
        'Json': 'JSONB',
        'unknown': 'INET',
      };
      
      // Handle uuid type
      if (colType === 'string' && (colName === 'id' || colName.endsWith('_id') || colName === 'user_id')) {
        colType = 'UUID';
      } else if (colType.includes('timestamp') || colName.includes('_at') || colName === 'created_at' || colName === 'updated_at') {
        colType = 'TIMESTAMP WITH TIME ZONE';
      } else if (typeMap[colType]) {
        colType = typeMap[colType];
      } else if (colType.startsWith('Database')) {
        // Enum type
        const enumMatch = colType.match(/Enums\["(\w+)"\]/);
        if (enumMatch) {
          colType = enumMatch[1].toUpperCase();
        }
      }
      
      columns.push({
        name: colName,
        type: colType,
        nullable,
        default: colName === 'id' ? 'gen_random_uuid()' : 
                 colName === 'created_at' ? 'now()' :
                 colName === 'updated_at' ? 'now()' : undefined
      });
    }
    
    if (columns.length > 0) {
      tables.push({
        name: tableName,
        columns,
        primaryKey: 'id',
        foreignKeys: [],
        indexes: [],
        rlsPolicies: []
      });
    }
  }
  
  return tables;
}

/**
 * Parse SQL migration files to extract full schema
 */
function parseMigrationFiles(migrations: { name: string; content: string }[]): ExtractedSchema {
  const schema: ExtractedSchema = {
    tables: [],
    enums: [],
    functions: [],
    triggers: [],
    rawMigrations: []
  };
  
  // Sort migrations by name (usually timestamp-based)
  const sortedMigrations = [...migrations].sort((a, b) => a.name.localeCompare(b.name));
  
  for (const migration of sortedMigrations) {
    schema.rawMigrations.push(`-- Migration: ${migration.name}\n${migration.content}`);
    
    // Extract ENUMs
    const enumPattern = /CREATE\s+TYPE\s+(?:public\.)?(\w+)\s+AS\s+ENUM\s*\(([^)]+)\)/gi;
    let match;
    while ((match = enumPattern.exec(migration.content)) !== null) {
      const enumName = match[1];
      const values = match[2].split(',').map(v => v.trim().replace(/'/g, ''));
      schema.enums.push({ name: enumName, values });
    }
    
    // Extract CREATE TABLE
    const tablePattern = /CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(?:public\.)?(\w+)\s*\(([\s\S]*?)\);/gi;
    while ((match = tablePattern.exec(migration.content)) !== null) {
      const tableName = match[1];
      const tableBody = match[2];
      
      const columns: ExtractedTable['columns'] = [];
      const foreignKeys: ExtractedTable['foreignKeys'] = [];
      let primaryKey: string | undefined;
      
      // Parse columns
      const lines = tableBody.split(',').map(l => l.trim());
      for (const line of lines) {
        // Skip constraints
        if (line.match(/^\s*(PRIMARY|FOREIGN|UNIQUE|CHECK|CONSTRAINT)/i)) {
          // Extract primary key
          const pkMatch = line.match(/PRIMARY\s+KEY\s*\((\w+)\)/i);
          if (pkMatch) primaryKey = pkMatch[1];
          
          // Extract foreign key
          const fkMatch = line.match(/FOREIGN\s+KEY\s*\((\w+)\)\s*REFERENCES\s+(?:public\.)?(\w+)/i);
          if (fkMatch) {
            foreignKeys.push({ column: fkMatch[1], references: fkMatch[2] });
          }
          continue;
        }
        
        // Parse column definition
        const colMatch = line.match(/^(\w+)\s+(\w+(?:\s+\w+)*(?:\([^)]+\))?)\s*(.*)?$/i);
        if (colMatch) {
          const colName = colMatch[1];
          const colType = colMatch[2].toUpperCase();
          const constraints = colMatch[3] || '';
          
          const nullable = !constraints.includes('NOT NULL');
          const defaultMatch = constraints.match(/DEFAULT\s+([^\s,]+)/i);
          const isPK = constraints.includes('PRIMARY KEY');
          
          if (isPK) primaryKey = colName;
          
          columns.push({
            name: colName,
            type: colType,
            nullable,
            default: defaultMatch ? defaultMatch[1] : undefined
          });
        }
      }
      
      if (columns.length > 0) {
        // Check if table already exists, merge if so
        const existingIndex = schema.tables.findIndex(t => t.name === tableName);
        if (existingIndex >= 0) {
          // Merge columns (ALTER TABLE ADD COLUMN scenarios)
          for (const col of columns) {
            if (!schema.tables[existingIndex].columns.find(c => c.name === col.name)) {
              schema.tables[existingIndex].columns.push(col);
            }
          }
        } else {
          schema.tables.push({
            name: tableName,
            columns,
            primaryKey,
            foreignKeys,
            indexes: [],
            rlsPolicies: []
          });
        }
      }
    }
    
    // Extract ALTER TABLE ADD COLUMN
    const alterPattern = /ALTER\s+TABLE\s+(?:public\.)?(\w+)\s+ADD\s+(?:COLUMN\s+)?(\w+)\s+(\w+(?:\s+\w+)*)/gi;
    while ((match = alterPattern.exec(migration.content)) !== null) {
      const tableName = match[1];
      const colName = match[2];
      const colType = match[3];
      
      const tableIndex = schema.tables.findIndex(t => t.name === tableName);
      if (tableIndex >= 0) {
        if (!schema.tables[tableIndex].columns.find(c => c.name === colName)) {
          schema.tables[tableIndex].columns.push({
            name: colName,
            type: colType.toUpperCase(),
            nullable: true
          });
        }
      }
    }
    
    // Extract RLS policies
    const policyPattern = /CREATE\s+POLICY\s+"([^"]+)"\s+ON\s+(?:public\.)?(\w+)\s+([\s\S]*?)(?:;|$)/gi;
    while ((match = policyPattern.exec(migration.content)) !== null) {
      const policyName = match[1];
      const tableName = match[2];
      const policyBody = match[3];
      
      const tableIndex = schema.tables.findIndex(t => t.name === tableName);
      if (tableIndex >= 0) {
        schema.tables[tableIndex].rlsPolicies.push(`CREATE POLICY "${policyName}" ON ${tableName} ${policyBody}`);
      }
    }
    
    // Extract functions
    const funcPattern = /CREATE\s+(?:OR\s+REPLACE\s+)?FUNCTION\s+(?:public\.)?(\w+)\s*\([^)]*\)([\s\S]*?)(?=CREATE|ALTER|$)/gi;
    while ((match = funcPattern.exec(migration.content)) !== null) {
      const funcName = match[1];
      const fullMatch = match[0];
      
      if (!schema.functions.find(f => f.name === funcName)) {
        schema.functions.push({ name: funcName, sql: fullMatch.trim() });
      }
    }
    
    // Extract triggers
    const triggerPattern = /CREATE\s+(?:OR\s+REPLACE\s+)?TRIGGER\s+(\w+)\s+([\s\S]*?)ON\s+(?:public\.)?(\w+)/gi;
    while ((match = triggerPattern.exec(migration.content)) !== null) {
      const triggerName = match[1];
      const triggerBody = match[2];
      const tableName = match[3];
      
      schema.triggers.push({ 
        name: triggerName, 
        table: tableName, 
        sql: match[0].trim() 
      });
    }
  }
  
  return schema;
}

/**
 * Generate complete SQL schema from extracted data
 */
function generateSQLSchema(schema: ExtractedSchema, fromTypes?: ExtractedTable[]): string {
  let sql = `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- SCH√âMA SQL G√âN√âR√â AUTOMATIQUEMENT
-- G√©n√©r√© par InoPay Liberation Pack
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- IMPORTANT: Ce sch√©ma est extrait automatiquement depuis:
-- 1. Les fichiers de migration Supabase existants
-- 2. Les types TypeScript (src/integrations/supabase/types.ts)
-- 
-- V√©rifiez et adaptez avant d'ex√©cuter sur votre base de donn√©es.

`;

  // If we have raw migrations, use them directly
  if (schema.rawMigrations.length > 0) {
    sql += `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- MIGRATIONS ORIGINALES NETTOY√âES
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

`;
    
    for (const migration of schema.rawMigrations) {
      // Clean Supabase-specific references
      let cleanedMigration = migration
        // Remove auth.uid() if no auth system
        .replace(/auth\.uid\(\)/g, 'current_user_id()')
        // Add function stub for current_user_id if needed
        .replace(/supabase_realtime/g, '-- supabase_realtime (disabled)')
        // Comment out Supabase-specific storage operations
        .replace(/(INSERT INTO storage\.buckets)/g, '-- $1')
        .replace(/(CREATE POLICY.*ON storage\.objects)/g, '-- $1');
      
      sql += cleanedMigration + '\n\n';
    }
    
    // Add helper function for auth
    sql += `
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- FONCTIONS D'AIDE (√† adapter selon votre syst√®me d'auth)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Fonction pour obtenir l'ID utilisateur courant
-- Adaptez selon votre syst√®me d'authentification
CREATE OR REPLACE FUNCTION current_user_id()
RETURNS UUID
LANGUAGE sql
STABLE
AS $$
  SELECT NULLIF(current_setting('app.current_user_id', true), '')::UUID
$$;

-- Alternative avec JWT (si vous utilisez PostgREST)
-- CREATE OR REPLACE FUNCTION current_user_id()
-- RETURNS UUID
-- LANGUAGE sql
-- STABLE
-- AS $$
--   SELECT NULLIF(current_setting('request.jwt.claims', true)::json->>'sub', '')::UUID
-- $$;

`;
  } else if (fromTypes && fromTypes.length > 0) {
    // Generate from types.ts if no migrations available
    sql += `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- SCH√âMA G√âN√âR√â DEPUIS TYPES.TS
-- (Aucune migration Supabase trouv√©e)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

`;
    
    // Generate enums
    for (const enumDef of schema.enums) {
      sql += `CREATE TYPE ${enumDef.name} AS ENUM (${enumDef.values.map(v => `'${v}'`).join(', ')});\n\n`;
    }
    
    // Generate tables
    for (const table of fromTypes) {
      sql += `-- Table: ${table.name}\n`;
      sql += `CREATE TABLE IF NOT EXISTS public.${table.name} (\n`;
      
      const colDefs = table.columns.map(col => {
        let def = `  ${col.name} ${col.type}`;
        if (!col.nullable) def += ' NOT NULL';
        if (col.default) def += ` DEFAULT ${col.default}`;
        return def;
      });
      
      if (table.primaryKey) {
        colDefs.push(`  PRIMARY KEY (${table.primaryKey})`);
      }
      
      sql += colDefs.join(',\n');
      sql += '\n);\n\n';
      
      // Enable RLS
      sql += `ALTER TABLE public.${table.name} ENABLE ROW LEVEL SECURITY;\n\n`;
      
      // Generate basic RLS policies
      sql += `-- RLS Policies pour ${table.name}\n`;
      sql += `CREATE POLICY "${table.name}_select_own" ON public.${table.name}
  FOR SELECT USING (user_id = current_user_id());\n`;
      sql += `CREATE POLICY "${table.name}_insert_own" ON public.${table.name}
  FOR INSERT WITH CHECK (user_id = current_user_id());\n`;
      sql += `CREATE POLICY "${table.name}_update_own" ON public.${table.name}
  FOR UPDATE USING (user_id = current_user_id());\n`;
      sql += `CREATE POLICY "${table.name}_delete_own" ON public.${table.name}
  FOR DELETE USING (user_id = current_user_id());\n\n`;
    }
    
    // Add helper function
    sql += `
-- Fonction pour obtenir l'ID utilisateur courant
CREATE OR REPLACE FUNCTION current_user_id()
RETURNS UUID
LANGUAGE sql
STABLE
AS $$
  SELECT NULLIF(current_setting('app.current_user_id', true), '')::UUID
$$;

-- Fonction de mise √† jour automatique de updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
`;
    
    // Add triggers for updated_at
    for (const table of fromTypes) {
      if (table.columns.find(c => c.name === 'updated_at')) {
        sql += `
CREATE TRIGGER update_${table.name}_updated_at
  BEFORE UPDATE ON public.${table.name}
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();
`;
      }
    }
  }
  
  return sql;
}

/**
 * Extract schema from project files
 */
function extractSchemaFromProject(
  files: Record<string, string>,
  providedSchema?: string
): { sql: string; source: string; tables: string[] } {
  // 1. Check for existing migrations in supabase/migrations/
  const migrationFiles: { name: string; content: string }[] = [];
  
  for (const [path, content] of Object.entries(files)) {
    if (path.startsWith('supabase/migrations/') && path.endsWith('.sql')) {
      migrationFiles.push({ 
        name: path.replace('supabase/migrations/', ''), 
        content: content as string 
      });
    }
  }
  
  // 2. Check for types.ts
  let typesContent = '';
  for (const [path, content] of Object.entries(files)) {
    if (path.includes('supabase/types.ts') || path.includes('integrations/supabase/types.ts')) {
      typesContent = content as string;
      break;
    }
  }
  
  // 3. Generate schema based on available sources
  if (migrationFiles.length > 0) {
    const schema = parseMigrationFiles(migrationFiles);
    const tablesFromTypes = typesContent ? parseTypesFile(typesContent) : [];
    
    return {
      sql: generateSQLSchema(schema, tablesFromTypes),
      source: `migrations (${migrationFiles.length} fichiers)`,
      tables: schema.tables.map(t => t.name)
    };
  } else if (typesContent) {
    const tables = parseTypesFile(typesContent);
    const schema: ExtractedSchema = {
      tables,
      enums: [],
      functions: [],
      triggers: [],
      rawMigrations: []
    };
    
    // Try to extract enums from types
    const enumMatch = typesContent.match(/Enums:\s*{([^}]+)}/);
    if (enumMatch) {
      const enumPattern = /(\w+):\s*\[([^\]]+)\]/g;
      let match;
      while ((match = enumPattern.exec(enumMatch[1])) !== null) {
        const values = match[2].split(',').map(v => v.trim().replace(/"/g, ''));
        schema.enums.push({ name: match[1], values });
      }
    }
    
    return {
      sql: generateSQLSchema(schema, tables),
      source: 'types.ts',
      tables: tables.map(t => t.name)
    };
  } else if (providedSchema) {
    return {
      sql: providedSchema,
      source: 'sch√©ma fourni',
      tables: []
    };
  }
  
  return {
    sql: `-- Aucun sch√©ma d√©tect√©
-- Ajoutez vos tables ici ou importez depuis votre base de donn√©es existante

-- Exemple:
-- CREATE TABLE users (
--   id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
--   email TEXT UNIQUE NOT NULL,
--   created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
-- );
`,
    source: 'aucun',
    tables: []
  };
}

// ============================================
// SQL SCHEMA VALIDATOR
// ============================================

interface SQLValidationResult {
  isValid: boolean;
  errors: SQLValidationError[];
  warnings: SQLValidationWarning[];
  stats: {
    tables: number;
    columns: number;
    foreignKeys: number;
    indexes: number;
    policies: number;
    functions: number;
    triggers: number;
  };
  dependencyGraph: Record<string, string[]>;
}

interface SQLValidationError {
  type: 'syntax' | 'reference' | 'circular' | 'missing_column' | 'duplicate' | 'type_mismatch';
  message: string;
  line?: number;
  context?: string;
  severity: 'error' | 'critical';
}

interface SQLValidationWarning {
  type: 'missing_rls' | 'missing_index' | 'nullable_fk' | 'no_default' | 'reserved_keyword';
  message: string;
  table?: string;
  column?: string;
}

/**
 * Validates SQL schema for syntax and dependency issues
 */
function validateSQLSchema(sql: string): SQLValidationResult {
  const errors: SQLValidationError[] = [];
  const warnings: SQLValidationWarning[] = [];
  const stats = {
    tables: 0,
    columns: 0,
    foreignKeys: 0,
    indexes: 0,
    policies: 0,
    functions: 0,
    triggers: 0
  };
  
  // Track defined objects
  const definedTables = new Set<string>();
  const definedEnums = new Set<string>();
  const definedFunctions = new Set<string>();
  const tableColumns: Record<string, Set<string>> = {};
  const dependencyGraph: Record<string, string[]> = {};
  const tablesWithRLS = new Set<string>();
  
  const lines = sql.split('\n');
  
  // === PASS 1: Extract all definitions ===
  
  // Extract ENUMs
  const enumPattern = /CREATE\s+TYPE\s+(?:public\.)?(\w+)\s+AS\s+ENUM/gi;
  let match;
  while ((match = enumPattern.exec(sql)) !== null) {
    definedEnums.add(match[1].toLowerCase());
  }
  
  // Extract tables and their columns
  const tablePattern = /CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(?:public\.)?(\w+)\s*\(([\s\S]*?)\);/gi;
  while ((match = tablePattern.exec(sql)) !== null) {
    const tableName = match[1].toLowerCase();
    const tableBody = match[2];
    
    definedTables.add(tableName);
    tableColumns[tableName] = new Set<string>();
    dependencyGraph[tableName] = [];
    stats.tables++;
    
    // Parse columns
    const columnLines = tableBody.split(',');
    for (const line of columnLines) {
      const trimmed = line.trim();
      
      // Skip constraints
      if (trimmed.match(/^\s*(PRIMARY|FOREIGN|UNIQUE|CHECK|CONSTRAINT)/i)) continue;
      
      // Extract column name
      const colMatch = trimmed.match(/^(\w+)\s+/);
      if (colMatch) {
        tableColumns[tableName].add(colMatch[1].toLowerCase());
        stats.columns++;
      }
      
      // Check for foreign key references
      const fkMatch = trimmed.match(/REFERENCES\s+(?:public\.)?(\w+)/i);
      if (fkMatch) {
        const referencedTable = fkMatch[1].toLowerCase();
        dependencyGraph[tableName].push(referencedTable);
        stats.foreignKeys++;
      }
    }
  }
  
  // Extract standalone FOREIGN KEY constraints
  const fkPattern = /ALTER\s+TABLE\s+(?:public\.)?(\w+)\s+ADD\s+(?:CONSTRAINT\s+\w+\s+)?FOREIGN\s+KEY\s*\([^)]+\)\s*REFERENCES\s+(?:public\.)?(\w+)/gi;
  while ((match = fkPattern.exec(sql)) !== null) {
    const fromTable = match[1].toLowerCase();
    const toTable = match[2].toLowerCase();
    
    if (!dependencyGraph[fromTable]) dependencyGraph[fromTable] = [];
    dependencyGraph[fromTable].push(toTable);
    stats.foreignKeys++;
  }
  
  // Extract functions
  const funcPattern = /CREATE\s+(?:OR\s+REPLACE\s+)?FUNCTION\s+(?:public\.)?(\w+)/gi;
  while ((match = funcPattern.exec(sql)) !== null) {
    definedFunctions.add(match[1].toLowerCase());
    stats.functions++;
  }
  
  // Extract triggers
  const triggerPattern = /CREATE\s+(?:OR\s+REPLACE\s+)?TRIGGER\s+(\w+)/gi;
  while ((match = triggerPattern.exec(sql)) !== null) {
    stats.triggers++;
  }
  
  // Extract indexes
  const indexPattern = /CREATE\s+(?:UNIQUE\s+)?INDEX/gi;
  while ((match = indexPattern.exec(sql)) !== null) {
    stats.indexes++;
  }
  
  // Extract RLS-enabled tables
  const rlsPattern = /ALTER\s+TABLE\s+(?:public\.)?(\w+)\s+ENABLE\s+ROW\s+LEVEL\s+SECURITY/gi;
  while ((match = rlsPattern.exec(sql)) !== null) {
    tablesWithRLS.add(match[1].toLowerCase());
  }
  
  // Extract policies
  const policyPattern = /CREATE\s+POLICY/gi;
  while ((match = policyPattern.exec(sql)) !== null) {
    stats.policies++;
  }
  
  // === PASS 2: Validate references ===
  
  // Check foreign key references
  for (const [table, deps] of Object.entries(dependencyGraph)) {
    for (const dep of deps) {
      if (!definedTables.has(dep) && dep !== 'auth.users' && !dep.startsWith('auth.')) {
        errors.push({
          type: 'reference',
          message: `Table "${table}" r√©f√©rence "${dep}" qui n'est pas d√©finie`,
          severity: 'error',
          context: `REFERENCES ${dep}`
        });
      }
    }
  }
  
  // Check for circular dependencies
  function detectCycle(table: string, visited: Set<string>, path: string[]): string[] | null {
    if (path.includes(table)) {
      return [...path, table];
    }
    if (visited.has(table)) return null;
    
    visited.add(table);
    path.push(table);
    
    for (const dep of (dependencyGraph[table] || [])) {
      const cycle = detectCycle(dep, visited, [...path]);
      if (cycle) return cycle;
    }
    
    return null;
  }
  
  const visitedForCycles = new Set<string>();
  for (const table of definedTables) {
    const cycle = detectCycle(table, new Set(), []);
    if (cycle && !visitedForCycles.has(cycle.join('->'))) {
      visitedForCycles.add(cycle.join('->'));
      errors.push({
        type: 'circular',
        message: `D√©pendance circulaire d√©tect√©e: ${cycle.join(' ‚Üí ')}`,
        severity: 'critical'
      });
    }
  }
  
  // Check trigger function references
  const triggerFuncPattern = /EXECUTE\s+(?:PROCEDURE|FUNCTION)\s+(?:public\.)?(\w+)/gi;
  while ((match = triggerFuncPattern.exec(sql)) !== null) {
    const funcName = match[1].toLowerCase();
    if (!definedFunctions.has(funcName)) {
      errors.push({
        type: 'reference',
        message: `Trigger r√©f√©rence la fonction "${funcName}" qui n'est pas d√©finie`,
        severity: 'error',
        context: `EXECUTE FUNCTION ${funcName}`
      });
    }
  }
  
  // Check policy table/column references
  const policyTablePattern = /CREATE\s+POLICY\s+"[^"]+"\s+ON\s+(?:public\.)?(\w+)/gi;
  while ((match = policyTablePattern.exec(sql)) !== null) {
    const tableName = match[1].toLowerCase();
    if (!definedTables.has(tableName)) {
      errors.push({
        type: 'reference',
        message: `Policy sur la table "${tableName}" qui n'existe pas`,
        severity: 'error'
      });
    }
  }
  
  // Check USING/WITH CHECK column references in policies
  const policyColumnPattern = /(?:USING|WITH\s+CHECK)\s*\(([^)]+)\)/gi;
  while ((match = policyColumnPattern.exec(sql)) !== null) {
    const condition = match[1];
    // Look for column references like "user_id = ..."
    const colRefs = condition.match(/\b(\w+)\s*(?:=|<>|IS|IN|LIKE)/gi);
    // We can't easily validate without knowing which table, skip detailed check
  }
  
  // === PASS 3: Syntax validation ===
  
  // Check for unbalanced parentheses
  let parenCount = 0;
  let lineNum = 0;
  for (const line of lines) {
    lineNum++;
    if (line.trim().startsWith('--')) continue; // Skip comments
    
    for (const char of line) {
      if (char === '(') parenCount++;
      if (char === ')') parenCount--;
      
      if (parenCount < 0) {
        errors.push({
          type: 'syntax',
          message: `Parenth√®se fermante sans ouvrante`,
          line: lineNum,
          severity: 'error'
        });
        parenCount = 0;
      }
    }
  }
  
  if (parenCount !== 0) {
    errors.push({
      type: 'syntax',
      message: `Parenth√®ses non √©quilibr√©es (${parenCount > 0 ? 'manque ' + parenCount + ' fermante(s)' : 'trop de fermantes'})`,
      severity: 'error'
    });
  }
  
  // Check for common syntax errors
  const syntaxPatterns = [
    { pattern: /,\s*\)/g, message: 'Virgule avant parenth√®se fermante' },
    { pattern: /\(\s*,/g, message: 'Virgule apr√®s parenth√®se ouvrante' },
    { pattern: /;;/g, message: 'Double point-virgule' },
    { pattern: /CREATE\s+TABLE[^(]+$/gm, message: 'CREATE TABLE sans parenth√®ses' },
  ];
  
  for (const { pattern, message } of syntaxPatterns) {
    if (pattern.test(sql)) {
      errors.push({
        type: 'syntax',
        message,
        severity: 'error'
      });
    }
  }
  
  // Check for reserved keywords used as identifiers
  const reservedKeywords = ['user', 'order', 'group', 'select', 'table', 'index', 'key', 'primary', 'foreign'];
  for (const [table, columns] of Object.entries(tableColumns)) {
    if (reservedKeywords.includes(table)) {
      warnings.push({
        type: 'reserved_keyword',
        message: `Nom de table "${table}" est un mot r√©serv√© SQL - encadrez avec des guillemets`,
        table
      });
    }
    for (const col of columns) {
      if (reservedKeywords.includes(col)) {
        warnings.push({
          type: 'reserved_keyword',
          message: `Colonne "${col}" dans "${table}" est un mot r√©serv√© SQL`,
          table,
          column: col
        });
      }
    }
  }
  
  // === PASS 4: Generate warnings ===
  
  // Check tables without RLS
  for (const table of definedTables) {
    if (!tablesWithRLS.has(table)) {
      warnings.push({
        type: 'missing_rls',
        message: `Table "${table}" n'a pas RLS activ√© - donn√©es potentiellement expos√©es`,
        table
      });
    }
  }
  
  // Check for tables without primary key
  for (const [table, columns] of Object.entries(tableColumns)) {
    if (!columns.has('id')) {
      // Check if there's an explicit PRIMARY KEY in the table definition
      const tableDefMatch = sql.match(new RegExp(`CREATE\\s+TABLE[^;]*${table}[^;]*PRIMARY\\s+KEY`, 'i'));
      if (!tableDefMatch) {
        warnings.push({
          type: 'no_default',
          message: `Table "${table}" pourrait ne pas avoir de cl√© primaire`,
          table
        });
      }
    }
  }
  
  // Check for timestamp columns without defaults
  const timestampPattern = /(\w+)\s+TIMESTAMP[^,\n]*(?!DEFAULT)/gi;
  // This is a simplified check, would need more context
  
  return {
    isValid: errors.filter(e => e.severity === 'critical').length === 0,
    errors,
    warnings,
    stats,
    dependencyGraph
  };
}

/**
 * Generate a human-readable validation report
 */
function generateValidationReport(validation: SQLValidationResult): string {
  let report = `# üîç Rapport de Validation du Sch√©ma SQL

## R√©sum√©

| M√©trique | Valeur |
|----------|--------|
| Statut | ${validation.isValid ? '‚úÖ Valide' : '‚ùå Erreurs critiques'} |
| Tables | ${validation.stats.tables} |
| Colonnes | ${validation.stats.columns} |
| Cl√©s √©trang√®res | ${validation.stats.foreignKeys} |
| Index | ${validation.stats.indexes} |
| Policies RLS | ${validation.stats.policies} |
| Fonctions | ${validation.stats.functions} |
| Triggers | ${validation.stats.triggers} |

`;

  if (validation.errors.length > 0) {
    report += `## ‚ùå Erreurs (${validation.errors.length})

`;
    for (const error of validation.errors) {
      const icon = error.severity === 'critical' ? 'üî¥' : 'üü†';
      report += `${icon} **${error.type.toUpperCase()}**: ${error.message}`;
      if (error.line) report += ` (ligne ${error.line})`;
      if (error.context) report += `\n   \`${error.context}\``;
      report += '\n\n';
    }
  }

  if (validation.warnings.length > 0) {
    report += `## ‚ö†Ô∏è Avertissements (${validation.warnings.length})

`;
    for (const warning of validation.warnings) {
      report += `- **${warning.type}**: ${warning.message}\n`;
    }
    report += '\n';
  }

  // Dependency graph visualization
  const deps = Object.entries(validation.dependencyGraph).filter(([_, v]) => v.length > 0);
  if (deps.length > 0) {
    report += `## üîó Graphe des D√©pendances

\`\`\`
`;
    for (const [table, references] of deps) {
      report += `${table} ‚Üí ${references.join(', ')}\n`;
    }
    report += `\`\`\`

### Ordre de cr√©ation sugg√©r√©

Pour √©viter les erreurs de r√©f√©rence, cr√©ez les tables dans cet ordre:

`;
    // Topological sort
    const order = topologicalSort(validation.dependencyGraph);
    order.forEach((table, i) => {
      report += `${i + 1}. \`${table}\`\n`;
    });
  }

  report += `
---

## üí° Recommandations

`;

  if (validation.warnings.some(w => w.type === 'missing_rls')) {
    report += `### S√©curit√© RLS

Activez Row Level Security sur toutes les tables contenant des donn√©es utilisateur:

\`\`\`sql
ALTER TABLE votre_table ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own data" ON votre_table
  FOR SELECT USING (user_id = current_user_id());
\`\`\`

`;
  }

  if (validation.warnings.some(w => w.type === 'reserved_keyword')) {
    report += `### Mots r√©serv√©s SQL

Encadrez les identifiants qui sont des mots r√©serv√©s avec des guillemets:

\`\`\`sql
CREATE TABLE "user" (...);  -- au lieu de: CREATE TABLE user
SELECT "order" FROM ...;    -- au lieu de: SELECT order
\`\`\`

`;
  }

  return report;
}

/**
 * Topological sort for dependency ordering
 */
function topologicalSort(graph: Record<string, string[]>): string[] {
  const visited = new Set<string>();
  const result: string[] = [];
  
  function visit(node: string) {
    if (visited.has(node)) return;
    visited.add(node);
    
    for (const dep of (graph[node] || [])) {
      if (!dep.startsWith('auth.')) { // Skip auth schema references
        visit(dep);
      }
    }
    
    result.push(node);
  }
  
  for (const node of Object.keys(graph)) {
    visit(node);
  }
  
  return result;
}

// ============================================
// EDGE FUNCTION TO EXPRESS CONVERTER - ADVANCED
// ============================================

interface EdgeFunctionInfo {
  name: string;
  content: string;
  originalContent: string;
  hasAuth: boolean;
  httpMethods: string[];
  envVars: string[];
  usesSupabase: boolean;
  usesStripe: boolean;
  usesResend: boolean;
  dependencies: string[];
  webhookDetected: boolean;
  webhookType?: 'stripe' | 'github' | 'twilio' | 'custom';
  businessLogicBlocks: { type: string; content: string }[];
}

interface WebhookMigrationInfo {
  type: string;
  signatureHeader: string;
  verificationMethod: string;
  reconfigurationGuide: string;
}

interface ConversionResult {
  routeFile: string;
  testFile: string;
  dependencies: string[];
  preservedLogicPercentage: number;
  manualTodosCount: number;
  webhookInfo?: WebhookMigrationInfo;
}

/**
 * Parse Edge Function with deep analysis
 */
function parseEdgeFunctionAdvanced(name: string, content: string): EdgeFunctionInfo {
  const envVars: string[] = [];
  const httpMethods: string[] = [];
  const dependencies: string[] = [];
  const businessLogicBlocks: { type: string; content: string }[] = [];

  // Extract environment variables
  const envMatches = content.matchAll(/Deno\.env\.get\(['"](\w+)['"]\)/g);
  for (const match of envMatches) {
    if (!envVars.includes(match[1])) {
      envVars.push(match[1]);
    }
  }

  // Detect HTTP methods
  if (/req\.method\s*===?\s*['"]GET['"]/i.test(content)) httpMethods.push('GET');
  if (/req\.method\s*===?\s*['"]POST['"]/i.test(content)) httpMethods.push('POST');
  if (/req\.method\s*===?\s*['"]PUT['"]/i.test(content)) httpMethods.push('PUT');
  if (/req\.method\s*===?\s*['"]DELETE['"]/i.test(content)) httpMethods.push('DELETE');
  if (/req\.method\s*===?\s*['"]PATCH['"]/i.test(content)) httpMethods.push('PATCH');
  if (httpMethods.length === 0) httpMethods.push('POST');

  // Detect features
  const hasAuth = /Authorization|auth\.getUser|supabase\.auth/i.test(content);
  const usesSupabase = /supabase|@supabase|createClient/i.test(content);
  const usesStripe = /Stripe|stripe/i.test(content);
  const usesResend = /Resend|resend/i.test(content);

  // Detect webhooks
  const webhookDetected = /webhook|signature|verify.*signature/i.test(content);
  let webhookType: 'stripe' | 'github' | 'twilio' | 'custom' | undefined;
  
  if (webhookDetected) {
    if (content.includes('stripe-signature') || content.includes('constructEvent')) {
      webhookType = 'stripe';
    } else if (content.includes('x-hub-signature') || content.includes('x-github')) {
      webhookType = 'github';
    } else if (content.includes('x-twilio-signature')) {
      webhookType = 'twilio';
    } else {
      webhookType = 'custom';
    }
  }

  // Extract business logic blocks
  const lines = content.split('\n');
  let inTryBlock = false;
  let currentBlockLines: string[] = [];
  let currentBlockType = 'general';

  for (const line of lines) {
    if (/\btry\s*{/.test(line)) {
      inTryBlock = true;
    }
    
    if (inTryBlock) {
      if (/supabase\.(from|rpc|storage)/.test(line)) {
        if (currentBlockLines.length > 0 && currentBlockType !== 'database') {
          businessLogicBlocks.push({ type: currentBlockType, content: currentBlockLines.join('\n') });
          currentBlockLines = [];
        }
        currentBlockType = 'database';
      } else if (/fetch\(|axios|http/i.test(line) && !line.includes('esm.sh')) {
        if (currentBlockLines.length > 0 && currentBlockType !== 'api-call') {
          businessLogicBlocks.push({ type: currentBlockType, content: currentBlockLines.join('\n') });
          currentBlockLines = [];
        }
        currentBlockType = 'api-call';
      } else if (/verifySignature|constructEvent|validateWebhook/i.test(line)) {
        if (currentBlockLines.length > 0) {
          businessLogicBlocks.push({ type: currentBlockType, content: currentBlockLines.join('\n') });
          currentBlockLines = [];
        }
        currentBlockType = 'webhook-validation';
      }
      currentBlockLines.push(line);
    }
    
    if (/}\s*catch/.test(line) && inTryBlock) {
      if (currentBlockLines.length > 0) {
        businessLogicBlocks.push({ type: currentBlockType, content: currentBlockLines.join('\n') });
      }
      inTryBlock = false;
      currentBlockLines = [];
      currentBlockType = 'general';
    }
  }

  // Build dependencies list
  if (usesSupabase) dependencies.push('@supabase/supabase-js');
  if (usesStripe) dependencies.push('stripe');
  if (usesResend) dependencies.push('resend');

  return {
    name,
    content,
    originalContent: content,
    hasAuth,
    httpMethods,
    envVars,
    usesSupabase,
    usesStripe,
    usesResend,
    dependencies,
    webhookDetected,
    webhookType,
    businessLogicBlocks
  };
}

/**
 * Convert Deno syntax to Node.js with 100% preservation
 */
function convertDenoToNodeComplete(denoCode: string): string {
  let nodeCode = denoCode;

  // 1. Remove Deno-specific imports
  nodeCode = nodeCode.replace(/import\s*"https:\/\/deno\.land\/x\/xhr[^"]*";?\n?/g, '');
  nodeCode = nodeCode.replace(/import\s*{\s*serve\s*}\s*from\s*"https:\/\/deno\.land\/std[^"]*\/http\/server\.ts";?\n?/g, '');
  
  // 2. Convert esm.sh imports to npm packages
  nodeCode = nodeCode.replace(
    /import\s*{\s*createClient\s*}\s*from\s*"https:\/\/esm\.sh\/@supabase\/supabase-js[^"]*";?\n?/g,
    "import { createClient } from '@supabase/supabase-js';\n"
  );
  nodeCode = nodeCode.replace(
    /import\s+(\w+)\s+from\s*"https:\/\/esm\.sh\/([^@][^"]+)@[^"]+";?\n?/g,
    "import $1 from '$2';\n"
  );
  nodeCode = nodeCode.replace(
    /import\s*{\s*([^}]+)\s*}\s*from\s*"https:\/\/esm\.sh\/([^@][^"]+)@[^"]+";?\n?/g,
    "import { $1 } from '$2';\n"
  );
  nodeCode = nodeCode.replace(
    /import\s+(\w+)\s+from\s*"https:\/\/esm\.sh\/([^"]+)";?\n?/g,
    "import $1 from '$2';\n"
  );

  // 3. Convert Deno.env.get to process.env
  nodeCode = nodeCode.replace(/Deno\.env\.get\(['"](\w+)['"]\)!?/g, 'process.env.$1');
  nodeCode = nodeCode.replace(/Deno\.env\.get\("(\w+)"\)!?/g, 'process.env.$1');

  // 4. Remove serve() wrapper - preserve the handler code
  const serveMatch = nodeCode.match(/serve\(async\s*\(req(?::\s*Request)?\)\s*=>\s*{([\s\S]*?)}\s*\);\s*$/);
  if (serveMatch) {
    nodeCode = nodeCode.replace(/serve\(async\s*\(req(?::\s*Request)?\)\s*=>\s*{/, '// Handler logic:');
    const lastServeClose = nodeCode.lastIndexOf('});');
    if (lastServeClose > -1) {
      nodeCode = nodeCode.slice(0, lastServeClose) + nodeCode.slice(lastServeClose + 3);
    }
  }

  // 5. Convert Response objects to Express res
  nodeCode = nodeCode.replace(
    /return new Response\(\s*null\s*,\s*{\s*headers:\s*corsHeaders\s*}\s*\)/g,
    'return res.status(204).end()'
  );
  nodeCode = nodeCode.replace(
    /return new Response\(\s*JSON\.stringify\(\s*{([^}]+)}\s*\)\s*,\s*{\s*status:\s*(\d+)[^}]*}\s*\)/g,
    'return res.status($2).json({$1})'
  );
  nodeCode = nodeCode.replace(
    /return new Response\(\s*JSON\.stringify\(([^)]+)\)\s*,\s*{[^}]*headers[^}]*}\s*\)/g,
    'return res.json($1)'
  );
  nodeCode = nodeCode.replace(
    /return new Response\(\s*JSON\.stringify\(([^)]+)\)\s*\)/g,
    'return res.json($1)'
  );
  nodeCode = nodeCode.replace(
    /new Response\(\s*([^,]+)\s*,\s*{\s*status:\s*(\d+)[^}]*}\s*\)/g,
    'res.status($2).send($1)'
  );

  // 6. Convert req.json() to req.body
  nodeCode = nodeCode.replace(/await\s+req\.json\(\)/g, 'req.body');
  
  // 7. Convert req.headers.get to req.headers
  nodeCode = nodeCode.replace(/req\.headers\.get\(['"]([^'"]+)['"]\)/g, "req.headers['$1']");

  // 8. Remove corsHeaders references
  nodeCode = nodeCode.replace(/,?\s*headers:\s*{\s*\.\.\.corsHeaders[^}]*}/g, '');
  nodeCode = nodeCode.replace(/,?\s*headers:\s*corsHeaders/g, '');

  // 9. Clean up CORS preflight check
  nodeCode = nodeCode.replace(
    /if\s*\(\s*req\.method\s*===?\s*['"]OPTIONS['"]\s*\)\s*{\s*return[^}]+}/g,
    '// CORS handled by middleware'
  );

  // 10. Remove corsHeaders constant definition
  nodeCode = nodeCode.replace(
    /const\s+corsHeaders\s*=\s*{[^}]+};\s*\n?/g,
    ''
  );

  return nodeCode;
}

/**
 * Generate webhook migration info
 */
function generateWebhookMigrationInfo(type: string, functionName: string): WebhookMigrationInfo {
  const configs: Record<string, WebhookMigrationInfo> = {
    stripe: {
      type: 'Stripe',
      signatureHeader: 'stripe-signature',
      verificationMethod: `stripe.webhooks.constructEvent(body, signature, webhookSecret)`,
      reconfigurationGuide: `## üîÑ Migration Webhook Stripe

### √âtapes de reconfiguration:

1. **Acc√©dez au Dashboard Stripe**
   - https://dashboard.stripe.com/webhooks

2. **Mettez √† jour l'URL du webhook**
   - Ancienne: \`https://xxx.supabase.co/functions/v1/${functionName}\`
   - Nouvelle: \`https://VOTRE_DOMAINE/api/${functionName.replace(/-/g, '_')}\`

3. **R√©cup√©rez le nouveau Webhook Secret**
   - Copiez le "Signing secret" (whsec_...)
   - Ajoutez-le √† votre .env: \`STRIPE_WEBHOOK_SECRET=whsec_...\`

4. **Testez avec Stripe CLI**
   \`\`\`bash
   stripe listen --forward-to localhost:3000/api/${functionName.replace(/-/g, '_')}
   \`\`\`

### Code de v√©rification Express:
\`\`\`typescript
const sig = req.headers['stripe-signature'];
const event = stripe.webhooks.constructEvent(
  req.body, // raw body
  sig,
  process.env.STRIPE_WEBHOOK_SECRET
);
\`\`\`
`
    },
    github: {
      type: 'GitHub',
      signatureHeader: 'x-hub-signature-256',
      verificationMethod: 'crypto.timingSafeEqual(expectedSig, actualSig)',
      reconfigurationGuide: `## üîÑ Migration Webhook GitHub

### √âtapes de reconfiguration:

1. **Acc√©dez aux Settings du repo**
   - Settings ‚Üí Webhooks ‚Üí Edit

2. **Mettez √† jour l'URL**
   - Nouvelle: \`https://VOTRE_DOMAINE/api/${functionName.replace(/-/g, '_')}\`

3. **Gardez le m√™me Secret ou r√©g√©n√©rez-le**
   - Ajoutez √† .env: \`GITHUB_WEBHOOK_SECRET=...\`

### Code de v√©rification Express:
\`\`\`typescript
import crypto from 'crypto';

const signature = req.headers['x-hub-signature-256'];
const hmac = crypto.createHmac('sha256', process.env.GITHUB_WEBHOOK_SECRET);
const digest = 'sha256=' + hmac.update(JSON.stringify(req.body)).digest('hex');
const valid = crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(digest));
\`\`\`
`
    },
    twilio: {
      type: 'Twilio',
      signatureHeader: 'x-twilio-signature',
      verificationMethod: 'twilio.validateRequest(authToken, signature, url, params)',
      reconfigurationGuide: `## üîÑ Migration Webhook Twilio

### √âtapes de reconfiguration:

1. **Acc√©dez √† la Console Twilio**
   - https://console.twilio.com

2. **Mettez √† jour les Webhook URLs**
   - Messaging ‚Üí Settings ‚Üí Webhook URL
   - Nouvelle: \`https://VOTRE_DOMAINE/api/${functionName.replace(/-/g, '_')}\`

### Code de v√©rification Express:
\`\`\`typescript
import twilio from 'twilio';

const valid = twilio.validateRequest(
  process.env.TWILIO_AUTH_TOKEN,
  req.headers['x-twilio-signature'],
  \`https://VOTRE_DOMAINE/api/${functionName.replace(/-/g, '_')}\`,
  req.body
);
\`\`\`
`
    },
    custom: {
      type: 'Custom',
      signatureHeader: 'x-webhook-signature',
      verificationMethod: 'HMAC-SHA256',
      reconfigurationGuide: `## üîÑ Migration Webhook Personnalis√©

### √âtapes g√©n√©rales:

1. **Identifiez le service source**
2. **Mettez √† jour l'URL de callback**
3. **Adaptez la v√©rification de signature**

### Pattern de v√©rification commun:
\`\`\`typescript
import crypto from 'crypto';

const signature = req.headers['x-webhook-signature'];
const hmac = crypto.createHmac('sha256', process.env.WEBHOOK_SECRET);
const digest = hmac.update(JSON.stringify(req.body)).digest('hex');
const valid = signature === digest;
\`\`\`
`
    }
  };

  return configs[type] || configs.custom;
}

/**
 * Generate test file for converted route
 */
function generateRouteTestFile(func: EdgeFunctionInfo, routeName: string): string {
  return `import request from 'supertest';
import express from 'express';
import { ${routeName}Router } from './${routeName}';

const app = express();
app.use(express.json());
app.use('/api/${func.name}', ${routeName}Router);

describe('${func.name} route', () => {
${func.httpMethods.filter(m => m !== 'OPTIONS').map(method => `
  describe('${method} /api/${func.name}', () => {
    it('should respond successfully', async () => {
      const response = await request(app)
        .${method.toLowerCase()}('/api/${func.name}')
        ${method !== 'GET' ? ".send({ test: true })" : ''}
        ${func.hasAuth ? ".set('Authorization', 'Bearer test-token')" : ''};
      
      expect(response.status).toBeLessThan(500);
    });
${func.hasAuth ? `
    it('should require authentication', async () => {
      const response = await request(app)
        .${method.toLowerCase()}('/api/${func.name}')
        ${method !== 'GET' ? ".send({ test: true })" : ''};
      
      expect(response.status).toBe(401);
    });
` : ''}
  });
`).join('\n')}
});
`;
}

/**
 * Convert to Express route with complete logic preservation
 */
function convertToExpressRouteComplete(func: EdgeFunctionInfo): ConversionResult {
  const routeName = func.name.replace(/-/g, '_');
  let manualTodosCount = 0;
  let preservedLogicPercentage = 100;

  // Convert the code
  const convertedCode = convertDenoToNodeComplete(func.content);

  // Build imports
  let imports = `import { Router, Request, Response } from 'express';
`;

  if (func.usesSupabase) {
    imports += `import { createClient } from '@supabase/supabase-js';
`;
  }
  if (func.usesStripe) {
    imports += `import Stripe from 'stripe';
`;
  }
  if (func.usesResend) {
    imports += `import { Resend } from 'resend';
`;
  }

  // Build initializations
  let inits = `
export const ${routeName}Router = Router();
`;

  if (func.usesSupabase) {
    inits += `
// Supabase client factory
const supabaseUrl = process.env.SUPABASE_URL || process.env.DATABASE_URL?.replace(/^postgresql:/, 'https:');
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_ANON_KEY;

function getSupabaseClient(authHeader?: string) {
  const options = authHeader ? { global: { headers: { Authorization: authHeader } } } : {};
  return createClient(supabaseUrl!, supabaseKey!, options);
}
`;
  }

  if (func.usesStripe) {
    inits += `
const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2023-10-16'
});
`;
  }

  if (func.usesResend) {
    inits += `
const resend = new Resend(process.env.RESEND_API_KEY);
`;
  }

  // Extract the main business logic from the converted code
  let businessLogic = '';
  
  const tryMatch = convertedCode.match(/try\s*{([\s\S]*?)}\s*catch/);
  if (tryMatch) {
    businessLogic = tryMatch[1]
      .trim()
      .split('\n')
      .map(line => '    ' + line)
      .join('\n');
  } else {
    const afterCorsMatch = convertedCode.match(/\/\/ CORS handled by middleware\s*([\s\S]*?)$/);
    if (afterCorsMatch) {
      businessLogic = afterCorsMatch[1]
        .trim()
        .split('\n')
        .map(line => '    ' + line)
        .join('\n');
    } else {
      let cleanedLogic = convertedCode
        .replace(/import[^;]+;?\n?/g, '')
        .replace(/const\s+\w+\s*=\s*{[^}]+};\s*\n?/g, '')
        .replace(/\/\/ Handler logic:/g, '')
        .trim();
      
      businessLogic = cleanedLogic
        .split('\n')
        .map(line => '    ' + line)
        .join('\n');
      
      manualTodosCount += 1;
      preservedLogicPercentage = 80;
    }
  }

  if (businessLogic.includes('TODO') || businessLogic.includes('// TODO')) {
    manualTodosCount += (businessLogic.match(/TODO/g) || []).length;
    preservedLogicPercentage = Math.max(50, preservedLogicPercentage - manualTodosCount * 5);
  }

  // Generate route handlers
  let handlers = '';
  
  for (const method of func.httpMethods.filter(m => m !== 'OPTIONS')) {
    const methodLower = method.toLowerCase();
    
    handlers += `
${routeName}Router.${methodLower}('/', async (req: Request, res: Response) => {
  try {
`;

    if (func.hasAuth) {
      handlers += `    const authHeader = req.headers.authorization;
    if (!authHeader?.startsWith('Bearer ')) {
      return res.status(401).json({ error: 'Authorization required' });
    }
`;
      if (func.usesSupabase) {
        handlers += `
    const supabase = getSupabaseClient(authHeader);
    const { data: { user }, error: userError } = await supabase.auth.getUser();
    if (userError || !user) {
      return res.status(401).json({ error: 'Invalid token' });
    }
`;
      }
    } else if (func.usesSupabase) {
      handlers += `    const supabase = getSupabaseClient();
`;
    }

    if (businessLogic.length > 50) {
      handlers += `
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // BUSINESS LOGIC (100% migrated from Edge Function)
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
${businessLogic}
`;
    } else {
      handlers += `
    const body = req.body;
    
    // TODO: Review migrated logic from original Edge Function
    // See: _original-edge-functions/${func.name}/index.ts
    //
    // Environment variables needed: ${func.envVars.join(', ') || 'none'}
    // Uses Supabase: ${func.usesSupabase}
    // Requires Auth: ${func.hasAuth}
    
    res.json({ 
      success: true, 
      message: 'Route ${func.name} migrated',
      body 
    });
`;
      manualTodosCount += 1;
      preservedLogicPercentage = 30;
    }

    handlers += `  } catch (error) {
    console.error('[${routeName}] Error:', error);
    res.status(500).json({ 
      error: error instanceof Error ? error.message : 'Internal server error',
      route: '${func.name}'
    });
  }
});
`;
  }

  const routeFile = imports + inits + handlers;
  const testFile = generateRouteTestFile(func, routeName);

  let webhookInfo: WebhookMigrationInfo | undefined;
  if (func.webhookDetected && func.webhookType) {
    webhookInfo = generateWebhookMigrationInfo(func.webhookType, func.name);
  }

  return {
    routeFile,
    testFile,
    dependencies: func.dependencies,
    preservedLogicPercentage,
    manualTodosCount,
    webhookInfo
  };
}

// ============================================
// SELF-HOSTED AUTH API GENERATOR
// ============================================

function generateSelfHostedAuthAPI(projectName: string): {
  indexTs: string;
  packageJson: string;
  dockerfile: string;
  tsconfigJson: string;
  schemaSql: string;
  dockerCompose: string;
  readme: string;
  migrateScript: string;
} {
  const indexTs = `import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import { Pool } from 'pg';
import jwt from 'jsonwebtoken';
import bcrypt from 'bcryptjs';
import { v4 as uuidv4 } from 'uuid';

const app = express();
const PORT = process.env.PORT || 3001;

const pool = new Pool({ connectionString: process.env.DATABASE_URL });

app.use(helmet());
app.use(cors({ origin: process.env.CORS_ORIGIN || '*', credentials: true }));
app.use(express.json());

const JWT_SECRET = process.env.JWT_SECRET!;
const JWT_EXPIRY = process.env.JWT_EXPIRY || '7d';
const REFRESH_EXPIRY = process.env.REFRESH_TOKEN_EXPIRY || '30d';

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'auth-api', timestamp: new Date().toISOString() });
});

// Sign Up
app.post('/auth/v1/signup', async (req, res) => {
  try {
    const { email, password, data } = req.body;
    if (!email || !password) {
      return res.status(400).json({ error: 'Email and password required' });
    }
    
    const existing = await pool.query('SELECT id FROM auth.users WHERE email = $1', [email.toLowerCase()]);
    if (existing.rows.length > 0) {
      return res.status(400).json({ error: 'User already registered' });
    }
    
    const hashedPassword = await bcrypt.hash(password, 12);
    const userId = uuidv4();
    
    await pool.query(
      \`INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, raw_user_meta_data, created_at, updated_at)
       VALUES ($1, $2, $3, NOW(), $4, NOW(), NOW())\`,
      [userId, email.toLowerCase(), hashedPassword, JSON.stringify(data || {})]
    );
    
    const accessToken = jwt.sign({ sub: userId, email: email.toLowerCase(), role: 'authenticated' }, JWT_SECRET, { expiresIn: JWT_EXPIRY });
    const refreshToken = jwt.sign({ sub: userId, type: 'refresh' }, JWT_SECRET, { expiresIn: REFRESH_EXPIRY });
    
    res.json({
      access_token: accessToken,
      token_type: 'bearer',
      expires_in: 3600,
      refresh_token: refreshToken,
      user: { id: userId, email: email.toLowerCase(), email_confirmed_at: new Date().toISOString(), user_metadata: data || {} }
    });
  } catch (error) {
    console.error('Signup error:', error);
    res.status(500).json({ error: 'Failed to create user' });
  }
});

// Sign In
app.post('/auth/v1/token', async (req, res) => {
  try {
    const { email, password, grant_type, refresh_token } = req.body;
    
    if (grant_type === 'refresh_token' && refresh_token) {
      try {
        const decoded = jwt.verify(refresh_token, JWT_SECRET) as { sub: string; type: string };
        if (decoded.type !== 'refresh') return res.status(401).json({ error: 'Invalid refresh token' });
        
        const userResult = await pool.query('SELECT * FROM auth.users WHERE id = $1', [decoded.sub]);
        if (userResult.rows.length === 0) return res.status(401).json({ error: 'User not found' });
        
        const user = userResult.rows[0];
        const accessToken = jwt.sign({ sub: user.id, email: user.email, role: 'authenticated' }, JWT_SECRET, { expiresIn: JWT_EXPIRY });
        const newRefreshToken = jwt.sign({ sub: user.id, type: 'refresh' }, JWT_SECRET, { expiresIn: REFRESH_EXPIRY });
        
        return res.json({
          access_token: accessToken, token_type: 'bearer', expires_in: 3600, refresh_token: newRefreshToken,
          user: { id: user.id, email: user.email, user_metadata: user.raw_user_meta_data || {} }
        });
      } catch { return res.status(401).json({ error: 'Invalid refresh token' }); }
    }
    
    if (!email || !password) return res.status(400).json({ error: 'Email and password required' });
    
    const result = await pool.query('SELECT * FROM auth.users WHERE email = $1', [email.toLowerCase()]);
    if (result.rows.length === 0) return res.status(401).json({ error: 'Invalid credentials' });
    
    const user = result.rows[0];
    const validPassword = await bcrypt.compare(password, user.encrypted_password);
    if (!validPassword) return res.status(401).json({ error: 'Invalid credentials' });
    
    const accessToken = jwt.sign({ sub: user.id, email: user.email, role: 'authenticated' }, JWT_SECRET, { expiresIn: JWT_EXPIRY });
    const refreshToken = jwt.sign({ sub: user.id, type: 'refresh' }, JWT_SECRET, { expiresIn: REFRESH_EXPIRY });
    
    await pool.query('UPDATE auth.users SET last_sign_in_at = NOW() WHERE id = $1', [user.id]);
    
    res.json({
      access_token: accessToken, token_type: 'bearer', expires_in: 3600, refresh_token: refreshToken,
      user: { id: user.id, email: user.email, email_confirmed_at: user.email_confirmed_at, user_metadata: user.raw_user_meta_data || {} }
    });
  } catch (error) { console.error('Login error:', error); res.status(500).json({ error: 'Authentication failed' }); }
});

// Get User
app.get('/auth/v1/user', async (req, res) => {
  try {
    const authHeader = req.headers.authorization;
    if (!authHeader?.startsWith('Bearer ')) return res.status(401).json({ error: 'No token provided' });
    
    const token = authHeader.split(' ')[1];
    const decoded = jwt.verify(token, JWT_SECRET) as { sub: string };
    
    const result = await pool.query('SELECT * FROM auth.users WHERE id = $1', [decoded.sub]);
    if (result.rows.length === 0) return res.status(401).json({ error: 'User not found' });
    
    const user = result.rows[0];
    res.json({ id: user.id, email: user.email, email_confirmed_at: user.email_confirmed_at, created_at: user.created_at, user_metadata: user.raw_user_meta_data || {} });
  } catch (error) { console.error('Get user error:', error); res.status(401).json({ error: 'Invalid token' }); }
});

// Sign Out
app.post('/auth/v1/logout', (req, res) => res.json({ success: true }));

app.listen(PORT, () => console.log(\\\`üîê Auth API running on port \\\${PORT}\\\`));
`;

  const packageJson = JSON.stringify({
    name: `${projectName}-auth`,
    version: "1.0.0",
    main: "dist/index.js",
    scripts: { dev: "tsx watch index.ts", build: "tsc", start: "node dist/index.js" },
    dependencies: {
      express: "^4.18.2", cors: "^2.8.5", helmet: "^7.1.0",
      pg: "^8.11.3", jsonwebtoken: "^9.0.2", bcryptjs: "^2.4.3", uuid: "^9.0.1"
    },
    devDependencies: {
      "@types/express": "^4.17.21", "@types/cors": "^2.8.17", "@types/node": "^20.10.0",
      "@types/jsonwebtoken": "^9.0.5", "@types/bcryptjs": "^2.4.6", "@types/uuid": "^9.0.7",
      tsx: "^4.7.0", typescript: "^5.3.0"
    }
  }, null, 2);

  const dockerfile = `FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY --from=builder /app/dist ./dist
ENV NODE_ENV=production
EXPOSE 3001
CMD ["node", "dist/index.js"]
`;

  const tsconfigJson = JSON.stringify({
    compilerOptions: {
      target: "ES2022", module: "commonjs", outDir: "./dist", rootDir: ".",
      strict: true, esModuleInterop: true, skipLibCheck: true, declaration: true
    },
    include: ["*.ts"],
    exclude: ["node_modules", "dist"]
  }, null, 2);

  const schemaSql = `-- Schema compatible avec Supabase Auth
-- √Ä ex√©cuter sur votre PostgreSQL

CREATE SCHEMA IF NOT EXISTS auth;

CREATE TABLE IF NOT EXISTS auth.users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email TEXT UNIQUE NOT NULL,
  encrypted_password TEXT NOT NULL,
  email_confirmed_at TIMESTAMP WITH TIME ZONE,
  phone TEXT,
  phone_confirmed_at TIMESTAMP WITH TIME ZONE,
  raw_user_meta_data JSONB DEFAULT '{}',
  raw_app_meta_data JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  last_sign_in_at TIMESTAMP WITH TIME ZONE
);

CREATE INDEX IF NOT EXISTS users_email_idx ON auth.users(email);

-- Fonction pour compatibilit√© avec RLS Supabase
CREATE OR REPLACE FUNCTION auth.uid()
RETURNS UUID
LANGUAGE sql
STABLE
AS $$
  SELECT NULLIF(current_setting('request.jwt.claims', true)::json->>'sub', '')::UUID
$$;

CREATE OR REPLACE FUNCTION auth.role()
RETURNS TEXT
LANGUAGE sql
STABLE
AS $$
  SELECT COALESCE(current_setting('request.jwt.claims', true)::json->>'role', 'anon')
$$;
`;

  const dockerCompose = `version: '3.8'

services:
  auth-api:
    build: .
    container_name: ${projectName}-auth
    restart: unless-stopped
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - JWT_SECRET=\${JWT_SECRET}
      - DATABASE_URL=\${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  app-network:
    external: true
`;

  const readme = `# üîê Service d'Authentification Autonome

Remplacement direct de Supabase Auth, compatible avec les JWT existants.

## D√©marrage rapide

\`\`\`bash
# Cr√©er le sch√©ma
psql -d votre_db -f schema.sql

# D√©marrer
docker compose up -d
\`\`\`

## Endpoints

| Endpoint | Description |
|----------|-------------|
| POST /auth/v1/signup | Inscription |
| POST /auth/v1/token | Connexion / Refresh |
| GET /auth/v1/user | Utilisateur courant |
| POST /auth/v1/logout | D√©connexion |

## Variables d'environnement

- \`JWT_SECRET\`: Cl√© secr√®te JWT (requise)
- \`DATABASE_URL\`: URL PostgreSQL
- \`JWT_EXPIRY\`: Dur√©e token (d√©faut: 7d)
- \`REFRESH_TOKEN_EXPIRY\`: Dur√©e refresh (d√©faut: 30d)
`;

  const migrateScript = `// Script de migration des utilisateurs Supabase
// Usage: npx tsx migrate-users.ts < users.json

import { Pool } from 'pg';
import fs from 'fs';

const pool = new Pool({ connectionString: process.env.DATABASE_URL });

async function migrateUsers() {
  const data = fs.readFileSync(0, 'utf-8'); // stdin
  const users = JSON.parse(data);
  
  console.log('Migrating ' + users.length + ' users...');
  
  for (const user of users) {
    try {
      await pool.query(
        'INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, raw_user_meta_data, created_at) VALUES ($1, $2, $3, $4, $5, $6) ON CONFLICT (id) DO NOTHING',
        [user.id, user.email, user.encrypted_password, user.email_confirmed_at, user.raw_user_meta_data, user.created_at]
      );
      console.log('‚úÖ Migrated: ' + user.email);
    } catch (err) {
      console.error('‚ùå Failed: ' + user.email, err);
    }
  }
  
  await pool.end();
  console.log('Migration complete!');
}

migrateUsers();
`;

  return { indexTs, packageJson, dockerfile, tsconfigJson, schemaSql, dockerCompose, readme, migrateScript };
}

/**
 * Generate auth client adapter for frontend
 */
function generateAuthClientAdapter(): string {
  return `/**
 * Auth Client Adapter
 * Drop-in replacement for Supabase auth client
 * Generated by InoPay Liberation Pack
 */

interface User {
  id: string;
  email: string;
  email_confirmed_at?: string;
  user_metadata?: Record<string, any>;
}

interface Session {
  access_token: string;
  refresh_token: string;
  expires_in: number;
  user: User;
}

interface AuthResponse {
  data: { user: User | null; session: Session | null };
  error: Error | null;
}

const AUTH_URL = import.meta.env.VITE_AUTH_URL || import.meta.env.VITE_API_URL || '';
const STORAGE_KEY = 'auth_session';

function getStoredSession(): Session | null {
  try {
    const stored = localStorage.getItem(STORAGE_KEY);
    return stored ? JSON.parse(stored) : null;
  } catch { return null; }
}

function storeSession(session: Session | null): void {
  if (session) {
    localStorage.setItem(STORAGE_KEY, JSON.stringify(session));
  } else {
    localStorage.removeItem(STORAGE_KEY);
  }
}

async function fetchAuth(endpoint: string, options: RequestInit = {}): Promise<any> {
  const session = getStoredSession();
  const headers: Record<string, string> = {
    'Content-Type': 'application/json',
    ...options.headers as Record<string, string>
  };
  
  if (session?.access_token) {
    headers['Authorization'] = 'Bearer ' + session.access_token;
  }
  
  const res = await fetch(AUTH_URL + '/auth/v1' + endpoint, { ...options, headers });
  return res.json();
}

export const authClient = {
  async signUp(email: string, password: string, metadata?: Record<string, any>): Promise<AuthResponse> {
    try {
      const data = await fetchAuth('/signup', {
        method: 'POST',
        body: JSON.stringify({ email, password, data: metadata })
      });
      
      if (data.error) return { data: { user: null, session: null }, error: new Error(data.error) };
      
      const session: Session = {
        access_token: data.access_token,
        refresh_token: data.refresh_token,
        expires_in: data.expires_in,
        user: data.user
      };
      
      storeSession(session);
      return { data: { user: data.user, session }, error: null };
    } catch (error) {
      return { data: { user: null, session: null }, error: error as Error };
    }
  },

  async signInWithPassword(email: string, password: string): Promise<AuthResponse> {
    try {
      const data = await fetchAuth('/token', {
        method: 'POST',
        body: JSON.stringify({ email, password, grant_type: 'password' })
      });
      
      if (data.error) return { data: { user: null, session: null }, error: new Error(data.error) };
      
      const session: Session = {
        access_token: data.access_token,
        refresh_token: data.refresh_token,
        expires_in: data.expires_in,
        user: data.user
      };
      
      storeSession(session);
      return { data: { user: data.user, session }, error: null };
    } catch (error) {
      return { data: { user: null, session: null }, error: error as Error };
    }
  },

  async signOut(): Promise<{ error: Error | null }> {
    try {
      await fetchAuth('/logout', { method: 'POST' });
      storeSession(null);
      return { error: null };
    } catch (error) {
      storeSession(null);
      return { error: error as Error };
    }
  },

  async getUser(): Promise<{ data: { user: User | null }; error: Error | null }> {
    try {
      const session = getStoredSession();
      if (!session) return { data: { user: null }, error: null };
      
      const data = await fetchAuth('/user');
      if (data.error) return { data: { user: null }, error: new Error(data.error) };
      
      return { data: { user: data }, error: null };
    } catch (error) {
      return { data: { user: null }, error: error as Error };
    }
  },

  async getSession(): Promise<{ data: { session: Session | null }; error: Error | null }> {
    const session = getStoredSession();
    return { data: { session }, error: null };
  },

  onAuthStateChange(callback: (event: string, session: Session | null) => void): { data: { subscription: { unsubscribe: () => void } } } {
    const session = getStoredSession();
    callback(session ? 'SIGNED_IN' : 'SIGNED_OUT', session);
    
    // Listen for storage changes (cross-tab sync)
    const handler = (e: StorageEvent) => {
      if (e.key === STORAGE_KEY) {
        const newSession = e.newValue ? JSON.parse(e.newValue) : null;
        callback(newSession ? 'SIGNED_IN' : 'SIGNED_OUT', newSession);
      }
    };
    
    window.addEventListener('storage', handler);
    return { data: { subscription: { unsubscribe: () => window.removeEventListener('storage', handler) } } };
  }
};

// Export for compatibility with existing code
export const supabase = { auth: authClient };
export default authClient;
`;
}

function generateExpressBackend(functions: EdgeFunctionInfo[]): {
  routes: { 
    name: string; 
    content: string; 
    testFile?: string;
    webhookInfo?: WebhookMigrationInfo;
    preservedLogicPercentage: number;
    manualTodosCount: number;
  }[];
  indexTs: string;
  packageJson: string;
  tsconfigJson: string;
  middlewareAuth: string;
} {
  const conversionResults = functions.map(func => ({
    func,
    result: convertToExpressRouteComplete(func)
  }));

  const routes = conversionResults.map(({ func, result }) => ({
    name: func.name.replace(/-/g, '_'),
    content: result.routeFile,
    testFile: result.testFile,
    webhookInfo: result.webhookInfo,
    preservedLogicPercentage: result.preservedLogicPercentage,
    manualTodosCount: result.manualTodosCount
  }));

  const allEnvVars = new Set<string>(['PORT', 'DATABASE_URL', 'JWT_SECRET']);
  functions.forEach(f => f.envVars.forEach((v: string) => allEnvVars.add(v)));

  // Middleware d'authentification
  const middlewareAuth = `import { Request, Response, NextFunction } from 'express';
import jwt from 'jsonwebtoken';

export interface AuthenticatedRequest extends Request {
  user?: { id: string; email: string };
}

export const authMiddleware = async (
  req: AuthenticatedRequest, 
  res: Response, 
  next: NextFunction
) => {
  try {
    const authHeader = req.headers.authorization;
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ error: 'Authorization header required' });
    }
    
    const token = authHeader.split(' ')[1];
    const decoded = jwt.verify(token, process.env.JWT_SECRET!) as { sub: string; email: string };
    
    req.user = { id: decoded.sub, email: decoded.email };
    next();
  } catch (error) {
    return res.status(401).json({ error: 'Invalid token' });
  }
};

export const optionalAuth = async (
  req: AuthenticatedRequest, 
  res: Response, 
  next: NextFunction
) => {
  try {
    const authHeader = req.headers.authorization;
    
    if (authHeader?.startsWith('Bearer ')) {
      const token = authHeader.split(' ')[1];
      const decoded = jwt.verify(token, process.env.JWT_SECRET!) as { sub: string; email: string };
      req.user = { id: decoded.sub, email: decoded.email };
    }
    
    next();
  } catch {
    next();
  }
};
`;

  const indexTs = `import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import dotenv from 'dotenv';
import { rateLimit } from 'express-rate-limit';

dotenv.config();

${routes.map(r => `import { ${r.name}Router } from './routes/${r.name}';`).join('\n')}

const app = express();
const PORT = process.env.PORT || 3000;

// S√©curit√©
app.use(helmet());
app.use(cors({
  origin: process.env.CORS_ORIGIN || '*',
  credentials: true
}));

// Rate limiting
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // 100 requ√™tes par fen√™tre
  standardHeaders: true,
  legacyHeaders: false
});
app.use('/api/', limiter);

// Body parsing
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true }));

// Health check
app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    version: process.env.npm_package_version || '1.0.0'
  });
});

// Routes API
${routes.map(r => `app.use('/api/${r.name.replace(/_/g, '-')}', ${r.name}Router);`).join('\n')}

// 404 handler
app.use((req, res) => {
  res.status(404).json({ 
    error: 'Not found',
    path: req.path,
    availableRoutes: [${routes.map(r => `'/api/${r.name.replace(/_/g, '-')}'`).join(', ')}]
  });
});

// Error handler
app.use((err: Error, req: express.Request, res: express.Response, next: express.NextFunction) => {
  console.error('Unhandled error:', err);
  res.status(500).json({ 
    error: 'Internal Server Error',
    message: process.env.NODE_ENV === 'development' ? err.message : undefined
  });
});

app.listen(PORT, () => {
  console.log(\`üöÄ Backend server running on port \${PORT}\`);
  console.log(\`üìç Health check: http://localhost:\${PORT}/health\`);
  console.log(\`üìÇ Available routes:\`);
${routes.map(r => `  console.log(\`   - /api/${r.name.replace(/_/g, '-')}\`);`).join('\n')}
});

export default app;
`;

  const packageJson = JSON.stringify({
    name: "sovereign-backend-api",
    version: "1.0.0",
    description: "Backend API souverain - Converti depuis Supabase Edge Functions",
    main: "dist/index.js",
    scripts: {
      dev: "tsx watch src/index.ts",
      build: "tsc",
      start: "node dist/index.js",
      typecheck: "tsc --noEmit",
      lint: "eslint src --ext .ts"
    },
    dependencies: {
      express: "^4.18.2",
      cors: "^2.8.5",
      helmet: "^7.1.0",
      dotenv: "^16.3.1",
      "express-rate-limit": "^7.1.5",
      "@supabase/supabase-js": "^2.39.0",
      jsonwebtoken: "^9.0.2",
      pg: "^8.11.3",
      stripe: "^14.10.0",
      resend: "^2.1.0"
    },
    devDependencies: {
      "@types/express": "^4.17.21",
      "@types/cors": "^2.8.17",
      "@types/node": "^20.10.0",
      "@types/jsonwebtoken": "^9.0.5",
      "@types/pg": "^8.10.9",
      tsx: "^4.7.0",
      typescript: "^5.3.0",
      eslint: "^8.56.0",
      "@typescript-eslint/eslint-plugin": "^6.18.0",
      "@typescript-eslint/parser": "^6.18.0"
    },
    engines: { node: ">=18.0.0" }
  }, null, 2);

  const tsconfigJson = JSON.stringify({
    compilerOptions: {
      target: "ES2022",
      module: "commonjs",
      lib: ["ES2022"],
      outDir: "./dist",
      rootDir: "./src",
      strict: true,
      esModuleInterop: true,
      skipLibCheck: true,
      forceConsistentCasingInFileNames: true,
      resolveJsonModule: true,
      declaration: true,
      sourceMap: true
    },
    include: ["src/**/*"],
    exclude: ["node_modules", "dist"]
  }, null, 2);

  return { routes, indexTs, packageJson, tsconfigJson, middlewareAuth };
}

// ============================================
// POST-DEPLOYMENT CHECKLIST GENERATOR
// ============================================

interface ServiceCheck {
  name: string;
  type: 'http' | 'database' | 'api' | 'webhook' | 'storage' | 'auth';
  endpoint: string;
  method?: 'GET' | 'POST' | 'HEAD';
  expectedStatus?: number;
  timeout?: number;
  description: string;
  critical: boolean;
}

function generatePostDeploymentChecklist(
  projectName: string,
  hasBackend: boolean,
  hasDatabase: boolean,
  hasAuth: boolean,
  backendRoutes: string[] = [],
  webhooks: { name: string; type: string }[] = [],
  envVars: string[] = []
): string {
  // Build service checks
  const checks: ServiceCheck[] = [
    {
      name: 'Frontend',
      type: 'http',
      endpoint: '/',
      method: 'GET',
      expectedStatus: 200,
      description: 'V√©rification que le frontend est accessible',
      critical: true
    },
    {
      name: 'Health Check',
      type: 'api',
      endpoint: '/health',
      method: 'GET',
      expectedStatus: 200,
      description: 'Endpoint de sant√© du serveur',
      critical: true
    }
  ];

  if (hasBackend) {
    backendRoutes.slice(0, 10).forEach(route => {
      checks.push({
        name: 'API: ' + route,
        type: 'api',
        endpoint: '/api/' + route,
        method: 'GET',
        description: 'Endpoint ' + route,
        critical: false
      });
    });
  }

  if (hasAuth) {
    checks.push({
      name: 'Auth Service',
      type: 'auth',
      endpoint: '/auth/v1/health',
      method: 'GET',
      description: "Service d'authentification",
      critical: true
    });
  }

  if (hasDatabase) {
    checks.push({
      name: 'Database',
      type: 'database',
      endpoint: '/api/health?check=db',
      method: 'GET',
      description: 'Connexion √† la base de donn√©es',
      critical: true
    });
  }

  const checksJson = JSON.stringify(checks);
  const envVarsJson = JSON.stringify(envVars);
  const webhooksJson = JSON.stringify(webhooks.map(w => ({ ...w, url: '/api/' + w.name.replace(/-/g, '_') })));

  return `<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Checklist Post-D√©ploiement - ${projectName}</title>
  <style>
    :root { --primary: #6366f1; --success: #22c55e; --warning: #f59e0b; --danger: #ef4444; --info: #3b82f6; --bg: #0f172a; --bg-card: #1e293b; --text: #e2e8f0; --text-muted: #94a3b8; --border: #334155; }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: system-ui, sans-serif; background: var(--bg); color: var(--text); line-height: 1.6; min-height: 100vh; }
    .container { max-width: 1100px; margin: 0 auto; padding: 2rem; }
    header { text-align: center; padding: 2.5rem; background: linear-gradient(135deg, var(--primary), #4f46e5); border-radius: 1.5rem; margin-bottom: 2rem; }
    header h1 { font-size: 2rem; margin-bottom: 0.5rem; }
    .config-section { background: var(--bg-card); border-radius: 1rem; padding: 1.5rem; margin-bottom: 1.5rem; border: 1px solid var(--border); }
    .config-section h3 { color: #818cf8; margin-bottom: 1rem; display: flex; align-items: center; gap: 0.5rem; }
    .input-group { display: flex; gap: 1rem; flex-wrap: wrap; }
    .input-group label { flex: 1; min-width: 200px; }
    .input-group label span { display: block; font-size: 0.875rem; color: var(--text-muted); margin-bottom: 0.25rem; }
    input[type="text"], input[type="url"] { width: 100%; padding: 0.75rem 1rem; background: var(--bg); border: 1px solid var(--border); border-radius: 0.5rem; color: var(--text); font-size: 1rem; }
    input:focus { outline: none; border-color: var(--primary); box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.2); }
    .btn { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.875rem 1.5rem; border: none; border-radius: 0.75rem; font-size: 1rem; font-weight: 600; cursor: pointer; transition: all 0.2s; }
    .btn-primary { background: var(--primary); color: white; }
    .btn-primary:hover { background: #818cf8; }
    .btn-primary:disabled { opacity: 0.5; cursor: not-allowed; }
    .btn-outline { background: transparent; border: 2px solid var(--border); color: var(--text); }
    .btn-outline:hover { border-color: var(--primary); color: var(--primary); }
    .actions { display: flex; gap: 1rem; margin: 1.5rem 0; flex-wrap: wrap; }
    .stats-bar { display: grid; grid-template-columns: repeat(auto-fit, minmax(130px, 1fr)); gap: 1rem; margin-bottom: 1.5rem; }
    .stat-card { background: var(--bg-card); border-radius: 1rem; padding: 1.25rem; text-align: center; border: 1px solid var(--border); }
    .stat-card .value { font-size: 1.75rem; font-weight: 700; }
    .stat-card .label { color: var(--text-muted); font-size: 0.875rem; }
    .stat-card.success .value { color: var(--success); }
    .stat-card.danger .value { color: var(--danger); }
    .checks-grid { display: grid; gap: 1rem; }
    .check-card { background: var(--bg-card); border-radius: 1rem; padding: 1.25rem; border: 1px solid var(--border); transition: all 0.3s; }
    .check-card.running { border-color: var(--info); animation: pulse 1.5s infinite; }
    .check-card.success { border-color: var(--success); }
    .check-card.failed { border-color: var(--danger); }
    @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
    .check-header { display: flex; align-items: center; gap: 1rem; margin-bottom: 0.75rem; }
    .check-icon { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 1.25rem; flex-shrink: 0; background: rgba(148, 163, 184, 0.2); }
    .check-card.success .check-icon { background: rgba(34, 197, 94, 0.2); }
    .check-card.failed .check-icon { background: rgba(239, 68, 68, 0.2); }
    .check-card.running .check-icon { background: rgba(59, 130, 246, 0.2); }
    .check-info { flex: 1; }
    .check-info h4 { margin-bottom: 0.25rem; }
    .check-info p { color: var(--text-muted); font-size: 0.875rem; }
    .check-badge { padding: 0.25rem 0.75rem; border-radius: 1rem; font-size: 0.75rem; font-weight: 600; text-transform: uppercase; }
    .badge-critical { background: rgba(239, 68, 68, 0.2); color: var(--danger); }
    .badge-optional { background: rgba(148, 163, 184, 0.2); color: var(--text-muted); }
    .check-details { background: var(--bg); border-radius: 0.5rem; padding: 1rem; font-family: monospace; font-size: 0.8rem; margin-top: 0.75rem; }
    .check-details .endpoint { color: var(--info); }
    .check-details .error { color: var(--danger); }
    .check-details .timing { color: var(--text-muted); }
    .section-title { display: flex; align-items: center; gap: 0.75rem; margin: 2rem 0 1rem; font-size: 1.25rem; }
    .progress-bar { height: 6px; background: var(--border); border-radius: 3px; overflow: hidden; margin: 1rem 0; display: none; }
    .progress-fill { height: 100%; background: linear-gradient(90deg, var(--primary), var(--success)); transition: width 0.3s; }
    .log-panel { background: #0d1117; border-radius: 1rem; padding: 1.5rem; margin-top: 2rem; border: 1px solid var(--border); max-height: 300px; overflow-y: auto; }
    .log-panel h3 { margin-bottom: 1rem; }
    .log-entry { font-family: monospace; font-size: 0.8rem; padding: 0.375rem 0; border-bottom: 1px solid var(--border); }
    .log-entry .time { color: var(--text-muted); }
    .log-entry.success { color: var(--success); }
    .log-entry.error { color: var(--danger); }
    .summary-card { background: var(--bg-card); border-radius: 1.5rem; padding: 2rem; margin-top: 2rem; border: 1px solid var(--border); text-align: center; display: none; }
    .summary-card .score { font-size: 3.5rem; font-weight: 700; margin: 1rem 0; }
    .summary-card .score.good { color: var(--success); }
    .summary-card .score.medium { color: var(--warning); }
    .summary-card .score.bad { color: var(--danger); }
    .retry-btn { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.5rem 1rem; background: rgba(99, 102, 241, 0.2); border: 1px solid var(--primary); border-radius: 0.5rem; color: var(--primary); font-size: 0.875rem; cursor: pointer; margin-top: 0.5rem; }
    footer { text-align: center; padding: 2rem; color: var(--text-muted); font-size: 0.875rem; }
    @media (max-width: 768px) { .container { padding: 1rem; } .input-group, .actions { flex-direction: column; } .btn { width: 100%; justify-content: center; } }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>‚úÖ Checklist Post-D√©ploiement</h1>
      <p>${projectName} - V√©rification automatique des services</p>
    </header>
    
    <section class="config-section">
      <h3>‚öôÔ∏è Configuration</h3>
      <div class="input-group">
        <label><span>URL de base</span><input type="url" id="baseUrl" placeholder="https://votre-domaine.com"></label>
        <label><span>JWT Token (optionnel)</span><input type="text" id="authToken" placeholder="eyJhbGciOiJIUzI1NiIs..."></label>
      </div>
    </section>
    
    <div class="actions">
      <button class="btn btn-primary" id="runAllBtn" onclick="runAllChecks()">üöÄ Lancer les v√©rifications</button>
      <button class="btn btn-outline" onclick="resetChecks()">üîÑ R√©initialiser</button>
      <button class="btn btn-outline" onclick="exportReport()">üìÑ Exporter</button>
    </div>
    
    <div class="progress-bar" id="progressBar"><div class="progress-fill" id="progressFill"></div></div>
    
    <div class="stats-bar">
      <div class="stat-card" id="statTotal"><div class="value">-</div><div class="label">Total</div></div>
      <div class="stat-card" id="statPassed"><div class="value">-</div><div class="label">R√©ussis</div></div>
      <div class="stat-card" id="statFailed"><div class="value">-</div><div class="label">√âchou√©s</div></div>
      <div class="stat-card" id="statTime"><div class="value">-</div><div class="label">Dur√©e</div></div>
    </div>
    
    <h2 class="section-title"><span>üîç</span> V√©rifications</h2>
    <div class="checks-grid" id="checksGrid"></div>
    
    <div class="log-panel"><h3>üìã Journal</h3><div id="logContainer"></div></div>
    <div class="summary-card" id="summaryCard"><h2>R√©sum√©</h2><div class="score" id="summaryScore">-</div><p id="summaryText"></p></div>
  </div>
  <footer><p>InoPay Liberation Pack</p></footer>
  
  <script>
    const checks = ${checksJson};
    const envVars = ${envVarsJson};
    const webhooks = ${webhooksJson};
    let results = [], startTime = null;
    
    function initUI() {
      document.getElementById('checksGrid').innerHTML = checks.map((c, i) => 
        '<div class="check-card pending" id="check-' + i + '">' +
        '<div class="check-header"><div class="check-icon">‚è≥</div>' +
        '<div class="check-info"><h4>' + c.name + '</h4><p>' + c.description + '</p></div>' +
        '<span class="check-badge ' + (c.critical ? 'badge-critical' : 'badge-optional') + '">' + (c.critical ? 'Critique' : 'Optionnel') + '</span></div>' +
        '<div class="check-details"><div class="endpoint">' + (c.method || 'GET') + ' ' + c.endpoint + '</div><div class="status">En attente...</div></div></div>'
      ).join('');
      updateStats();
    }
    
    function log(msg, type) {
      const c = document.getElementById('logContainer');
      const t = new Date().toLocaleTimeString();
      c.insertAdjacentHTML('afterbegin', '<div class="log-entry ' + type + '"><span class="time">[' + t + ']</span> ' + msg + '</div>');
    }
    
    function updateStats() {
      const total = checks.length, passed = results.filter(r => r.success).length, failed = results.filter(r => !r.success && r.done).length;
      const elapsed = startTime ? ((Date.now() - startTime) / 1000).toFixed(1) + 's' : '-';
      document.getElementById('statTotal').querySelector('.value').textContent = total;
      document.getElementById('statPassed').querySelector('.value').textContent = passed;
      document.getElementById('statFailed').querySelector('.value').textContent = failed;
      document.getElementById('statTime').querySelector('.value').textContent = elapsed;
      document.getElementById('statPassed').className = 'stat-card ' + (passed > 0 ? 'success' : '');
      document.getElementById('statFailed').className = 'stat-card ' + (failed > 0 ? 'danger' : '');
    }
    
    async function runCheck(i) {
      const c = checks[i], card = document.getElementById('check-' + i);
      const base = document.getElementById('baseUrl').value.replace(/\\/$/, '');
      const token = document.getElementById('authToken').value;
      if (!base) { log('‚ùå URL de base requise', 'error'); return { success: false, done: true }; }
      
      card.className = 'check-card running';
      card.querySelector('.check-icon').textContent = 'üîÑ';
      card.querySelector('.status').textContent = 'V√©rification...';
      
      try {
        const ctrl = new AbortController();
        const tid = setTimeout(() => ctrl.abort(), c.timeout || 10000);
        const headers = { 'Content-Type': 'application/json' };
        if (token && c.type === 'api') headers['Authorization'] = 'Bearer ' + token;
        
        const t0 = performance.now();
        const res = await fetch(base + c.endpoint, { method: c.method || 'GET', headers, signal: ctrl.signal });
        clearTimeout(tid);
        const ms = (performance.now() - t0).toFixed(0);
        const ok = res.status === (c.expectedStatus || 200) || (res.status >= 200 && res.status < 300);
        
        card.className = 'check-card ' + (ok ? 'success' : 'failed');
        card.querySelector('.check-icon').textContent = ok ? '‚úÖ' : '‚ùå';
        card.querySelector('.status').innerHTML = 'Status: <strong>' + res.status + '</strong><div class="timing">' + ms + 'ms</div>';
        log((ok ? '‚úÖ' : '‚ùå') + ' ' + c.name + ' - ' + res.status + ' (' + ms + 'ms)', ok ? 'success' : 'error');
        return { success: ok, status: res.status, time: ms, done: true };
      } catch (e) {
        const msg = e.name === 'AbortError' ? 'Timeout' : e.message;
        card.className = 'check-card failed';
        card.querySelector('.check-icon').textContent = '‚ùå';
        card.querySelector('.status').innerHTML = '<div class="error">' + msg + '</div><button class="retry-btn" onclick="retryCheck(' + i + ')">üîÑ R√©essayer</button>';
        log('‚ùå ' + c.name + ' - ' + msg, 'error');
        return { success: false, error: msg, done: true };
      }
    }
    
    async function runAllChecks() {
      const base = document.getElementById('baseUrl').value;
      if (!base) { log('‚ö†Ô∏è Entrez l\\'URL de base', 'warning'); document.getElementById('baseUrl').focus(); return; }
      document.getElementById('runAllBtn').disabled = true;
      document.getElementById('progressBar').style.display = 'block';
      document.getElementById('summaryCard').style.display = 'none';
      results = []; startTime = Date.now();
      log('üöÄ D√©marrage...', 'info');
      
      for (let i = 0; i < checks.length; i++) {
        results[i] = await runCheck(i);
        document.getElementById('progressFill').style.width = ((i + 1) / checks.length * 100) + '%';
        updateStats();
        await new Promise(r => setTimeout(r, 150));
      }
      showSummary();
      document.getElementById('runAllBtn').disabled = false;
      log('‚úÖ Termin√©', 'success');
    }
    
    async function retryCheck(i) { results[i] = await runCheck(i); updateStats(); showSummary(); }
    
    function showSummary() {
      const passed = results.filter(r => r.success).length;
      const score = Math.round((passed / checks.length) * 100);
      const cls = score >= 90 ? 'good' : score >= 60 ? 'medium' : 'bad';
      const msg = score === 100 ? 'üéâ Tous les services sont op√©rationnels!' : score >= 80 ? '‚úÖ La plupart des services fonctionnent.' : '‚ùå V√©rifiez la configuration.';
      document.getElementById('summaryScore').textContent = score + '%';
      document.getElementById('summaryScore').className = 'score ' + cls;
      document.getElementById('summaryText').textContent = msg;
      document.getElementById('summaryCard').style.display = 'block';
    }
    
    function resetChecks() { results = []; startTime = null; document.getElementById('progressBar').style.display = 'none'; document.getElementById('summaryCard').style.display = 'none'; document.getElementById('logContainer').innerHTML = ''; initUI(); log('üîÑ R√©initialis√©', 'info'); }
    
    function exportReport() {
      const r = { project: '${projectName}', url: document.getElementById('baseUrl').value, time: new Date().toISOString(), checks: checks.map((c, i) => ({ ...c, result: results[i] || {} })), score: Math.round((results.filter(r => r.success).length / checks.length) * 100) };
      const a = document.createElement('a');
      a.href = URL.createObjectURL(new Blob([JSON.stringify(r, null, 2)], { type: 'application/json' }));
      a.download = '${projectName.toLowerCase().replace(/[^a-z0-9]/g, '-')}-deploy-report.json';
      a.click();
      log('üìÑ Rapport export√©', 'success');
    }
    
    initUI();
    log('üëã Configurez l\\'URL puis lancez les v√©rifications', 'info');
  </script>
</body>
</html>`;
}

// ============================================
// DEPLOY GUIDE HTML GENERATOR - ENRICHI
// ============================================

function generateDeployGuide(
  projectName: string, 
  envVars: string[], 
  hasBackend: boolean, 
  hasDatabase: boolean, 
  sovereigntyScore: number,
  hasAI: boolean = false
): string {
  const envVarDescriptions: Record<string, { desc: string; required: boolean; example?: string }> = {
    'PORT': { desc: 'Port du serveur (d√©faut: 3000)', required: false, example: '3000' },
    'DATABASE_URL': { desc: 'URL PostgreSQL compl√®te', required: true, example: 'postgresql://user:pass@localhost:5432/db' },
    'POSTGRES_USER': { desc: 'Utilisateur PostgreSQL', required: true, example: 'app' },
    'POSTGRES_PASSWORD': { desc: 'Mot de passe PostgreSQL', required: true, example: '(g√©n√©r√© automatiquement)' },
    'POSTGRES_DB': { desc: 'Nom de la base', required: false, example: 'app' },
    'JWT_SECRET': { desc: 'Cl√© secr√®te JWT (32+ chars)', required: true, example: '(g√©n√©r√© automatiquement)' },
    'STRIPE_SECRET_KEY': { desc: 'Cl√© secr√®te Stripe', required: false, example: 'sk_live_...' },
    'STRIPE_WEBHOOK_SECRET': { desc: 'Secret webhook Stripe', required: false, example: 'whsec_...' },
    'RESEND_API_KEY': { desc: 'Cl√© API Resend (emails)', required: false, example: 're_...' },
    'OPENAI_API_KEY': { desc: 'Cl√© API OpenAI (ou vide si Ollama)', required: false },
    'OLLAMA_URL': { desc: 'URL Ollama local', required: false, example: 'http://ollama:11434' },
    'OLLAMA_MODEL': { desc: 'Mod√®le Ollama', required: false, example: 'llama2' },
    'AI_PROVIDER': { desc: 'Provider IA (ollama/openai/openrouter)', required: false, example: 'ollama' },
    'SUPABASE_URL': { desc: 'URL projet Supabase (si utilis√©)', required: false },
    'SUPABASE_ANON_KEY': { desc: 'Cl√© anonyme Supabase', required: false },
    'SUPABASE_SERVICE_ROLE_KEY': { desc: 'Cl√© service Supabase', required: false },
    'MEILISEARCH_MASTER_KEY': { desc: 'Cl√© master Meilisearch', required: false },
    'MINIO_ACCESS_KEY': { desc: 'Access key MinIO', required: false },
    'MINIO_SECRET_KEY': { desc: 'Secret key MinIO', required: false },
  };

  const scoreColor = sovereigntyScore >= 95 ? '#22c55e' : sovereigntyScore >= 80 ? '#f59e0b' : '#ef4444';
  const scoreEmoji = sovereigntyScore >= 95 ? '‚úÖ' : sovereigntyScore >= 80 ? '‚ö†Ô∏è' : '‚ùå';

  return `<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Guide de D√©ploiement - ${projectName}</title>
  <style>
    :root { 
      --primary: #6366f1; 
      --primary-light: #818cf8;
      --success: #22c55e; 
      --warning: #f59e0b; 
      --danger: #ef4444;
      --bg: #0f172a; 
      --bg-card: #1e293b; 
      --bg-code: #0d1117;
      --text: #e2e8f0; 
      --text-muted: #94a3b8;
      --border: #334155; 
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: system-ui, -apple-system, sans-serif; background: var(--bg); color: var(--text); line-height: 1.7; }
    .container { max-width: 1000px; margin: 0 auto; padding: 2rem; }
    
    header { text-align: center; margin-bottom: 3rem; padding: 3rem 2rem; background: linear-gradient(135deg, var(--primary), #4f46e5); border-radius: 1.5rem; position: relative; overflow: hidden; }
    header::before { content: ''; position: absolute; top: 0; left: 0; right: 0; bottom: 0; background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23ffffff' fill-opacity='0.05'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E"); }
    header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; position: relative; }
    header p { opacity: 0.9; font-size: 1.1rem; position: relative; }
    .sovereignty-badge { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.75rem 1.5rem; background: ${scoreColor}15; border: 2px solid ${scoreColor}; border-radius: 2rem; font-weight: 700; font-size: 1.1rem; color: ${scoreColor}; margin-top: 1.5rem; position: relative; backdrop-filter: blur(8px); }
    
    nav { background: var(--bg-card); border-radius: 1rem; padding: 1rem; margin-bottom: 2rem; border: 1px solid var(--border); position: sticky; top: 1rem; z-index: 100; }
    nav ul { display: flex; flex-wrap: wrap; gap: 0.5rem; list-style: none; justify-content: center; }
    nav a { color: var(--text-muted); text-decoration: none; padding: 0.5rem 1rem; border-radius: 0.5rem; transition: all 0.2s; font-size: 0.875rem; }
    nav a:hover { background: var(--primary); color: white; }
    
    section { background: var(--bg-card); border-radius: 1rem; padding: 2rem; margin-bottom: 1.5rem; border: 1px solid var(--border); }
    section h2 { display: flex; align-items: center; gap: 0.75rem; margin-bottom: 1.5rem; font-size: 1.5rem; }
    section h3 { margin: 2rem 0 1rem; color: var(--primary-light); font-size: 1.1rem; }
    .step-num { background: var(--primary); width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 1rem; flex-shrink: 0; }
    
    .code-block { position: relative; background: var(--bg-code); border-radius: 0.75rem; padding: 1.25rem; margin: 1rem 0; overflow-x: auto; border: 1px solid var(--border); }
    .code-block code { font-family: 'Fira Code', 'Monaco', monospace; font-size: 0.875rem; white-space: pre-wrap; color: #e6edf3; }
    .copy-btn { position: absolute; top: 0.75rem; right: 0.75rem; background: var(--primary); color: white; border: none; padding: 0.5rem 1rem; border-radius: 0.5rem; cursor: pointer; font-size: 0.75rem; font-weight: 600; transition: all 0.2s; }
    .copy-btn:hover { background: var(--primary-light); transform: scale(1.05); }
    .copy-btn.copied { background: var(--success); }
    
    .alert { padding: 1rem 1.25rem; border-radius: 0.75rem; margin: 1rem 0; display: flex; gap: 0.75rem; align-items: flex-start; }
    .alert-success { background: rgba(34, 197, 94, 0.1); border: 1px solid var(--success); }
    .alert-warning { background: rgba(245, 158, 11, 0.1); border: 1px solid var(--warning); }
    .alert-info { background: rgba(99, 102, 241, 0.1); border: 1px solid var(--primary); }
    .alert-danger { background: rgba(239, 68, 68, 0.1); border: 1px solid var(--danger); }
    .alert strong { display: block; margin-bottom: 0.25rem; }
    
    table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
    th, td { text-align: left; padding: 1rem; border-bottom: 1px solid var(--border); }
    th { background: var(--bg); font-weight: 600; color: var(--text-muted); text-transform: uppercase; font-size: 0.75rem; letter-spacing: 0.05em; }
    td code { background: var(--bg); padding: 0.25rem 0.5rem; border-radius: 0.375rem; font-size: 0.875rem; }
    tr:hover { background: rgba(99, 102, 241, 0.05); }
    
    .checklist { list-style: none; }
    .checklist li { display: flex; align-items: flex-start; gap: 1rem; padding: 1rem; border-bottom: 1px solid var(--border); transition: background 0.2s; }
    .checklist li:hover { background: rgba(99, 102, 241, 0.05); }
    .checklist li:last-child { border-bottom: none; }
    .checklist input { width: 22px; height: 22px; accent-color: var(--success); cursor: pointer; margin-top: 2px; flex-shrink: 0; }
    .checklist label { cursor: pointer; flex: 1; }
    
    .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 1rem; margin: 1rem 0; }
    .card { background: var(--bg); border-radius: 0.75rem; padding: 1.5rem; border: 1px solid var(--border); }
    .card h4 { color: var(--primary-light); margin-bottom: 0.5rem; display: flex; align-items: center; gap: 0.5rem; }
    .card p { color: var(--text-muted); font-size: 0.875rem; }
    
    .tabs { display: flex; gap: 0.5rem; margin-bottom: 1rem; flex-wrap: wrap; }
    .tab { padding: 0.75rem 1.25rem; background: var(--bg); border: 1px solid var(--border); border-radius: 0.5rem; cursor: pointer; transition: all 0.2s; }
    .tab:hover, .tab.active { background: var(--primary); border-color: var(--primary); color: white; }
    .tab-content { display: none; }
    .tab-content.active { display: block; }
    
    footer { text-align: center; padding: 3rem 2rem; color: var(--text-muted); font-size: 0.875rem; }
    footer a { color: var(--primary); text-decoration: none; }
    footer a:hover { text-decoration: underline; }
    
    @media (max-width: 768px) {
      .container { padding: 1rem; }
      header { padding: 2rem 1rem; }
      header h1 { font-size: 1.75rem; }
      section { padding: 1.5rem; }
      nav { position: static; }
      nav ul { flex-direction: column; }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>üöÄ ${projectName}</h1>
      <p>Guide de d√©ploiement autonome complet</p>
      <div class="sovereignty-badge">${scoreEmoji} Score de Souverainet√©: ${sovereigntyScore}%</div>
    </header>
    
    <nav>
      <ul>
        <li><a href="#prerequisites">Pr√©requis</a></li>
        <li><a href="#upload">Upload</a></li>
        <li><a href="#config">Configuration</a></li>
        <li><a href="#deploy">D√©ploiement</a></li>
        ${hasBackend ? '<li><a href="#webhooks">Webhooks</a></li>' : ''}
        ${hasAI ? '<li><a href="#ai">IA Open Source</a></li>' : ''}
        ${hasDatabase ? '<li><a href="#database">Base de donn√©es</a></li>' : ''}
        <li><a href="#verify">V√©rification</a></li>
        <li><a href="#troubleshoot">D√©pannage</a></li>
      </ul>
    </nav>
    
    <section id="prerequisites">
      <h2><span class="step-num">1</span> Pr√©requis</h2>
      <ul class="checklist">
        <li><input type="checkbox" id="check-vps"> <label for="check-vps"><strong>Serveur VPS</strong> - Ubuntu 22.04+ ou Debian 12+ avec acc√®s SSH root<br><span style="color: var(--text-muted); font-size: 0.875rem;">Recommand√©: 2GB RAM, 2 vCPU minimum. Hetzner, OVH, Scaleway...</span></label></li>
        <li><input type="checkbox" id="check-docker"> <label for="check-docker"><strong>Docker</strong> - Sera install√© automatiquement si absent</label></li>
        <li><input type="checkbox" id="check-domain"> <label for="check-domain"><strong>Domaine (optionnel)</strong> - Enregistrement A pointant vers l'IP du serveur pour HTTPS automatique</label></li>
        ${hasBackend ? '<li><input type="checkbox" id="check-stripe"> <label for="check-stripe"><strong>Compte Stripe (si paiements)</strong> - Cl√©s API et webhook configur√©s</label></li>' : ''}
      </ul>
      
      <div class="grid">
        <div class="card">
          <h4>üí° VPS √âconomique</h4>
          <p>Hetzner CX11 (~4‚Ç¨/mois), OVH Starter (~3‚Ç¨/mois), Scaleway DEV1-S (~5‚Ç¨/mois)</p>
        </div>
        <div class="card">
          <h4>üîí S√©curit√© recommand√©e</h4>
          <p>Cl√© SSH (pas de mot de passe), Firewall UFW, Fail2ban</p>
        </div>
      </div>
    </section>
    
    <section id="upload">
      <h2><span class="step-num">2</span> Upload & Extraction</h2>
      <div class="code-block"><code># Connexion au serveur
ssh root@VOTRE_IP

# Cr√©er le dossier et transf√©rer le ZIP
mkdir -p /opt/apps && cd /opt/apps

# Depuis votre machine locale (autre terminal):
scp liberation-pack.zip root@VOTRE_IP:/opt/apps/

# Retour sur le serveur - Extraction
cd /opt/apps
unzip liberation-pack.zip
cd ${projectName.toLowerCase().replace(/[^a-z0-9]/g, '-')}</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <div class="alert alert-info">
        üí° <strong>Alternative: T√©l√©chargement direct</strong><br>
        Si votre pack est h√©berg√© en ligne, utilisez: <code>wget URL_DU_ZIP && unzip liberation-pack.zip</code>
      </div>
    </section>
    
    <section id="config">
      <h2><span class="step-num">3</span> Configuration</h2>
      
      <h3>3.1 - Fichier d'environnement</h3>
      <div class="code-block"><code># Copier le template
cp .env.example .env

# √âditer avec nano ou vim
nano .env</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <h3>3.2 - Variables √† configurer</h3>
      <table>
        <thead><tr><th>Variable</th><th>Description</th><th>Requis</th><th>Exemple</th></tr></thead>
        <tbody>
          ${envVars.map(v => {
            const info = envVarDescriptions[v] || { desc: 'Variable personnalis√©e', required: false };
            return `<tr>
              <td><code>${v}</code></td>
              <td>${info.desc}</td>
              <td>${info.required ? '‚úÖ' : '‚ùå'}</td>
              <td><code>${info.example || '-'}</code></td>
            </tr>`;
          }).join('')}
        </tbody>
      </table>
      
      <div class="alert alert-warning">
        ‚ö†Ô∏è <strong>Important</strong><br>
        Les mots de passe et secrets seront g√©n√©r√©s automatiquement par le script quick-deploy.sh si vous les laissez vides.
      </div>
    </section>
    
    <section id="deploy">
      <h2><span class="step-num">4</span> D√©ploiement</h2>
      
      <div class="tabs">
        <button class="tab active" onclick="showTab('quick')">üöÄ M√©thode Rapide</button>
        <button class="tab" onclick="showTab('manual')">üîß Manuel</button>
      </div>
      
      <div id="tab-quick" class="tab-content active">
        <div class="code-block"><code># Rendre le script ex√©cutable et lancer
chmod +x scripts/quick-deploy.sh
sudo ./scripts/quick-deploy.sh</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
        <div class="alert alert-success">
          ‚úÖ <strong>Le script fait tout automatiquement:</strong><br>
          Installation Docker, g√©n√©ration des secrets, configuration firewall, d√©marrage des services
        </div>
      </div>
      
      <div id="tab-manual" class="tab-content">
        <div class="code-block"><code># 1. Installer Docker (si absent)
curl -fsSL https://get.docker.com | sh

# 2. G√©n√©rer les secrets
JWT_SECRET=$(openssl rand -base64 32)
POSTGRES_PASSWORD=$(openssl rand -base64 16)
echo "JWT_SECRET=$JWT_SECRET" >> .env
echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> .env

# 3. Construire et d√©marrer
docker compose up -d --build

# 4. V√©rifier le statut
docker compose ps</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      </div>
    </section>
    
    ${hasBackend ? `
    <section id="webhooks">
      <h2><span class="step-num">5</span> Configuration des Webhooks</h2>
      
      <div class="alert alert-warning">
        ‚ö†Ô∏è <strong>Action requise</strong><br>
        Si votre application utilise des webhooks (Stripe, GitHub, etc.), vous devez les reconfigurer pour pointer vers votre nouveau serveur.
      </div>
      
      <h3>üîó Webhook Stripe</h3>
      <ol style="padding-left: 1.5rem; line-height: 2;">
        <li>Connectez-vous √† votre <a href="https://dashboard.stripe.com/webhooks" target="_blank" style="color: var(--primary);">Dashboard Stripe</a></li>
        <li>Cliquez sur "Ajouter un endpoint"</li>
        <li>URL: <code>https://VOTRE_DOMAINE/api/stripe-webhook</code></li>
        <li>S√©lectionnez les √©v√©nements: <code>checkout.session.completed</code>, <code>customer.subscription.updated</code>, etc.</li>
        <li>Copiez le "Signing secret" (commence par <code>whsec_</code>)</li>
        <li>Ajoutez dans votre <code>.env</code>: <code>STRIPE_WEBHOOK_SECRET=whsec_...</code></li>
        <li>Red√©marrez: <code>docker compose restart backend</code></li>
      </ol>
      
      <h3>üîó Webhook GitHub</h3>
      <ol style="padding-left: 1.5rem; line-height: 2;">
        <li>Allez dans Settings > Webhooks de votre repo</li>
        <li>Payload URL: <code>https://VOTRE_DOMAINE/api/github-webhook</code></li>
        <li>Content type: <code>application/json</code></li>
        <li>Secret: G√©n√©rez et ajoutez dans <code>.env</code></li>
      </ol>
      
      <h3>üß™ Tester les webhooks en local</h3>
      <div class="code-block"><code># Avec ngrok (pour tests)
ngrok http 3000

# Avec Stripe CLI
stripe listen --forward-to localhost:3000/api/stripe-webhook</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
    </section>
    ` : ''}
    
    ${hasAI ? `
    <section id="ai">
      <h2><span class="step-num">6</span> IA Open Source avec Ollama</h2>
      
      <div class="alert alert-info">
        üí° <strong>Alternative gratuite √† OpenAI</strong><br>
        Ollama permet de faire tourner des mod√®les IA localement, sans API externe ni co√ªts r√©currents.
      </div>
      
      <h3>Installation</h3>
      <div class="code-block"><code># Ajouter Ollama √† votre stack (copier le contenu de services/ollama/docker-compose.yml)
# Puis:
docker compose up -d ollama

# T√©l√©charger un mod√®le (exemples)
docker exec ollama ollama pull llama2        # Usage g√©n√©ral
docker exec ollama ollama pull mistral       # Excellent √©quilibre
docker exec ollama ollama pull codellama     # Pour le code</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <h3>Configuration</h3>
      <div class="code-block"><code># Dans .env
AI_PROVIDER=ollama
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama2</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <h3>Mod√®les recommand√©s</h3>
      <table>
        <thead><tr><th>Mod√®le</th><th>Taille</th><th>Usage</th><th>RAM requise</th></tr></thead>
        <tbody>
          <tr><td><code>llama2:7b</code></td><td>3.8 GB</td><td>Usage g√©n√©ral</td><td>8 GB</td></tr>
          <tr><td><code>mistral:7b</code></td><td>4.1 GB</td><td>Meilleur rapport qualit√©/vitesse</td><td>8 GB</td></tr>
          <tr><td><code>codellama:7b</code></td><td>3.8 GB</td><td>G√©n√©ration de code</td><td>8 GB</td></tr>
          <tr><td><code>mixtral:8x7b</code></td><td>26 GB</td><td>Qualit√© maximale</td><td>48 GB</td></tr>
          <tr><td><code>phi</code></td><td>1.6 GB</td><td>Petit mais efficace</td><td>4 GB</td></tr>
        </tbody>
      </table>
      
      <div class="alert alert-success">
        ‚úÖ Le client IA inclus (<code>src/lib/ai-client.ts</code>) supporte Ollama, OpenRouter et OpenAI. Changez simplement <code>AI_PROVIDER</code> dans .env.
      </div>
    </section>
    ` : ''}
    
    ${hasDatabase ? `
    <section id="database">
      <h2><span class="step-num">7</span> Base de donn√©es</h2>
      
      <h3>Migrations automatiques</h3>
      <p>Les migrations SQL dans <code>database/migrations/</code> sont ex√©cut√©es automatiquement au premier d√©marrage de PostgreSQL.</p>
      
      <h3>Acc√®s √† la base</h3>
      <div class="code-block"><code># Connexion directe
docker exec -it ${projectName.toLowerCase().replace(/[^a-z0-9]/g, '-')}-postgres psql -U app -d app

# Depuis l'ext√©rieur (avec le port expos√©)
psql postgresql://app:VOTRE_MOT_DE_PASSE@VOTRE_IP:5432/app</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <h3>Backup & Restore</h3>
      <div class="code-block"><code># Backup
docker exec ${projectName.toLowerCase().replace(/[^a-z0-9]/g, '-')}-postgres pg_dump -U app app > backup.sql

# Restore
cat backup.sql | docker exec -i ${projectName.toLowerCase().replace(/[^a-z0-9]/g, '-')}-postgres psql -U app app</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <div class="alert alert-warning">
        ‚ö†Ô∏è <strong>S√©curit√©</strong><br>
        Le port 5432 est expos√© pour le d√©veloppement. En production, retirez le mapping de port dans docker-compose.yml.
      </div>
    </section>
    ` : ''}
    
    <section id="verify">
      <h2><span class="step-num">${hasDatabase ? '8' : hasAI ? '7' : hasBackend ? '6' : '5'}</span> V√©rification</h2>
      
      <div class="code-block"><code># Statut des containers
docker compose ps

# Logs en temps r√©el
docker compose logs -f

# Test sant√© frontend
curl http://localhost

# Test sant√© API ${hasBackend ? '\ncurl http://localhost/api/health' : '(pas de backend)'}</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <div class="alert alert-success">
        üéâ <strong>Votre application est accessible!</strong><br>
        Frontend: <code>http://VOTRE_IP</code> ${hasBackend ? '| API: <code>http://VOTRE_IP/api/*</code>' : ''}
      </div>
      
      <h3>Checklist post-d√©ploiement</h3>
      <ul class="checklist">
        <li><input type="checkbox" id="post-1"> <label for="post-1">Tous les containers sont en statut "healthy" ou "Up"</label></li>
        <li><input type="checkbox" id="post-2"> <label for="post-2">L'application se charge correctement dans le navigateur</label></li>
        ${hasBackend ? '<li><input type="checkbox" id="post-3"> <label for="post-3">L\'endpoint /api/health renvoie {"status":"ok"}</label></li>' : ''}
        ${hasDatabase ? '<li><input type="checkbox" id="post-4"> <label for="post-4">Les migrations SQL se sont ex√©cut√©es correctement</label></li>' : ''}
        <li><input type="checkbox" id="post-5"> <label for="post-5">SSL/HTTPS fonctionne (si domaine configur√©)</label></li>
        ${hasBackend ? '<li><input type="checkbox" id="post-6"> <label for="post-6">Les webhooks sont configur√©s et test√©s</label></li>' : ''}
      </ul>
    </section>
    
    <section id="troubleshoot">
      <h2>üîß D√©pannage</h2>
      
      <h3>Commandes utiles</h3>
      <div class="code-block"><code># Voir les 100 derni√®res lignes de logs
docker compose logs --tail=100

# Logs d'un service sp√©cifique
docker compose logs -f frontend
docker compose logs -f backend

# Red√©marrer un service
docker compose restart frontend

# Reconstruire compl√®tement
docker compose down
docker compose build --no-cache
docker compose up -d

# Nettoyer les images inutilis√©es
docker system prune -af</code><button class="copy-btn" onclick="copyCode(this)">Copier</button></div>
      
      <h3>Probl√®mes fr√©quents</h3>
      <div class="grid">
        <div class="card">
          <h4>üî¥ Container qui red√©marre en boucle</h4>
          <p>V√©rifiez les logs: <code>docker compose logs [service]</code><br>Souvent un probl√®me de variable d'environnement manquante.</p>
        </div>
        <div class="card">
          <h4>üî¥ Erreur "port already in use"</h4>
          <p>Un autre service utilise le port. Trouvez-le: <code>lsof -i :80</code> puis arr√™tez-le ou changez le port dans docker-compose.yml</p>
        </div>
        <div class="card">
          <h4>üî¥ CORS errors</h4>
          <p>Ajoutez votre domaine dans <code>CORS_ORIGIN</code> du .env et red√©marrez le backend.</p>
        </div>
        <div class="card">
          <h4>üî¥ SSL ne fonctionne pas</h4>
          <p>V√©rifiez que le DNS pointe vers votre IP. Attendez propagation DNS (jusqu'√† 48h). V√©rifiez les logs Caddy.</p>
        </div>
      </div>
    </section>
    
    <footer>
      <p>G√©n√©r√© par <strong>InoPay Liberation Pack v4.0</strong></p>
      <p><a href="https://inopay.fr">inopay.fr</a> - Lib√©rez votre code, reprenez le contr√¥le !</p>
    </footer>
  </div>
  
  <script>
    function copyCode(btn) {
      const code = btn.parentElement.querySelector('code').textContent;
      navigator.clipboard.writeText(code).then(() => {
        btn.textContent = 'Copi√©!';
        btn.classList.add('copied');
        setTimeout(() => {
          btn.textContent = 'Copier';
          btn.classList.remove('copied');
        }, 2000);
      });
    }
    
    function showTab(name) {
      document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
      document.querySelectorAll('.tab-content').forEach(t => t.classList.remove('active'));
      event.target.classList.add('active');
      document.getElementById('tab-' + name).classList.add('active');
    }
    
    // Smooth scroll pour la navigation
    document.querySelectorAll('nav a').forEach(link => {
      link.addEventListener('click', e => {
        e.preventDefault();
        const target = document.querySelector(link.getAttribute('href'));
        target.scrollIntoView({ behavior: 'smooth', block: 'start' });
      });
    });
    
    // Sauvegarder l'√©tat des checkboxes
    document.querySelectorAll('.checklist input').forEach(checkbox => {
      const key = 'check-' + checkbox.id;
      checkbox.checked = localStorage.getItem(key) === 'true';
      checkbox.addEventListener('change', () => {
        localStorage.setItem(key, checkbox.checked);
      });
    });
  </script>
</body>
</html>`;
}

// ============================================
// DOCKER COMPOSE GENERATOR - ENRICHI
// ============================================

function generateDockerCompose(
  projectName: string, 
  envVars: string[], 
  hasBackend: boolean, 
  hasDatabase: boolean,
  hasAI: boolean = false
): string {
  const serviceName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  
  return `version: '3.8'

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ${projectName} - Stack de Production Souveraine
# G√©n√©r√© par InoPay Liberation Pack v4.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

services:
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # FRONTEND - Application React avec Caddy (auto-SSL)
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ${serviceName}-frontend
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    environment:
      - DOMAIN=\${DOMAIN:-localhost}
      - VITE_API_URL=\${VITE_API_URL:-http://localhost/api}
    volumes:
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
${hasBackend || hasDatabase ? `    depends_on:
${hasBackend ? '      backend:\n        condition: service_healthy' : ''}
${hasDatabase ? '      postgres:\n        condition: service_healthy' : ''}` : ''}

${hasBackend ? `
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # BACKEND - API Express.js (converti depuis Edge Functions)
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ${serviceName}-backend
    restart: unless-stopped
    expose:
      - "3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - CORS_ORIGIN=\${DOMAIN:-*}
${envVars.filter(v => !['DOMAIN', 'VITE_API_URL'].includes(v)).map(v => `      - ${v}=\${${v}}`).join('\n')}
${hasDatabase ? `      - DATABASE_URL=postgresql://\${POSTGRES_USER:-app}:\${POSTGRES_PASSWORD}@postgres:5432/\${POSTGRES_DB:-app}` : ''}
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
${hasDatabase ? `    depends_on:
      postgres:
        condition: service_healthy` : ''}
` : ''}

${hasDatabase ? `
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # DATABASE - PostgreSQL 15
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  postgres:
    image: postgres:15-alpine
    container_name: ${serviceName}-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=\${POSTGRES_USER:-app}
      - POSTGRES_PASSWORD=\${POSTGRES_PASSWORD}
      - POSTGRES_DB=\${POSTGRES_DB:-app}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/migrations:/docker-entrypoint-initdb.d:ro
    # D√©commentez pour acc√®s externe (d√©veloppement uniquement!)
    # ports:
    #   - "5432:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U \${POSTGRES_USER:-app} -d \${POSTGRES_DB:-app}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
` : ''}

  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # WATCHTOWER - Mise √† jour automatique des containers
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  watchtower:
    image: containrrr/watchtower
    container_name: ${serviceName}-watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_POLL_INTERVAL=86400  # V√©rifie toutes les 24h
      - WATCHTOWER_INCLUDE_STOPPED=false
    networks:
      - app-network

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# VOLUMES PERSISTANTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
volumes:
  caddy_data:
  caddy_config:
${hasDatabase ? '  postgres_data:' : ''}

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# R√âSEAU
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
networks:
  app-network:
    driver: bridge
`;
}

function generateDockerComposeFull(projectName: string, envVars: string[]): string {
  const serviceName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  
  return `version: '3.8'

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ${projectName} - Stack COMPL√àTE avec Services Open Source
# Inclut: Ollama (IA), Meilisearch (Recherche), MinIO (Storage)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

services:
  # ... (inclure les services de base) ...
  
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # OLLAMA - IA Locale (remplace OpenAI)
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ollama:
    image: ollama/ollama:latest
    container_name: ${serviceName}-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - app-network
    # Pour GPU NVIDIA, d√©commentez:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # MEILISEARCH - Recherche Full-Text (remplace Algolia)
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  meilisearch:
    image: getmeili/meilisearch:latest
    container_name: ${serviceName}-meilisearch
    restart: unless-stopped
    ports:
      - "7700:7700"
    volumes:
      - meilisearch_data:/meili_data
    environment:
      - MEILI_MASTER_KEY=\${MEILISEARCH_MASTER_KEY}
      - MEILI_ENV=production
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:7700/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # MINIO - Stockage S3-Compatible (remplace AWS S3)
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  minio:
    image: minio/minio:latest
    container_name: ${serviceName}-minio
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=\${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_ROOT_PASSWORD=\${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ollama_data:
  meilisearch_data:
  minio_data:

networks:
  app-network:
    driver: bridge
`;
}

// ============================================
// QUICK DEPLOY SCRIPT - AM√âLIOR√â
// ============================================

function generateQuickDeployScript(projectName: string, hasDatabase: boolean, hasAI: boolean = false): string {
  const safeName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  
  return `#!/bin/bash
set -e

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# InoPay Liberation Pack - Script de D√©ploiement Automatique
# Projet: ${projectName}
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
BLUE='\\033[0;34m'
NC='\\033[0m'

echo -e "\${BLUE}"
echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "‚ïë   üöÄ InoPay Liberation Pack - ${projectName}"
echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
echo -e "\${NC}"

# V√©rification root
if [ "\\$EUID" -ne 0 ]; then
  echo -e "\${RED}‚ùå Ce script doit √™tre ex√©cut√© en tant que root\${NC}"
  echo -e "   Utilisez: \${YELLOW}sudo ./quick-deploy.sh\${NC}"
  exit 1
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 1. Installation Docker
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo -e "\${YELLOW}üì¶ V√©rification de Docker...\${NC}"

if ! command -v docker &> /dev/null; then
  echo -e "\${YELLOW}üì• Installation de Docker...\${NC}"
  curl -fsSL https://get.docker.com | sh
  systemctl enable docker
  systemctl start docker
  echo -e "\${GREEN}‚úì Docker install√© avec succ√®s\${NC}"
else
  echo -e "\${GREEN}‚úì Docker est d√©j√† install√© ($(docker --version))\${NC}"
fi

# Docker Compose (inclus dans Docker r√©cent)
if ! docker compose version &> /dev/null; then
  echo -e "\${RED}‚ùå Docker Compose non disponible\${NC}"
  exit 1
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 2. Configuration des variables d'environnement
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo -e "\${YELLOW}‚öôÔ∏è  Configuration de l'environnement...\${NC}"

if [ ! -f .env ]; then
  cp .env.example .env
  
  # G√©n√©ration automatique des secrets
  JWT_SECRET=$(openssl rand -base64 32)
  sed -i "s/^JWT_SECRET=.*/JWT_SECRET=$JWT_SECRET/" .env
  echo -e "\${GREEN}‚úì JWT_SECRET g√©n√©r√©\${NC}"
  
${hasDatabase ? `  # Base de donn√©es
  POSTGRES_PASSWORD=$(openssl rand -base64 16 | tr -d '/+=')
  sed -i "s/^POSTGRES_PASSWORD=.*/POSTGRES_PASSWORD=$POSTGRES_PASSWORD/" .env
  sed -i "s|^DATABASE_URL=.*|DATABASE_URL=postgresql://app:$POSTGRES_PASSWORD@postgres:5432/app|" .env
  echo -e "\${GREEN}‚úì POSTGRES_PASSWORD g√©n√©r√©\${NC}"
` : ''}

  echo -e "\${GREEN}‚úì Fichier .env cr√©√©\${NC}"
else
  echo -e "\${GREEN}‚úì Fichier .env existant conserv√©\${NC}"
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 3. Configuration du firewall
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo -e "\${YELLOW}üî• Configuration du firewall...\${NC}"

if command -v ufw &> /dev/null; then
  ufw allow 22/tcp   # SSH
  ufw allow 80/tcp   # HTTP
  ufw allow 443/tcp  # HTTPS
  echo -e "\${GREEN}‚úì Ports 80 et 443 ouverts\${NC}"
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 4. Build et d√©marrage
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo -e "\${YELLOW}üê≥ Construction et d√©marrage des containers...\${NC}"

docker compose pull 2>/dev/null || true
docker compose build --no-cache
docker compose up -d

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 5. Attente et v√©rification
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo -e "\${YELLOW}‚è≥ Attente du d√©marrage des services...\${NC}"
sleep 15

# V√©rification des containers
echo ""
docker compose ps

# Test de sant√©
HEALTH_CHECK=$(curl -s http://localhost 2>/dev/null | head -c 100 || echo "")

echo -e "\${GREEN}"
echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "‚ïë          üéâ D√âPLOIEMENT TERMIN√â AVEC SUCC√àS !             ‚ïë"
echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
echo -e "\${NC}"

# R√©cup√©rer l'IP publique
PUBLIC_IP=$(curl -s ifconfig.me 2>/dev/null || curl -s icanhazip.com 2>/dev/null || echo "VOTRE_IP")

echo -e "\${BLUE}üìç Acc√®s √† votre application:\${NC}"
echo -e "   Frontend:  \${GREEN}http://$PUBLIC_IP\${NC}"
echo -e "   API:       \${GREEN}http://$PUBLIC_IP/api/health\${NC}"
${hasDatabase ? `echo -e "   PostgreSQL: localhost:5432 (interne)"` : ''}
${hasAI ? `echo -e "   Ollama:    \${GREEN}http://$PUBLIC_IP:11434\${NC} (si activ√©)"` : ''}

echo ""
echo -e "\${YELLOW}üìã Commandes utiles:\${NC}"
echo "   docker compose logs -f          # Voir les logs"
echo "   docker compose restart          # Red√©marrer"
echo "   docker compose down             # Arr√™ter"
echo ""
echo -e "\${BLUE}üìñ Guide complet: ouvrez DEPLOY_GUIDE.html\${NC}"
echo ""
`;
}

// ============================================
// SOVEREIGNTY REPORT GENERATOR
// ============================================

function generateSovereigntyReport(projectName: string, check: SovereigntyCheck, fileCount: number): string {
  const date = new Date().toISOString();
  
  return `# üõ°Ô∏è Rapport de Souverainet√© - ${projectName}

**Date de g√©n√©ration:** ${date}
**Score de souverainet√©:** ${check.score}%
**Fichiers analys√©s:** ${fileCount}

---

## üìä Statut Global

${check.isClean ? '‚úÖ **CODE 100% SOUVERAIN** - Aucune d√©pendance propri√©taire d√©tect√©e!' : '‚ö†Ô∏è **ATTENTION** - Des √©l√©ments propri√©taires peuvent subsister'}

---

${check.criticalIssues.length > 0 ? `
## üî¥ Probl√®mes Critiques (${check.criticalIssues.length})

Ces √©l√©ments doivent √™tre corrig√©s manuellement:

${check.criticalIssues.map(issue => `- ‚ùå ${issue}`).join('\n')}
` : ''}

${check.warnings.length > 0 ? `
## üü° Avertissements (${check.warnings.length})

${check.warnings.map(warning => `- ‚ö†Ô∏è ${warning}`).join('\n')}
` : ''}

---

## ‚úÖ Nettoyage Effectu√©

### Imports & D√©pendances
- ‚úÖ Imports propri√©taires supprim√©s (@lovable, @gptengineer, @bolt, @v0, @cursor, @codeium, @copilot, @tabnine...)
- ‚úÖ Packages NPM suspects retir√©s
- ‚úÖ Plugins Vite propri√©taires d√©sactiv√©s

### Identifiants & Secrets
- ‚úÖ IDs de projet Supabase remplac√©s par des placeholders
- ‚úÖ Tokens JWT expos√©s neutralis√©s
- ‚úÖ Cl√©s Stripe live/test masqu√©es

### T√©l√©m√©trie & Tracking
- ‚úÖ Domaines de t√©l√©m√©trie supprim√©s (lovable.app, gptengineer.app, bolt.new, etc.)
- ‚úÖ Attributs data-* de tracking retir√©s
- ‚úÖ Commentaires avec r√©f√©rences propri√©taires nettoy√©s

### Appels Backend
- ‚úÖ \`supabase.functions.invoke\` convertis en \`fetch\` vers \`/api/...\`
- ‚úÖ Edge Functions converties en routes Express

---

## üìÅ Polyfills G√©n√©r√©s

Les hooks propri√©taires ont √©t√© remplac√©s par des impl√©mentations souveraines:

| Hook Original | Remplacement | Fichier |
|---------------|--------------|---------|
| \`@/hooks/use-mobile\` | D√©tection viewport | \`src/lib/hooks/use-mobile.ts\` |
| \`@/hooks/use-toast\` | Notifications | \`src/lib/hooks/use-toast.ts\` |
| \`@/components/ui/use-toast\` | Toast UI | \`src/lib/hooks/use-toast.ts\` |
| \`@/integrations/supabase\` | Client configurable | \`src/lib/supabase-client.ts\` |

---

## üîÑ Conversions Effectu√©es

### Edge Functions ‚Üí Express

Les Supabase Edge Functions ont √©t√© converties en routes Express.js:

\`\`\`
supabase/functions/{name}/index.ts ‚Üí backend/src/routes/{name}.ts
\`\`\`

- Imports Deno ‚Üí Imports Node.js/npm
- \`Deno.env.get()\` ‚Üí \`process.env\`
- \`new Response()\` ‚Üí \`res.json()\`
- CORS headers int√©gr√©s dans le middleware Express

---

## üöÄ Prochaines √âtapes

1. **Configurer les variables d'environnement**
   - Copiez \`.env.example\` vers \`.env\`
   - Remplissez les valeurs requises

2. **Si vous utilisez Supabase self-hosted:**
   - Cr√©ez un nouveau projet
   - Ex√©cutez les migrations dans \`database/migrations/\`
   - Mettez √† jour les URLs dans \`.env\`

3. **Si vous utilisez une IA:**
   - Installez Ollama ou configurez OpenRouter
   - Mettez √† jour \`AI_PROVIDER\` dans \`.env\`

4. **D√©ployez:**
   \`\`\`bash
   sudo ./scripts/quick-deploy.sh
   \`\`\`

---

## üìã Checklist Finale

- [ ] Variables d'environnement configur√©es
- [ ] Base de donn√©es migr√©e (si applicable)
- [ ] Webhooks reconfigur√©s (Stripe, GitHub...)
- [ ] DNS configur√© pour HTTPS
- [ ] Tests fonctionnels pass√©s

---

*G√©n√©r√© par **InoPay Liberation Pack v4.0** - Lib√©rez votre code!*
`;
}

// ============================================
// COMPLETE LIBERATION GUIDE GENERATORS
// ============================================

function generateCompleteLiberationGuideHTML(
  projectName: string,
  hasBackend: boolean,
  hasDatabase: boolean,
  hasAuth: boolean,
  envVars: string[],
  backendRoutes: string[],
  webhooks: Array<{ provider: string; endpoint: string }>,
  schemaSQL: string
): string {
  const safeName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  
  return `<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>üöÄ Guide Complet de Lib√©ration - ${projectName}</title>
  <style>
    :root { --bg: #0f172a; --card: #1e293b; --accent: #10b981; --text: #f8fafc; --muted: #94a3b8; --border: #475569; --warning: #f59e0b; --info: #3b82f6; }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: system-ui, sans-serif; background: var(--bg); color: var(--text); line-height: 1.6; }
    .container { max-width: 1100px; margin: 0 auto; padding: 20px; }
    .header { text-align: center; padding: 40px 20px; background: linear-gradient(135deg, var(--card), var(--bg)); border-bottom: 2px solid var(--accent); margin-bottom: 30px; }
    .header h1 { font-size: 2.2rem; background: linear-gradient(90deg, var(--accent), var(--info)); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    .progress-bar { position: fixed; top: 0; left: 0; width: 100%; height: 4px; background: var(--card); z-index: 1000; }
    .progress-fill { height: 100%; background: linear-gradient(90deg, var(--accent), var(--info)); width: 0%; transition: width 0.3s; }
    .nav { display: flex; flex-wrap: wrap; gap: 10px; justify-content: center; margin-bottom: 30px; }
    .nav-btn { padding: 10px 20px; background: var(--card); border: 1px solid var(--border); border-radius: 8px; color: var(--muted); cursor: pointer; transition: all 0.2s; }
    .nav-btn:hover, .nav-btn.active { background: var(--accent); color: white; border-color: var(--accent); }
    .nav-btn.done { background: transparent; border-color: var(--accent); color: var(--accent); }
    .card { background: var(--card); border-radius: 12px; padding: 25px; margin-bottom: 20px; border: 1px solid var(--border); }
    .card h2 { font-size: 1.4rem; margin-bottom: 20px; display: flex; align-items: center; gap: 10px; }
    .card h3 { font-size: 1.1rem; margin: 20px 0 15px; color: var(--accent); }
    .step { background: var(--bg); border-radius: 8px; padding: 20px; margin-bottom: 15px; border-left: 4px solid var(--border); }
    .step.done { border-left-color: var(--accent); }
    .step-header { display: flex; align-items: center; gap: 12px; margin-bottom: 12px; }
    .step-num { width: 28px; height: 28px; background: var(--border); border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 0.85rem; }
    .step.done .step-num { background: var(--accent); }
    .code { background: #0d1117; border-radius: 6px; padding: 12px 15px; margin: 12px 0; position: relative; font-family: Monaco, Consolas, monospace; font-size: 0.9rem; overflow-x: auto; }
    .copy-btn { position: absolute; top: 8px; right: 8px; background: var(--card); border: none; color: var(--muted); padding: 4px 10px; border-radius: 4px; cursor: pointer; font-size: 0.75rem; }
    .copy-btn:hover { background: var(--accent); color: white; }
    .btn { display: inline-flex; align-items: center; gap: 8px; padding: 12px 24px; border-radius: 8px; border: none; cursor: pointer; font-size: 1rem; font-weight: 600; transition: all 0.2s; }
    .btn-primary { background: var(--accent); color: white; }
    .btn-primary:hover { filter: brightness(1.1); transform: translateY(-1px); }
    .btn-secondary { background: var(--card); color: var(--text); border: 1px solid var(--border); }
    .check-item { display: flex; align-items: flex-start; gap: 12px; padding: 12px; background: var(--bg); border-radius: 8px; margin-bottom: 8px; cursor: pointer; }
    .check-item input { width: 18px; height: 18px; accent-color: var(--accent); margin-top: 2px; }
    .check-item.checked { border: 1px solid var(--accent); background: rgba(16, 185, 129, 0.1); }
    .info-box { background: rgba(59, 130, 246, 0.1); border: 1px solid var(--info); border-radius: 8px; padding: 15px; margin: 15px 0; }
    .warning-box { background: rgba(245, 158, 11, 0.1); border: 1px solid var(--warning); border-radius: 8px; padding: 15px; margin: 15px 0; }
    .success-box { background: rgba(16, 185, 129, 0.1); border: 1px solid var(--accent); border-radius: 8px; padding: 15px; margin: 15px 0; }
    .tabs { display: flex; gap: 5px; margin-bottom: 15px; border-bottom: 2px solid var(--border); }
    .tab { padding: 10px 18px; background: transparent; border: none; color: var(--muted); cursor: pointer; border-radius: 6px 6px 0 0; }
    .tab.active { background: var(--bg); color: var(--accent); }
    .tab-content { display: none; }
    .tab-content.active { display: block; }
    .table { width: 100%; border-collapse: collapse; margin: 15px 0; }
    .table th, .table td { padding: 10px; text-align: left; border-bottom: 1px solid var(--border); }
    .table th { background: var(--bg); font-weight: 600; }
    .table code { background: #0d1117; padding: 2px 6px; border-radius: 4px; font-size: 0.85rem; }
    .ascii { font-family: monospace; font-size: 0.8rem; background: #0d1117; padding: 15px; border-radius: 8px; white-space: pre; overflow-x: auto; color: #7ee787; }
    .section { display: none; }
    .section.active { display: block; animation: fadeIn 0.3s; }
    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
    .actions { display: flex; justify-content: space-between; margin-top: 25px; }
    @media (max-width: 768px) { .nav { flex-direction: column; } .actions { flex-direction: column; gap: 10px; } }
  </style>
</head>
<body>
  <div class="progress-bar"><div class="progress-fill" id="progress"></div></div>
  <header class="header">
    <h1>üöÄ Guide de Lib√©ration Complet</h1>
    <p style="color: var(--muted); margin-top: 10px;">${projectName} - Coolify + GitHub + Supabase Self-Hosted</p>
  </header>
  <div class="container">
    <nav class="nav">
      <button class="nav-btn active" data-section="1" onclick="goTo(1)">1. Pr√©requis</button>
      <button class="nav-btn" data-section="2" onclick="goTo(2)">2. Transfert</button>
      <button class="nav-btn" data-section="3" onclick="goTo(3)">3. GitHub</button>
      <button class="nav-btn" data-section="4" onclick="goTo(4)">4. Coolify</button>
      <button class="nav-btn" data-section="5" onclick="goTo(5)">5. Supabase SH</button>
      <button class="nav-btn" data-section="6" onclick="goTo(6)">6. Base de Donn√©es</button>
      <button class="nav-btn" data-section="7" onclick="goTo(7)">7. Domaine</button>
      <button class="nav-btn" data-section="8" onclick="goTo(8)">8. V√©rification</button>
    </nav>
    
    <section class="section active" id="s1">
      <div class="card">
        <h2>‚úì √âtape 1 : V√©rification des Pr√©requis</h2>
        <h3>üñ•Ô∏è Serveur VPS</h3>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><div><strong>VPS avec acc√®s root</strong><br><small style="color: var(--muted)">Min: 2 vCPU, 4GB RAM, 40GB SSD</small></div></div>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><div><strong>Coolify install√©</strong><br><small style="color: var(--muted)">curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash</small></div></div>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><div><strong>Nom de domaine</strong> (recommand√©)</div></div>
        <h3>üîê Test SSH</h3>
        <div class="step"><div class="step-header"><span class="step-num">1</span><span>Testez connexion</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>ssh root@VOTRE_IP_VPS</div></div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>V√©rifiez Docker</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>docker --version && docker compose version</div></div>
        <div class="actions"><span></span><button class="btn btn-primary" onclick="complete(1); goTo(2);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s2">
      <div class="card">
        <h2>üìÅ √âtape 2 : Transfert des Fichiers</h2>
        <div class="tabs">
          <button class="tab active" onclick="showTab(this, 'github')">üêô Via GitHub</button>
          <button class="tab" onclick="showTab(this, 'scp')">üíª Via SCP</button>
        </div>
        <div class="tab-content active" id="tab-github">
          <div class="step"><div class="step-header"><span class="step-num">1</span><span>Cr√©ez d√©p√¥t GitHub</span></div><p><a href="https://github.com/new" target="_blank" style="color: var(--accent)">github.com/new</a> ‚Üí ${safeName} ‚Üí Private ‚Üí Create</p></div>
          <div class="step"><div class="step-header"><span class="step-num">2</span><span>Push vers GitHub</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>cd ${safeName}
git init && git add . && git commit -m "üöÄ Liberation"
git remote add origin https://github.com/USER/${safeName}.git
git push -u origin main</div></div>
        </div>
        <div class="tab-content" id="tab-scp"><div class="step"><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>scp -r ${safeName} root@VOTRE_IP:/opt/apps/</div></div></div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(1)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(2); goTo(3);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s3">
      <div class="card">
        <h2>üêô √âtape 3 : Connexion GitHub √† Coolify</h2>
        <div class="step"><div class="step-header"><span class="step-num">1</span><span>Acc√©dez √† Coolify</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>https://VOTRE_IP:8000</div></div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>Connectez GitHub</span></div><div class="ascii">COOLIFY ‚Üí Settings ‚Üí Git Sources ‚Üí [+ Add GitHub App]</div></div>
        <div class="info-box">üí° Alternative: Personal Access Token dans GitHub Settings ‚Üí Tokens</div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(2)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(3); goTo(4);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s4">
      <div class="card">
        <h2>üöÄ √âtape 4 : D√©ploiement Coolify</h2>
        <div class="step"><div class="step-header"><span class="step-num">1</span><span>Nouveau projet</span></div><p>Dashboard ‚Üí + New Project ‚Üí ${projectName}</p></div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>Ajoutez l'app</span></div><p>+ New Resource ‚Üí Docker Compose ‚Üí GitHub ‚Üí S√©lectionnez repo</p></div>
        <div class="step"><div class="step-header"><span class="step-num">3</span><span>Variables d'environnement</span></div>
          <table class="table"><tr><th>Variable</th><th>Description</th></tr>
${envVars.slice(0, 6).map(v => `            <tr><td><code>${v}</code></td><td>√Ä configurer</td></tr>`).join('\n')}
          </table>
        </div>
        <div class="step"><div class="step-header"><span class="step-num">4</span><span>D√©ployez</span></div><p>Cliquez Deploy et attendez 2-5 min</p></div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(3)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(4); goTo(5);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s5">
      <div class="card">
        <h2>üóÑÔ∏è √âtape 5 : Supabase Self-Hosted</h2>
        <div class="step"><div class="step-header"><span class="step-num">1</span><span>T√©l√©chargez Supabase</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>cd /opt && git clone --depth 1 https://github.com/supabase/supabase
cd supabase/docker && cp .env.example .env</div></div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>G√©n√©rez secrets</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>openssl rand -base64 32  # JWT_SECRET</div></div>
        <div class="step"><div class="step-header"><span class="step-num">3</span><span>D√©marrez</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>nano .env  # √âditez
docker compose up -d && docker compose ps</div></div>
        <div class="step"><div class="step-header"><span class="step-num">4</span><span>Acc√©dez √† Studio</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>http://VOTRE_IP:3000</div></div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(4)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(5); goTo(6);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s6">
      <div class="card">
        <h2>üíæ √âtape 6 : Migration Base de Donn√©es</h2>
        ${hasDatabase ? `<div class="step"><div class="step-header"><span class="step-num">1</span><span>Sch√©ma SQL</span></div><p><code>database/migrations/001_schema.sql</code></p></div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>Via Studio</span></div><p>SQL Editor ‚Üí New Query ‚Üí Collez 001_schema.sql ‚Üí Run</p></div>
        <div class="step"><div class="step-header"><span class="step-num">3</span><span>Ou via CLI</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>psql "postgresql://postgres:PASS@IP:5432/postgres" -f 001_schema.sql</div></div>` : '<div class="info-box">‚ÑπÔ∏è Pas de migration de base n√©cessaire.</div>'}
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(5)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(6); goTo(7);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s7">
      <div class="card">
        <h2>üåê √âtape 7 : Configuration Domaine</h2>
        <div class="step"><div class="step-header"><span class="step-num">1</span><span>DNS chez registrar</span></div>
          <table class="table"><tr><th>Type</th><th>Nom</th><th>Valeur</th></tr>
            <tr><td>A</td><td>@</td><td>IP_VPS</td></tr>
            <tr><td>A</td><td>www</td><td>IP_VPS</td></tr>
            <tr><td>A</td><td>api</td><td>IP_VPS</td></tr>
          </table>
        </div>
        <div class="step"><div class="step-header"><span class="step-num">2</span><span>Dans Coolify</span></div><p>Application ‚Üí Settings ‚Üí Domains ‚Üí Ajoutez https://votre-domaine.com</p></div>
        <div class="step"><div class="step-header"><span class="step-num">3</span><span>V√©rifiez</span></div><div class="code"><button class="copy-btn" onclick="copy(this)">üìã</button>nslookup votre-domaine.com</div></div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(6)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(7); goTo(8);">Continuer ‚Üí</button></div>
      </div>
    </section>
    
    <section class="section" id="s8">
      <div class="card">
        <h2>üîç √âtape 8 : V√©rification Finale</h2>
        <h3>üìã Checklist</h3>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><span>Application s'affiche</span></div>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><span>Auth fonctionne</span></div>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><span>Donn√©es sauvegard√©es</span></div>
        <div class="check-item" onclick="toggleCheck(this)"><input type="checkbox"><span>SSL actif (cadenas)</span></div>
        ${webhooks.length > 0 ? `<h3>üîó Webhooks</h3><table class="table"><tr><th>Service</th><th>URL</th></tr>${webhooks.map(w => `<tr><td>${w.provider}</td><td><code>https://DOMAINE${w.endpoint}</code></td></tr>`).join('')}</table>` : ''}
        <div id="final" style="display: none;"><div class="success-box" style="text-align: center; padding: 30px;"><h2 style="color: var(--accent);">üéâ F√©licitations !</h2><p style="font-size: 1.2rem;">${projectName} est maintenant 100% souverain !</p></div></div>
        <div class="actions"><button class="btn btn-secondary" onclick="goTo(7)">‚Üê Retour</button><button class="btn btn-primary" onclick="complete(8); showFinal();">‚úÖ Terminer</button></div>
      </div>
    </section>
  </div>
  <script>
    const state = { completed: new Set(), current: 1 };
    const saved = localStorage.getItem('lib-${safeName}');
    if (saved) { const s = JSON.parse(saved); s.completed.forEach(n => state.completed.add(n)); state.current = s.current; }
    function save() { localStorage.setItem('lib-${safeName}', JSON.stringify({ completed: [...state.completed], current: state.current })); }
    function goTo(n) { document.querySelectorAll('.section').forEach(s => s.classList.remove('active')); document.getElementById('s'+n).classList.add('active'); document.querySelectorAll('.nav-btn').forEach(b => b.classList.remove('active')); document.querySelector('[data-section="'+n+'"]').classList.add('active'); state.current = n; save(); updateProgress(); }
    function complete(n) { state.completed.add(n); document.querySelector('[data-section="'+n+'"]').classList.add('done'); save(); updateProgress(); }
    function updateProgress() { document.getElementById('progress').style.width = ((state.completed.size / 8) * 100) + '%'; }
    function toggleCheck(el) { const cb = el.querySelector('input'); cb.checked = !cb.checked; el.classList.toggle('checked', cb.checked); }
    function showTab(btn, id) { btn.parentElement.querySelectorAll('.tab').forEach(t => t.classList.remove('active')); btn.classList.add('active'); const parent = btn.closest('.card'); parent.querySelectorAll('.tab-content').forEach(tc => tc.classList.remove('active')); parent.querySelector('#tab-'+id).classList.add('active'); }
    function copy(btn) { const code = btn.parentElement.textContent.replace('üìã', '').trim(); navigator.clipboard.writeText(code); btn.textContent = '‚úÖ'; setTimeout(() => btn.textContent = 'üìã', 1500); }
    function showFinal() { document.getElementById('final').style.display = 'block'; document.getElementById('final').scrollIntoView({ behavior: 'smooth' }); }
    state.completed.forEach(n => document.querySelector('[data-section="'+n+'"]').classList.add('done'));
    goTo(state.current);
  </script>
</body>
</html>`;
}

function generateSetupCoolifyScript(projectName: string, envVars: string[]): string {
  const safeName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  return `#!/bin/bash
# Setup Coolify - ${projectName}
set -e

echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "‚ïë     üöÄ Configuration Coolify - ${projectName}              ‚ïë"
echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"

command -v curl &> /dev/null || { echo "‚ùå curl requis"; exit 1; }
command -v docker &> /dev/null || { echo "‚ùå Docker requis"; exit 1; }
echo "‚úÖ Pr√©requis OK"

read -p "URL Coolify (ex: https://coolify.domaine.com): " COOLIFY_URL
read -p "Token API Coolify: " COOLIFY_TOKEN
read -p "URL d√©p√¥t GitHub: " GITHUB_REPO

echo "üöÄ Cr√©ation du projet..."
curl -s -X POST "\${COOLIFY_URL}/api/v1/projects" \\
    -H "Authorization: Bearer \${COOLIFY_TOKEN}" \\
    -H "Content-Type: application/json" \\
    -d '{"name": "${safeName}", "description": "Lib√©r√© par InoPay"}'

echo "‚úÖ Projet cr√©√©! Configurez les env vars dans Coolify."
`;
}

function generateImportSupabaseSchemaScript(projectName: string): string {
  return `#!/bin/bash
# Import Schema Supabase - ${projectName}
set -e

SCRIPT_DIR="$(cd "$(dirname "\${BASH_SOURCE[0]}")" && pwd)"
SCHEMA_FILE="\${SCRIPT_DIR}/../database/migrations/001_schema.sql"

echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "‚ïë     üíæ Import Sch√©ma Supabase - ${projectName}             ‚ïë"
echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"

[ ! -f "$SCHEMA_FILE" ] && { echo "‚ùå Fichier non trouv√©: $SCHEMA_FILE"; exit 1; }
echo "‚úÖ Fichier trouv√©"

read -p "H√¥te PostgreSQL [localhost]: " DB_HOST; DB_HOST=\${DB_HOST:-localhost}
read -p "Port [5432]: " DB_PORT; DB_PORT=\${DB_PORT:-5432}
read -p "Base [postgres]: " DB_NAME; DB_NAME=\${DB_NAME:-postgres}
read -p "Utilisateur [postgres]: " DB_USER; DB_USER=\${DB_USER:-postgres}
read -s -p "Mot de passe: " DB_PASSWORD; echo ""

echo "üîå Test connexion..."
PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT 1;" > /dev/null 2>&1 || { echo "‚ùå Connexion √©chou√©e"; exit 1; }
echo "‚úÖ Connexion OK"

read -p "Importer le sch√©ma? (oui/non): " CONFIRM
[ "$CONFIRM" != "oui" ] && { echo "Annul√©"; exit 0; }

PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -f "$SCHEMA_FILE"
echo "‚úÖ Sch√©ma import√©!"

echo "üìã Tables cr√©√©es:"
PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "\\dt public.*"
`;
}

function generateCoolifyStepByStepGuide(projectName: string): string {
  const safeName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');
  return `# üöÄ Guide Coolify Pas-√†-Pas - ${projectName}

## üìã Table des mati√®res
1. [Pr√©requis](#pr√©requis)
2. [Installation Coolify](#installation-coolify)
3. [Configuration GitHub](#configuration-github)
4. [D√©ploiement](#d√©ploiement)
5. [Troubleshooting](#troubleshooting)

---

## Pr√©requis

### Serveur VPS
- **Minimum**: 2 vCPU, 4GB RAM, 40GB SSD
- **OS**: Ubuntu 22.04 LTS

\`\`\`bash
ssh root@VOTRE_IP
free -h && df -h
\`\`\`

---

## Installation Coolify

\`\`\`bash
curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash
\`\`\`

Acc√®s: \`https://VOTRE_IP:8000\`

---

## Configuration GitHub

\`\`\`bash
cd ${safeName}
git init && git add . && git commit -m "üöÄ Liberation"
git remote add origin https://github.com/USER/${safeName}.git
git push -u origin main
\`\`\`

Dans Coolify: Settings ‚Üí Git Sources ‚Üí + Add GitHub App

---

## D√©ploiement

1. **New Project** ‚Üí Nom: \`${projectName}\`
2. **+ New Resource** ‚Üí Docker Compose ‚Üí GitHub
3. Configurez les variables d'environnement
4. Cliquez **Deploy**

---

## Troubleshooting

### Build qui √©choue
\`\`\`bash
echo "node_modules/" >> .gitignore
git rm -r --cached node_modules
git commit -m "Fix" && git push
\`\`\`

### SSL ne fonctionne pas
- V√©rifiez DNS: \`nslookup domaine.com\`
- Ports ouverts: \`ufw allow 80 && ufw allow 443\`

### Container restart en boucle
- V√©rifiez les logs dans Coolify
- Testez le Dockerfile localement

---

*G√©n√©r√© par InoPay Liberation Pack*
`;
}

// ============================================
// MAIN HANDLER

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      return new Response(JSON.stringify({ error: 'Non autoris√©' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_ANON_KEY')!;
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    
    const supabase = createClient(supabaseUrl, supabaseKey, {
      global: { headers: { Authorization: authHeader } }
    });
    
    // Client admin pour l'export des donn√©es
    const supabaseAdmin = createClient(supabaseUrl, supabaseServiceKey);

    const { data: { user }, error: userError } = await supabase.auth.getUser();
    if (userError || !user) {
      return new Response(JSON.stringify({ error: 'Utilisateur non authentifi√©' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const { 
      projectId,
      projectName, 
      cleanedFiles, 
      edgeFunctions,
      sqlSchema,
      includeBackend = true,
      includeDatabase = true,
      includeAIServices = false,
      sovereigntyScore = 0,
      clientSovereigntyScore = null,
      clientEnvVars = [],
      assetFiles = {}, // Downloaded assets from client
    } = await req.json();

    if (!cleanedFiles || Object.keys(cleanedFiles).length === 0) {
      return new Response(JSON.stringify({ error: 'Fichiers du projet requis' }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    console.log(`[generate-liberation-pack] Generating pack for ${projectName} with ${Object.keys(cleanedFiles).length} files`);

    // ==========================================
    // SERVER-SIDE DOUBLE CLEANING
    // ==========================================
    console.log(`[generate-liberation-pack] Starting server-side deep clean...`);
    
    const doubleCleanedFiles: Record<string, string> = {};
    let totalServerChanges = 0;
    
    for (const [path, content] of Object.entries(cleanedFiles)) {
      if (path.match(/\.(ts|tsx|js|jsx|json|html|css|md)$/)) {
        const { cleaned, changes } = serverSideDeepClean(content as string, path);
        doubleCleanedFiles[path] = cleaned;
        if (changes.length > 0) {
          totalServerChanges += changes.length;
          console.log(`[generate-liberation-pack] Server cleaned ${path}: ${changes.length} changes`);
        }
      } else {
        doubleCleanedFiles[path] = content as string;
      }
    }
    
    console.log(`[generate-liberation-pack] Server-side cleaning complete: ${totalServerChanges} total changes`);

    // ==========================================
    // SOVEREIGNTY VERIFICATION
    // ==========================================
    // Use client score if provided (more accurate), otherwise recalculate
    const serverSovereigntyCheck = verifySovereignty(doubleCleanedFiles);
    const sovereigntyCheck = clientSovereigntyScore !== null && clientSovereigntyScore >= 0
      ? { 
          score: clientSovereigntyScore, 
          isClean: clientSovereigntyScore >= 95, 
          criticalIssues: serverSovereigntyCheck.criticalIssues, 
          warnings: serverSovereigntyCheck.warnings 
        }
      : serverSovereigntyCheck;
    
    console.log(`[generate-liberation-pack] Sovereignty check: score=${sovereigntyCheck.score} (client=${clientSovereigntyScore}), clean=${sovereigntyCheck.isClean}`);

    // ==========================================
    // AUTO-DETECT EDGE FUNCTIONS FROM FILES
    // ==========================================
    let detectedEdgeFunctions = edgeFunctions || [];
    
    if (!detectedEdgeFunctions || detectedEdgeFunctions.length === 0) {
      console.log(`[generate-liberation-pack] No edge functions provided, auto-detecting from files...`);
      
      // Detect Edge Functions from supabase/functions/**/index.ts
      for (const [path, content] of Object.entries(doubleCleanedFiles)) {
        const match = path.match(/^supabase\/functions\/([^/]+)\/index\.ts$/);
        if (match && match[1] !== '_shared') {
          const funcName = match[1];
          const funcContent = content as string;
          
          // Parse the edge function to extract metadata
          const parsed = parseEdgeFunctionAdvanced(funcName, funcContent);
          detectedEdgeFunctions.push(parsed);
          
          console.log(`[generate-liberation-pack] Auto-detected Edge Function: ${funcName} (auth=${parsed.hasAuth}, supabase=${parsed.usesSupabase}, stripe=${parsed.usesStripe})`);
        }
      }
      
      console.log(`[generate-liberation-pack] Total Edge Functions detected: ${detectedEdgeFunctions.length}`);
    }

    const zip = new JSZip();
    const safeName = projectName.toLowerCase().replace(/[^a-z0-9]/g, '-');

    // D√©terminer si le projet utilise l'IA
    const hasAIUsage = Object.values(doubleCleanedFiles).some(content => 
      (content as string).includes('openai') || 
      (content as string).includes('anthropic') || 
      (content as string).includes('OPENAI_API_KEY') ||
      (content as string).includes('ai-client') ||
      (content as string).includes('/chat/completions')
    );

    // ==========================================
    // 1. FRONTEND FILES (√† la racine du ZIP)
    // ==========================================
    
    // ==========================================
    // 1a. VALIDATION ET CORRECTION DU PACKAGE.JSON
    // ==========================================
    const allContentForValidation = Object.values(doubleCleanedFiles).join('\n');
    const packageJsonFix = validateAndFixPackageJson(doubleCleanedFiles, allContentForValidation);
    
    if (packageJsonFix.fixed) {
      console.log(`[generate-liberation-pack] Fixed package.json - added: ${packageJsonFix.added.join(', ')}`);
    }
    if (packageJsonFix.errors.length > 0) {
      console.warn(`[generate-liberation-pack] Package.json errors: ${packageJsonFix.errors.join(', ')}`);
    }
    
    // Fichiers source directement √† la racine (pas de dossier frontend/)
    for (const [path, content] of Object.entries(doubleCleanedFiles)) {
      if (!path.startsWith('supabase/')) {
        zip.file(path, content as string);
      }
    }
    
    // ==========================================
    // 1b. DOWNLOADED ASSETS (from client)
    // ==========================================
    const assetCount = Object.keys(assetFiles).length;
    if (assetCount > 0) {
      console.log(`[generate-liberation-pack] Adding ${assetCount} downloaded assets...`);
      
      for (const [assetPath, assetContent] of Object.entries(assetFiles)) {
        const content = assetContent as string;
        
        // Check if it's base64 encoded
        if (content.startsWith('data:')) {
          // Extract the base64 data
          const base64Match = content.match(/^data:([^;]+);base64,(.+)$/);
          if (base64Match) {
            const mimeType = base64Match[1];
            const base64Data = base64Match[2];
            
            // Decode base64 to binary
            const binaryString = atob(base64Data);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
              bytes[i] = binaryString.charCodeAt(i);
            }
            
            // Add as binary file to the ZIP (√† la racine)
            zip.file(assetPath, bytes);
            console.log(`[generate-liberation-pack] Added asset: ${assetPath} (${bytes.length} bytes)`);
          }
        } else {
          // Plain text content (e.g., comment for failed downloads)
          zip.file(assetPath, content);
        }
      }
    }
    
    // Ajouter le client IA configurable
    if (hasAIUsage) {
      zip.file('src/lib/ai-client.ts', AI_CLIENT_TEMPLATE);
    }
    
    zip.file('Dockerfile', FRONTEND_DOCKERFILE);
    zip.file('nginx.conf', NGINX_CONF);
    
    // ==========================================
    // 1c. POLYFILLS AUTOMATIQUES (pour √©viter erreurs TS)
    // ==========================================
    const polyfillResult = addPolyfillsToFrontend(zip, doubleCleanedFiles);
    if (polyfillResult.count > 0) {
      console.log(`[generate-liberation-pack] Added ${polyfillResult.count} polyfills: ${polyfillResult.added.join(', ')}`);
    }
    
    const caddyfile = `:80 {
  root * /usr/share/caddy
  try_files {path} /index.html
  file_server
  encode gzip
  
${includeBackend ? `  handle /api/* {
    reverse_proxy backend:3000
  }
  
  handle /health {
    reverse_proxy backend:3000
  }` : ''}
}

# Pour HTTPS avec domaine personnalis√©, remplacez :80 par:
# {$DOMAIN} {
#   ...
# }`;
    zip.file('Caddyfile', caddyfile);

    // ==========================================
    // 2. BACKEND (depuis Edge Functions - CONVERSION COMPL√àTE)
    // ==========================================
    let backendRoutes: string[] = [];
    const allEnvVars = new Set<string>(['PORT', 'NODE_ENV', 'JWT_SECRET']);

    if (includeBackend && detectedEdgeFunctions && detectedEdgeFunctions.length > 0) {
      console.log(`[generate-liberation-pack] Converting ${detectedEdgeFunctions.length} Edge Functions to Express backend...`);
      
      const backendFolder = zip.folder('backend')!;
      const srcFolder = backendFolder.folder('src')!;
      const routesFolder = srcFolder.folder('routes')!;
      const middlewareFolder = srcFolder.folder('middleware')!;
      const testsFolder = srcFolder.folder('__tests__')!;

      // Parse functions (they may already be parsed from auto-detection)
      const parsedFunctions = detectedEdgeFunctions.map((ef: EdgeFunctionInfo) => {
        // If already parsed (from auto-detection), use it directly
        if (ef.usesSupabase !== undefined) {
          ef.envVars.forEach((v: string) => allEnvVars.add(v));
          return ef;
        }
        // Otherwise parse it
        const parsed = parseEdgeFunctionAdvanced(ef.name, ef.content);
        parsed.envVars.forEach((v: string) => allEnvVars.add(v));
        return parsed;
      });

      const backend = generateExpressBackend(parsedFunctions);
      backendRoutes = backend.routes.map(r => r.name);

      // Generate route files with complete business logic
      for (const route of backend.routes) {
        routesFolder.file(`${route.name}.ts`, route.content);
        
        // Add test file for each route
        if (route.testFile) {
          testsFolder.file(`${route.name}.test.ts`, route.testFile);
        }
        
        console.log(`[generate-liberation-pack] Generated route: ${route.name} (preserved: ${route.preservedLogicPercentage}%, todos: ${route.manualTodosCount})`);
      }

      middlewareFolder.file('auth.ts', backend.middlewareAuth);
      srcFolder.file('index.ts', backend.indexTs);
      backendFolder.file('package.json', backend.packageJson);
      backendFolder.file('tsconfig.json', backend.tsconfigJson);
      backendFolder.file('Dockerfile', BACKEND_DOCKERFILE);

      // Garder les originaux pour r√©f√©rence
      const originalFolder = backendFolder.folder('_original-edge-functions')!;
      for (const ef of detectedEdgeFunctions) {
        originalFolder.file(`${ef.name}/index.ts`, ef.content);
      }

      // README pour le backend
      const backendReadme = `# üîå Backend API (Converti depuis Edge Functions)

## üìä Statistiques de conversion

| M√©trique | Valeur |
|----------|--------|
| Edge Functions converties | ${detectedEdgeFunctions.length} |
| Routes g√©n√©r√©es | ${backendRoutes.length} |
| Taux de pr√©servation moyen | ${Math.round(backend.routes.reduce((acc, r) => acc + r.preservedLogicPercentage, 0) / backend.routes.length)}% |

## üöÄ D√©marrage rapide

\`\`\`bash
cd backend
npm install
npm run dev
\`\`\`

## üìÇ Routes API

${backendRoutes.map(r => `- \`/api/${r.replace(/_/g, '-')}\``).join('\n')}

## üîß Structure

\`\`\`
backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.ts           # Point d'entr√©e Express
‚îÇ   ‚îú‚îÄ‚îÄ routes/            # Routes converties
‚îÇ   ‚îú‚îÄ‚îÄ middleware/        # Auth et autres middlewares
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/         # Tests unitaires
‚îú‚îÄ‚îÄ _original-edge-functions/  # Code Deno original (r√©f√©rence)
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ Dockerfile
\`\`\`

## ‚ö†Ô∏è Points √† v√©rifier

1. **Environnement**: Copiez \`.env.example\` vers \`.env\` et remplissez les valeurs
2. **Base de donn√©es**: V√©rifiez que \`DATABASE_URL\` pointe vers votre PostgreSQL
3. **Secrets**: Assurez-vous que tous les secrets sont configur√©s

## üìù TODOs manuels

Certaines conversions peuvent n√©cessiter des ajustements manuels. 
Recherchez \`// TODO\` dans les fichiers de routes.

---
*G√©n√©r√© automatiquement par InoPay Liberation Pack*
`;
      backendFolder.file('README.md', backendReadme);

      // .dockerignore
      backendFolder.file('.dockerignore', `node_modules
dist
.env
*.log
.git
_original-edge-functions
`);

      // .env.example pour le backend
      const backendEnvExample = `# Backend API Environment Variables
# Generated from Edge Functions conversion

PORT=3000
NODE_ENV=production

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# Authentication
JWT_SECRET=${crypto.randomUUID().replace(/-/g, '')}

# Supabase (si n√©cessaire)
SUPABASE_URL=
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# Services externes d√©tect√©s
${Array.from(allEnvVars)
  .filter(v => !['PORT', 'NODE_ENV', 'DATABASE_URL', 'JWT_SECRET', 'SUPABASE_URL', 'SUPABASE_ANON_KEY', 'SUPABASE_SERVICE_ROLE_KEY'].includes(v))
  .map(v => `${v}=`)
  .join('\n')}
`;
      backendFolder.file('.env.example', backendEnvExample);
      
      console.log(`[generate-liberation-pack] Backend conversion complete: ${backendRoutes.length} routes generated`);
    }

    // ==========================================
    // 3. DATABASE - EXTRACTION AUTOMATIQUE + EXPORT DONN√âES
    // ==========================================
    let extractedSchema: { sql: string; source: string; tables: string[] } = { 
      sql: '', 
      source: 'aucun', 
      tables: [] 
    };
    
    let dataExportSQL = '';
    let fullDatabaseExport = '';
    
    if (includeDatabase) {
      const dbFolder = zip.folder('database')!;
      const migrationsFolder = dbFolder.folder('migrations')!;

      // Extraction automatique du sch√©ma
      extractedSchema = extractSchemaFromProject(doubleCleanedFiles, sqlSchema);
      
      console.log(`[generate-liberation-pack] Schema extracted from: ${extractedSchema.source}, tables: ${extractedSchema.tables.length}`);

      // Validation du sch√©ma SQL
      const schemaValidation = validateSQLSchema(extractedSchema.sql);
      console.log(`[generate-liberation-pack] Schema validation: valid=${schemaValidation.isValid}, errors=${schemaValidation.errors.length}, warnings=${schemaValidation.warnings.length}`);

      migrationsFolder.file('001_schema.sql', extractedSchema.sql);
      
      // Rapport de validation
      migrationsFolder.file('VALIDATION_REPORT.md', generateValidationReport(schemaValidation));
      
      // ==========================================
      // EXPORT DES DONN√âES COMPL√àTES
      // ==========================================
      console.log(`[generate-liberation-pack] Exporting database data...`);
      
      try {
        // Liste des tables √† exporter
        const tablesToExport = [
          'admin_activity_logs',
          'admin_config',
          'banned_users',
          'cleaning_cache',
          'cleaning_estimates',
          'deployment_history',
          'email_campaigns',
          'email_contacts',
          'email_list_contacts',
          'email_lists',
          'email_logs',
          'email_sends',
          'email_templates',
          'health_check_logs',
          'liberation_upsell_views',
          'newsletter_subscribers',
          'otp_verifications',
          'pending_liberation_payments',
          'profiles',
          'projects_analysis',
          'security_audit_logs',
          'server_deployments',
          'subscriptions',
          'sync_configurations',
          'sync_history',
          'user_notifications',
          'user_purchases',
          'user_roles',
          'user_servers',
          'user_settings'
        ];
        
        const exportStats: Record<string, number> = {};
        let sqlInserts = '';
        
        for (const tableName of tablesToExport) {
          try {
            const { data, error } = await supabaseAdmin
              .from(tableName)
              .select('*');

            if (error) {
              console.error(`[generate-liberation-pack] Error fetching ${tableName}:`, error.message);
              exportStats[tableName] = 0;
            } else if (data && data.length > 0) {
              exportStats[tableName] = data.length;
              
              sqlInserts += `\n-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n`;
              sqlInserts += `-- Table: ${tableName} (${data.length} rows)\n`;
              sqlInserts += `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n`;
              
              for (const row of data) {
                const columns = Object.keys(row).join(', ');
                const values = Object.values(row).map(v => {
                  if (v === null) return 'NULL';
                  if (typeof v === 'boolean') return v ? 'TRUE' : 'FALSE';
                  if (typeof v === 'number') return v.toString();
                  if (Array.isArray(v)) {
                    return `ARRAY[${v.map(i => `'${String(i).replace(/'/g, "''")}'`).join(',')}]`;
                  }
                  if (typeof v === 'object') {
                    return `'${JSON.stringify(v).replace(/'/g, "''")}'::jsonb`;
                  }
                  return `'${String(v).replace(/'/g, "''")}'`;
                }).join(', ');
                
                sqlInserts += `INSERT INTO public.${tableName} (${columns}) VALUES (${values}) ON CONFLICT DO NOTHING;\n`;
              }
            } else {
              exportStats[tableName] = 0;
            }
          } catch (tableError) {
            console.error(`[generate-liberation-pack] Exception for ${tableName}:`, tableError);
            exportStats[tableName] = 0;
          }
        }
        
        const totalRows = Object.values(exportStats).reduce((a, b) => a + b, 0);
        console.log(`[generate-liberation-pack] Data export completed. Total rows: ${totalRows}`);
        
        // G√©n√©rer le fichier d'export des donn√©es
        dataExportSQL = `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- INOPAY DATA EXPORT - ${projectName}
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- Generated: ${new Date().toISOString()}
-- Total tables: ${Object.keys(exportStats).filter(k => exportStats[k] > 0).length}
-- Total rows: ${totalRows}
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- STATISTIQUES:
${Object.entries(exportStats)
  .filter(([_, count]) => count > 0)
  .map(([table, count]) => `-- ${table}: ${count} rows`)
  .join('\n')}

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- ATTENTION: Ex√©cutez 001_schema.sql AVANT ce fichier
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

BEGIN;
${sqlInserts}
COMMIT;

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- FIN DE L'EXPORT DES DONN√âES
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
`;

        migrationsFolder.file('003_data_export.sql', dataExportSQL);
        
        // ==========================================
        // FICHIER SQL COMPLET FUSIONN√â
        // ==========================================
        fullDatabaseExport = `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- FULL DATABASE EXPORT - ${projectName}
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- 
-- Ce fichier contient TOUT ce qu'il faut pour reconstruire votre base de donn√©es:
--   1. Types et enums
--   2. Fonctions utilitaires
--   3. Tables et contraintes
--   4. Policies RLS
--   5. Triggers
--   6. Donn√©es existantes (INSERT statements)
--
-- Generated: ${new Date().toISOString()}
-- Source: InoPay Liberation Pack
-- 
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- PARTIE 1: SCH√âMA (Tables, Types, Fonctions, Policies)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

${extractedSchema.sql}

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- PARTIE 2: DONN√âES (${totalRows} lignes au total)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

${totalRows > 0 ? `BEGIN;
${sqlInserts}
COMMIT;` : `-- Aucune donn√©e √† exporter`}

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- FIN DU FULL DATABASE EXPORT
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- INSTRUCTIONS D'IMPORT:
-- 
-- Option 1 - PostgreSQL direct:
--   psql -h localhost -U postgres -d ${safeName} -f FULL_DATABASE_EXPORT.sql
-- 
-- Option 2 - Docker:
--   docker compose exec postgres psql -U app -d app -f /migrations/FULL_DATABASE_EXPORT.sql
-- 
-- Option 3 - Supabase self-hosted:
--   1. Allez dans SQL Editor de votre dashboard
--   2. Collez le contenu de ce fichier
--   3. Ex√©cutez
-- 
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
`;

        dbFolder.file('FULL_DATABASE_EXPORT.sql', fullDatabaseExport);
        
      } catch (exportError) {
        console.error(`[generate-liberation-pack] Data export error:`, exportError);
        // On continue m√™me si l'export √©choue - le sch√©ma sera toujours inclus
        dataExportSQL = `-- Erreur lors de l'export des donn√©es\n-- Cause: ${exportError}\n`;
        migrationsFolder.file('003_data_export.sql', dataExportSQL);
      }
      
      // Seed file (template pour donn√©es d'exemple)
      migrationsFolder.file('002_seed.sql', `-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DONN√âES INITIALES - ${projectName}
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- 
-- Ce fichier est un template pour vos donn√©es initiales.
-- Pour les donn√©es existantes export√©es, voir: 003_data_export.sql
--
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Exemples:
-- INSERT INTO users (email, role) VALUES ('admin@example.com', 'admin');
-- INSERT INTO settings (key, value) VALUES ('app_name', '${projectName}');
`);

      // README pour la base de donn√©es (enrichi)
      const tablesListMd = extractedSchema.tables.length > 0 
        ? extractedSchema.tables.map(t => `- \`${t}\``).join('\n')
        : '- Aucune table d√©tect√©e automatiquement';
      
      const warningsListMd = schemaValidation.warnings.length > 0 
        ? `\n## ‚ö†Ô∏è Points d'attention\n${schemaValidation.warnings.slice(0, 5).map(w => `- ${w.message}`).join('\n')}${schemaValidation.warnings.length > 5 ? `\n... et ${schemaValidation.warnings.length - 5} autres avertissements` : ''}\n`
        : '';

      migrationsFolder.file('README.md', `# üì¶ Migrations de Base de Donn√©es

## Source du Sch√©ma
Ce sch√©ma a √©t√© extrait automatiquement depuis: **${extractedSchema.source}**

## Fichiers Inclus

| Fichier | Description |
|---------|-------------|
| \`001_schema.sql\` | Structure des tables, types, fonctions, policies RLS |
| \`002_seed.sql\` | Template pour donn√©es initiales (optionnel) |
| \`003_data_export.sql\` | **Export complet de vos donn√©es actuelles** |
| \`VALIDATION_REPORT.md\` | Rapport de validation du sch√©ma |
| \`../FULL_DATABASE_EXPORT.sql\` | **Fichier unique avec sch√©ma + donn√©es** |

## üöÄ Import Rapide (1 commande)

Pour reconstruire votre base de donn√©es sur un VPS:

\`\`\`bash
# Option 1: Fichier unique complet
psql -h localhost -U postgres -d ${safeName} -f FULL_DATABASE_EXPORT.sql

# Option 2: Docker
docker compose exec postgres psql -U app -d app -f /app/database/FULL_DATABASE_EXPORT.sql

# Option 3: Script automatique
./scripts/import-database.sh
\`\`\`

## Validation
${schemaValidation.isValid 
  ? '‚úÖ Le sch√©ma a pass√© la validation avec succ√®s'
  : `‚ö†Ô∏è ${schemaValidation.errors.length} erreur(s) d√©tect√©e(s) - voir VALIDATION_REPORT.md`}

| M√©trique | Valeur |
|----------|--------|
| Tables | ${schemaValidation.stats.tables} |
| Colonnes | ${schemaValidation.stats.columns} |
| Cl√©s √©trang√®res | ${schemaValidation.stats.foreignKeys} |
| Policies RLS | ${schemaValidation.stats.policies} |

## Tables D√©tect√©es
${tablesListMd}
${warningsListMd}
## Comment Appliquer (Ordre Recommand√©)

### Option 1: PostgreSQL Direct
\`\`\`bash
# Cr√©er la base de donn√©es
createdb -h localhost -U postgres ${safeName}

# Importer le sch√©ma
psql -h localhost -U postgres -d ${safeName} -f 001_schema.sql

# Importer les donn√©es
psql -h localhost -U postgres -d ${safeName} -f 003_data_export.sql
\`\`\`

### Option 2: Docker
\`\`\`bash
docker compose exec postgres psql -U app -d app -f /migrations/001_schema.sql
docker compose exec postgres psql -U app -d app -f /migrations/003_data_export.sql
\`\`\`

### Option 3: Supabase Self-Hosted
1. Acc√©dez √† votre dashboard Supabase local
2. Allez dans SQL Editor
3. Copiez-collez le contenu de FULL_DATABASE_EXPORT.sql
4. Ex√©cutez

## Notes Importantes

1. **V√©rifiez les policies RLS** - Adaptez-les √† votre syst√®me d'authentification
2. **current_user_id()** - Cette fonction remplace auth.uid() de Supabase
3. **Ordre d'ex√©cution** - Respectez l'ordre des fichiers (001, 002, 003...)
4. **Rapport de validation** - Consultez VALIDATION_REPORT.md pour les d√©tails
5. **Donn√©es sensibles** - V√©rifiez 003_data_export.sql avant import en production

## Personnalisation

Si vous utilisez un syst√®me d'auth diff√©rent, modifiez la fonction \`current_user_id()\`:

\`\`\`sql
-- Pour JWT avec PostgREST
CREATE OR REPLACE FUNCTION current_user_id()
RETURNS UUID AS $$
  SELECT NULLIF(current_setting('request.jwt.claims', true)::json->>'sub', '')::UUID;
$$ LANGUAGE sql STABLE;

-- Pour une variable de session
CREATE OR REPLACE FUNCTION current_user_id()
RETURNS UUID AS $$
  SELECT current_setting('app.current_user_id')::UUID;
$$ LANGUAGE sql STABLE;
\`\`\`
`);

      allEnvVars.add('POSTGRES_USER');
      allEnvVars.add('POSTGRES_PASSWORD');
      allEnvVars.add('POSTGRES_DB');
      allEnvVars.add('DATABASE_URL');
      
      // Store validation for summary
      (extractedSchema as any).validation = schemaValidation;
    }

    // ==========================================
    // 4. SERVICES OPEN SOURCE
    // ==========================================
    const servicesFolder = zip.folder('services')!;
    
    // Ollama
    const ollamaFolder = servicesFolder.folder('ollama')!;
    ollamaFolder.file('docker-compose.yml', OLLAMA_DOCKER_COMPOSE);
    
    // Meilisearch
    const meilisearchFolder = servicesFolder.folder('meilisearch')!;
    meilisearchFolder.file('docker-compose.yml', MEILISEARCH_DOCKER_COMPOSE);
    
    // MinIO
    const minioFolder = servicesFolder.folder('minio')!;
    minioFolder.file('docker-compose.yml', MINIO_DOCKER_COMPOSE);

    // Guide des services
    zip.file('OPEN_SOURCE_SERVICES.md', OPEN_SOURCE_SERVICES_GUIDE);

    // ==========================================
    // 4b. AUTH SERVICE AUTO-INCLUS
    // ==========================================
    const authFolder = servicesFolder.folder('auth')!;
    
    // Generate self-hosted auth API
    const authApiCode = generateSelfHostedAuthAPI(safeName);
    authFolder.file('index.ts', authApiCode.indexTs);
    authFolder.file('package.json', authApiCode.packageJson);
    authFolder.file('Dockerfile', authApiCode.dockerfile);
    authFolder.file('tsconfig.json', authApiCode.tsconfigJson);
    authFolder.file('schema.sql', authApiCode.schemaSql);
    authFolder.file('docker-compose.yml', authApiCode.dockerCompose);
    authFolder.file('README.md', authApiCode.readme);
    
    // Auth client adapter for frontend (√† la racine)
    zip.file('src/lib/auth-client.ts', generateAuthClientAdapter());
    
    // User migration script
    authFolder.file('migrate-users.ts', authApiCode.migrateScript);

    // ==========================================
    // 4c. WEBHOOK MIGRATION GUIDES
    // ==========================================
    if (includeBackend && detectedEdgeFunctions?.length > 0) {
      const webhooksFolder = zip.folder('docs/webhooks')!;
      
      // Collect webhook info from all converted functions
      const webhookFunctions = detectedEdgeFunctions.filter((f: EdgeFunctionInfo) => f.webhookDetected);
      
      if (webhookFunctions.length > 0) {
        let webhookGuide = `# üîÑ Guide de Migration des Webhooks

Ce projet contient ${webhookFunctions.length} webhook(s) √† reconfigurer.

## Webhooks D√©tect√©s

`;
        
        for (const func of webhookFunctions) {
          const info = generateWebhookMigrationInfo(func.webhookType || 'custom', func.name);
          webhookGuide += `### ${func.name}
- **Type**: ${info.type}
- **Header de signature**: \`${info.signatureHeader}\`
- **Nouvelle URL**: \`https://VOTRE_DOMAINE/api/${func.name.replace(/-/g, '_')}\`

${info.reconfigurationGuide}

---

`;
          webhooksFolder.file(`${func.name}.md`, info.reconfigurationGuide);
        }
        
        webhooksFolder.file('README.md', webhookGuide);
      }
    }

    // ==========================================
    // 5. ROOT FILES
    // ==========================================
    // Merge server-detected env vars with client-detected env vars
    if (clientEnvVars && Array.isArray(clientEnvVars)) {
      for (const envVar of clientEnvVars) {
        if (typeof envVar === 'string' && envVar.length > 0) {
          allEnvVars.add(envVar);
        }
      }
    }
    const envVarsArray = Array.from(allEnvVars);
    
    // docker-compose.yml principal
    zip.file('docker-compose.yml', generateDockerCompose(
      projectName, 
      envVarsArray, 
      includeBackend && detectedEdgeFunctions?.length > 0,
      includeDatabase,
      hasAIUsage
    ));

    // docker-compose-full.yml avec tous les services
    zip.file('docker-compose.full.yml', generateDockerComposeFull(projectName, envVarsArray));

    // .env.example complet
    const envExample = `# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ${projectName} - Configuration
# Copiez vers .env et remplissez les valeurs
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# G√âN√âRAL
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DOMAIN=
NODE_ENV=production

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# S√âCURIT√â (g√©n√©r√©s automatiquement par quick-deploy.sh)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
JWT_SECRET=

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚ö° FRONTEND - VARIABLES VITE (OBLIGATOIRES POUR COOLIFY)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Ces variables sont inject√©es au BUILD TIME via Docker build args
# Dans Coolify: Settings ‚Üí Build ‚Üí Build Arguments
#
# Pour un Supabase self-hosted, utilisez votre URL locale
# Pour un Supabase cloud, utilisez vos credentials existants

VITE_SUPABASE_URL=https://votre-projet.supabase.co
VITE_SUPABASE_ANON_KEY=eyJ...votre_cle_anon
VITE_SUPABASE_PROJECT_ID=votre-project-id
VITE_APP_URL=https://votre-domaine.com

${includeDatabase ? `# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# BASE DE DONN√âES
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
POSTGRES_USER=app
POSTGRES_PASSWORD=
POSTGRES_DB=app
DATABASE_URL=postgresql://app:VOTRE_MOT_DE_PASSE@postgres:5432/app
` : ''}

${hasAIUsage ? `# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# INTELLIGENCE ARTIFICIELLE
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Provider: ollama | openrouter | openai
AI_PROVIDER=ollama

# Ollama (local - gratuit)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama2

# OpenRouter (alternative cloud √©conomique)
# OPENROUTER_API_KEY=
# OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct:free

# OpenAI (si n√©cessaire)
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini
` : ''}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# SERVICES EXTERNES (optionnels)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
${envVarsArray
  .filter(v => !['PORT', 'NODE_ENV', 'DOMAIN', 'DATABASE_URL', 'POSTGRES_USER', 'POSTGRES_PASSWORD', 'POSTGRES_DB', 'JWT_SECRET', 'AI_PROVIDER', 'OLLAMA_URL', 'OLLAMA_MODEL', 'OPENROUTER_API_KEY', 'OPENROUTER_MODEL', 'OPENAI_API_KEY', 'OPENAI_MODEL', 'SUPABASE_URL', 'SUPABASE_ANON_KEY', 'SUPABASE_SERVICE_ROLE_KEY', 'VITE_SUPABASE_URL', 'VITE_SUPABASE_ANON_KEY', 'VITE_SUPABASE_PROJECT_ID', 'VITE_APP_URL'].includes(v))
  .map(v => `${v}=`)
  .join('\n')}

# Stripe (paiements)
# STRIPE_SECRET_KEY=sk_live_...
# STRIPE_WEBHOOK_SECRET=whsec_...

# Resend (emails)
# RESEND_API_KEY=re_...

# Meilisearch (recherche)
# MEILISEARCH_MASTER_KEY=

# MinIO (stockage S3)
# MINIO_ACCESS_KEY=minioadmin
# MINIO_SECRET_KEY=

# Backend Supabase (si utilisation de l'API)
# SUPABASE_URL=
# SUPABASE_ANON_KEY=
# SUPABASE_SERVICE_ROLE_KEY=

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üöÄ INSTRUCTIONS COOLIFY
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 1. Dans Coolify ‚Üí New Resource ‚Üí Docker Compose (depuis GitHub)
# 2. Allez dans Settings ‚Üí Build ‚Üí Build Arguments
# 3. Ajoutez les variables VITE_* comme BUILD ARGS:
#    - VITE_SUPABASE_URL
#    - VITE_SUPABASE_ANON_KEY
#    - VITE_SUPABASE_PROJECT_ID
#    - VITE_APP_URL
# 4. Dans Environment Variables, ajoutez les autres variables
# 5. Cliquez Deploy
#
# Les variables VITE_* doivent √™tre en BUILD ARGS car Vite
# les int√®gre au moment du build, pas au runtime!
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
`;
    zip.file('.env.example', envExample);

    // Deploy guide HTML enrichi
    zip.file('DEPLOY_GUIDE.html', generateDeployGuide(
      projectName,
      envVarsArray,
      includeBackend && detectedEdgeFunctions?.length > 0,
      includeDatabase,
      sovereigntyCheck.score,
      hasAIUsage
    ));

    // Quick deploy script
    const scriptsFolder = zip.folder('scripts')!;
    scriptsFolder.file('quick-deploy.sh', generateQuickDeployScript(projectName, includeDatabase, hasAIUsage));

    // Post-deployment checklist
    const backendRouteNames = detectedEdgeFunctions?.map((f: EdgeFunctionInfo) => f.name.replace(/-/g, '_')) || [];
    const webhooksList = detectedEdgeFunctions?.filter((f: EdgeFunctionInfo) => f.webhookDetected).map((f: EdgeFunctionInfo) => ({ name: f.name, type: f.webhookType || 'custom' })) || [];
    zip.file('POST_DEPLOY_CHECKLIST.html', generatePostDeploymentChecklist(
      projectName,
      includeBackend && detectedEdgeFunctions?.length > 0,
      includeDatabase,
      true, // hasAuth
      backendRouteNames,
      webhooksList,
      envVarsArray
    ));

    // ==========================================
    // 6. GUIDE COMPLET DE LIB√âRATION (Coolify + GitHub + Supabase SH)
    // ==========================================
    const docsFolder = zip.folder('docs')!;
    
    // Guide HTML interactif ultra-d√©taill√©
    zip.file('COMPLETE_LIBERATION_GUIDE.html', generateCompleteLiberationGuideHTML(
      projectName,
      includeBackend && detectedEdgeFunctions?.length > 0,
      includeDatabase,
      true, // hasAuth
      envVarsArray,
      backendRouteNames,
      webhooksList.map((w: { name: string; type: string }) => ({ provider: w.type, endpoint: `/api/${w.name.replace(/-/g, '_')}` })),
      extractedSchema.sql
    ));

    // Scripts d'automatisation
    scriptsFolder.file('setup-coolify.sh', generateSetupCoolifyScript(projectName, envVarsArray));
    scriptsFolder.file('import-supabase-schema.sh', generateImportSupabaseSchemaScript(projectName));
    
    // Script d'import de base de donn√©es complet
    scriptsFolder.file('import-database.sh', `#!/bin/bash
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# IMPORT DATABASE - ${projectName}
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Ce script importe le sch√©ma ET les donn√©es dans votre base PostgreSQL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

set -e

# Couleurs
RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
BLUE='\\033[0;34m'
NC='\\033[0m'

echo -e "\${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\${NC}"
echo -e "\${BLUE}  IMPORT BASE DE DONN√âES - ${projectName}\${NC}"
echo -e "\${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\${NC}"
echo ""

# Configuration (√† personnaliser)
DB_HOST=\${DB_HOST:-localhost}
DB_PORT=\${DB_PORT:-5432}
DB_USER=\${DB_USER:-postgres}
DB_NAME=\${DB_NAME:-${safeName}}
DB_PASSWORD=\${DB_PASSWORD:-}

# Chemin des fichiers
SCRIPT_DIR="\$(cd "\$(dirname "\${BASH_SOURCE[0]}")" && pwd)"
DB_DIR="\$SCRIPT_DIR/../database"

# V√©rification des fichiers
echo -e "\${YELLOW}[1/5] V√©rification des fichiers...\${NC}"
if [ -f "\$DB_DIR/FULL_DATABASE_EXPORT.sql" ]; then
    echo -e "\${GREEN}  ‚úì FULL_DATABASE_EXPORT.sql trouv√©\${NC}"
    USE_FULL_EXPORT=true
elif [ -f "\$DB_DIR/migrations/001_schema.sql" ]; then
    echo -e "\${GREEN}  ‚úì 001_schema.sql trouv√©\${NC}"
    USE_FULL_EXPORT=false
else
    echo -e "\${RED}  ‚úó Aucun fichier SQL trouv√©!\${NC}"
    exit 1
fi

# Test de connexion
echo -e "\${YELLOW}[2/5] Test de connexion √† PostgreSQL...\${NC}"
if [ -n "\$DB_PASSWORD" ]; then
    export PGPASSWORD="\$DB_PASSWORD"
fi

if psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -d postgres -c "SELECT 1" > /dev/null 2>&1; then
    echo -e "\${GREEN}  ‚úì Connexion r√©ussie\${NC}"
else
    echo -e "\${RED}  ‚úó Impossible de se connecter √† PostgreSQL\${NC}"
    echo -e "  V√©rifiez: DB_HOST, DB_PORT, DB_USER, DB_PASSWORD"
    exit 1
fi

# Cr√©ation de la base si n√©cessaire
echo -e "\${YELLOW}[3/5] V√©rification/cr√©ation de la base...\${NC}"
if psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -lqt | cut -d \\| -f 1 | grep -qw "\$DB_NAME"; then
    echo -e "\${GREEN}  ‚úì Base '\$DB_NAME' existe d√©j√†\${NC}"
else
    echo -e "  Cr√©ation de la base '\$DB_NAME'..."
    createdb -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" "\$DB_NAME"
    echo -e "\${GREEN}  ‚úì Base cr√©√©e\${NC}"
fi

# Import
echo -e "\${YELLOW}[4/5] Import des donn√©es...\${NC}"
if [ "\$USE_FULL_EXPORT" = true ]; then
    echo -e "  Import de FULL_DATABASE_EXPORT.sql (sch√©ma + donn√©es)..."
    psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -d "\$DB_NAME" -f "\$DB_DIR/FULL_DATABASE_EXPORT.sql"
else
    echo -e "  Import de 001_schema.sql..."
    psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -d "\$DB_NAME" -f "\$DB_DIR/migrations/001_schema.sql"
    
    if [ -f "\$DB_DIR/migrations/003_data_export.sql" ]; then
        echo -e "  Import de 003_data_export.sql..."
        psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -d "\$DB_NAME" -f "\$DB_DIR/migrations/003_data_export.sql"
    fi
fi
echo -e "\${GREEN}  ‚úì Import termin√©\${NC}"

# Statistiques
echo -e "\${YELLOW}[5/5] V√©rification...\${NC}"
TABLE_COUNT=\$(psql -h "\$DB_HOST" -p "\$DB_PORT" -U "\$DB_USER" -d "\$DB_NAME" -t -c "SELECT count(*) FROM information_schema.tables WHERE table_schema = 'public'")
echo -e "\${GREEN}  ‚úì \$TABLE_COUNT tables import√©es\${NC}"

echo ""
echo -e "\${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\${NC}"
echo -e "\${GREEN}  ‚úì IMPORT TERMIN√â AVEC SUCC√àS!\${NC}"
echo -e "\${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\${NC}"
echo ""
echo -e "Votre base de donn√©es est pr√™te: \${BLUE}\$DB_NAME\${NC}"
echo ""
`);

    // Guide Markdown pour Coolify
    docsFolder.file('COOLIFY_STEP_BY_STEP.md', generateCoolifyStepByStepGuide(projectName));

    // Sovereignty report
    zip.file('SOVEREIGNTY_REPORT.md', generateSovereigntyReport(
      projectName,
      sovereigntyCheck,
      Object.keys(doubleCleanedFiles).length
    ));

    // ==========================================
    // 7. NCS PHASE: COMPREHENSIVE REPORTS
    // ==========================================
    const reportsFolder = zip.folder('reports')!;
    
    // Project Graph (NCS Phase 1)
    const projectGraph = {
      name: projectName,
      framework: 'vite-react',
      structure: {
        hasBackend: includeBackend && detectedEdgeFunctions?.length > 0,
        hasFrontend: true,
        hasDatabase: includeDatabase,
        hasEdgeFunctions: detectedEdgeFunctions?.length > 0,
      },
      files: {
        total: Object.keys(doubleCleanedFiles).length,
        frontend: Object.keys(doubleCleanedFiles).filter(p => p.match(/\.(tsx|jsx|css)$/)).length,
        backend: backendRoutes.length,
        config: Object.keys(doubleCleanedFiles).filter(p => p.match(/\.(json|toml|yaml)$/)).length,
        assets: Object.keys(doubleCleanedFiles).filter(p => p.match(/\.(png|jpg|svg|webp)$/)).length,
      },
      edgeFunctions: detectedEdgeFunctions?.map((f: EdgeFunctionInfo) => f.name) || [],
      envVars: envVarsArray,
      webhooks: webhooksList.map((w: { name: string }) => w.name),
    };
    reportsFolder.file('project_graph.json', JSON.stringify(projectGraph, null, 2));
    
    // Proprietary Map (NCS Phase 2)
    const proprietaryMap = {
      totalIssues: sovereigntyCheck.criticalIssues.length + sovereigntyCheck.warnings.length,
      criticalCount: sovereigntyCheck.criticalIssues.length,
      warningCount: sovereigntyCheck.warnings.length,
      entries: [
        ...sovereigntyCheck.criticalIssues.map(issue => ({ type: 'critical', issue })),
        ...sovereigntyCheck.warnings.map(issue => ({ type: 'warning', issue })),
      ],
      summary: {
        sovereigntyScore: sovereigntyCheck.score,
        isClean: sovereigntyCheck.isClean,
      }
    };
    reportsFolder.file('proprietary_map.json', JSON.stringify(proprietaryMap, null, 2));
    
    // Security Report (NCS Phase 3) - basic version
    const securityReport = {
      isSecure: sovereigntyCheck.criticalIssues.length === 0,
      score: sovereigntyCheck.score,
      criticalIssues: sovereigntyCheck.criticalIssues.length,
      summary: sovereigntyCheck.isClean 
        ? '‚úÖ Code s√©curis√© - aucun probl√®me critique'
        : '‚ö†Ô∏è Probl√®mes d√©tect√©s - voir proprietary_map.json',
    };
    reportsFolder.file('security_report.json', JSON.stringify(securityReport, null, 2));
    
    // Coolify Readiness (NCS Phase 6)
    const coolifyReady = {
      ready: sovereigntyCheck.score >= 70,
      score: sovereigntyCheck.score,
      checks: {
        dockerfile: { passed: true, issues: [] },
        dependencies: { passed: true, missing: [] },
        envVars: { passed: true, required: envVarsArray, missing: [] },
        ports: { passed: true, exposed: [80, 443] },
        healthcheck: { passed: true, path: '/health' },
        noProprietaryRuntime: { passed: sovereigntyCheck.isClean, found: sovereigntyCheck.criticalIssues },
      },
      recommendations: sovereigntyCheck.isClean ? [] : ['Corrigez les probl√®mes critiques'],
    };
    reportsFolder.file('coolify_ready.json', JSON.stringify(coolifyReady, null, 2));
    
    // Dependency Report (NCS Phase 4) - FULL ANALYSIS
    const dependencyReport = generateDependencyReport(doubleCleanedFiles, projectName);
    reportsFolder.file('dependency_report.json', JSON.stringify(dependencyReport, null, 2));
    
    // NOTE: rewriteLog and dockerValidation moved after securityAudit and componentFiles declarations (see below)
    
    // Docker Build Validation placeholder - actual generation happens after componentFiles is declared
    
    // Smoke Tests (NCS Phase 5)
    if (includeBackend && backendRouteNames.length > 0) {
      const smokeTestContent = `/**
 * Smoke Tests - ${projectName}
 * Generated by InoPay Liberation Pack NCS
 */
import { describe, it, expect } from 'vitest';

const API_URL = process.env.API_URL || 'http://localhost:3000';

describe('API Smoke Tests', () => {
  it('health check', async () => {
    const res = await fetch(\`\${API_URL}/health\`);
    expect(res.status).toBe(200);
  });
${backendRouteNames.slice(0, 10).map((route: string) => `
  it('${route} responds', async () => {
    const res = await fetch(\`\${API_URL}/api/${route}\`, { method: 'OPTIONS' });
    expect([200, 204, 401, 405]).toContain(res.status);
  });`).join('')}
});`;
      const testsFolder = zip.folder('backend/tests')!;
      testsFolder.file('smoke.test.ts', smokeTestContent);
    }
    
    // Lint configs (NCS Phase 7)
    zip.file('.prettierrc', `{
  "semi": true,
  "singleQuote": true,
  "tabWidth": 2,
  "trailingComma": "es5",
  "printWidth": 100
}`);
    zip.file('.eslintrc.cjs', `module.exports = {
  root: true,
  extends: ['eslint:recommended', 'plugin:@typescript-eslint/recommended', 'prettier'],
  parser: '@typescript-eslint/parser',
  plugins: ['@typescript-eslint'],
  rules: { 'no-console': 'warn' },
};`);

    // ==========================================
    // NCS V2.0 - LA GRANDE MESSE DE LIB√âRATION
    // ==========================================
    console.log('[generate-liberation-pack] NCS V2.0 - Generating advanced reports...');
    
    // PHASE 1: Sovereignty Manifest (SHA-256 signed) + Badge
    const manifest = await generateSovereigntyManifest(projectName, sovereigntyCheck, doubleCleanedFiles, 100, backendRouteNames.length, backendRoutes.length);
    zip.file('sovereignty_manifest.json', JSON.stringify(manifest, null, 2));
    zip.file('SOVEREIGNTY_BADGE.svg', generateSovereigntyBadge(sovereigntyCheck.score, projectName));
    
    // PHASE 2: Multi-Deployment Configs
    const deployConfigsFolder = zip.folder('deployment-configs')!;
    deployConfigsFolder.file('fly.toml', generateFlyConfig(projectName, includeBackend, includeDatabase));
    deployConfigsFolder.file('render.yaml', generateRenderConfig(projectName, includeBackend));
    deployConfigsFolder.file('railway.json', generateRailwayConfig());
    const helmChart = generateHelmChart(projectName);
    for (const [path, content] of Object.entries(helmChart)) { deployConfigsFolder.file(`helm/${path}`, content); }
    deployConfigsFolder.file('ansible/deploy.yml', generateAnsiblePlaybook(projectName));
    
    // PHASE 3 & 6: OWASP + Security Audits
    const owaspReport = runOwaspAudit(doubleCleanedFiles);
    const securityAudit = runSecurityAudit(doubleCleanedFiles);
    reportsFolder.file('owasp_compliance.json', JSON.stringify(owaspReport, null, 2));
    reportsFolder.file('security_audit_v2.json', JSON.stringify(securityAudit, null, 2));
    
    // PHASE 4: Auto-Generated Tests (ENHANCED)
    const ncsTestsFolder = zip.folder('tests')!;
    const componentFiles = Object.keys(doubleCleanedFiles).filter(p => p.match(/\/components\/.*\.tsx$/));
    const hookFiles = Object.keys(doubleCleanedFiles).filter(p => p.match(/\/hooks\/.*\.tsx?$/));
    const libFiles = Object.keys(doubleCleanedFiles).filter(p => p.match(/\/lib\/.*\.tsx?$/));
    
    ncsTestsFolder.file('unit/components.test.ts', generateUnitTests(componentFiles, projectName));
    ncsTestsFolder.file('unit/hooks.test.ts', generateHookTests(hookFiles, projectName));
    ncsTestsFolder.file('integration/api.test.ts', generateIntegrationTests(backendRouteNames, projectName));
    ncsTestsFolder.file('security/security.test.ts', generateSecurityTests(projectName));
    ncsTestsFolder.file('security/owasp.test.ts', generateOwaspTests(projectName));
    ncsTestsFolder.file('e2e/smoke.test.ts', generateE2ETests(projectName, backendRouteNames));
    
    // Vitest configuration
    ncsTestsFolder.file('vitest.config.ts', generateVitestConfig(projectName));
    ncsTestsFolder.file('setup.ts', generateTestSetup());
    
    // Rewrite Log (NCS Phase 8) - ENHANCED - moved here after componentFiles and securityAudit are declared
    const rewriteLog = {
      version: '2.0',
      generatedAt: new Date().toISOString(),
      projectName,
      totalFilesProcessed: Object.keys(doubleCleanedFiles).length,
      totalFilesModified: totalServerChanges,
      phases: {
        ingestion: { status: 'completed', filesExtracted: Object.keys(doubleCleanedFiles).length },
        proprietaryScan: { status: 'completed', issuesFound: sovereigntyCheck.criticalIssues.length + sovereigntyCheck.warnings.length },
        astAnalysis: { status: 'completed', dependenciesAnalyzed: dependencyReport.npm.total },
        rewriting: { status: 'completed', filesRewritten: totalServerChanges },
        securityPurification: { status: 'completed', score: securityAudit.score },
        stabilization: { status: 'completed', lintConfigsGenerated: 2 },
        packGeneration: { status: 'completed', routesConverted: backendRoutes.length },
        validation: { status: 'completed', dockerValidated: true, testsGenerated: componentFiles.length + backendRouteNames.length },
      },
      transformations: sovereigntyCheck.criticalIssues.map((issue: string) => ({ type: 'critical_fix', description: issue })),
      summary: `Pack de lib√©ration NCS v2.0 g√©n√©r√© avec ${backendRoutes.length} routes backend, ${componentFiles.length} composants test√©s`,
    };
    reportsFolder.file('rewrite_log.json', JSON.stringify(rewriteLog, null, 2));
    
    // Docker Build Validation (NCS Phase 8)
    const dockerValidation = validateDockerBuild(doubleCleanedFiles, includeBackend, includeDatabase);
    reportsFolder.file('docker_validation.json', JSON.stringify(dockerValidation, null, 2));
    
    // ==========================================
    // PHASE PRODUCTION READY - VALIDATION FINALE
    // ==========================================
    console.log('[generate-liberation-pack] Running Production Ready validation...');
    
    const productionReadyReport = validateProductionReady(
      doubleCleanedFiles,
      projectName,
      includeBackend && detectedEdgeFunctions?.length > 0,
      includeDatabase,
      sovereigntyCheck.score,
      securityAudit.score
    );
    
    reportsFolder.file('production_ready_report.json', JSON.stringify(productionReadyReport, null, 2));
    
    // ZIP Integrity Report
    const zipIntegrityReport = generateZipIntegrityReport(doubleCleanedFiles);
    reportsFolder.file('zip_integrity.md', zipIntegrityReport);
    
    // Log critical blockers
    if (productionReadyReport.criticalBlockers.length > 0) {
      console.warn('[generate-liberation-pack] CRITICAL BLOCKERS:', productionReadyReport.criticalBlockers);
    }
    
    console.log(`[generate-liberation-pack] Production Ready: ${productionReadyReport.isProductionReady ? 'YES' : 'NO'} (Score: ${productionReadyReport.overallScore}%)`);
    
    // PHASE 5: Full Liberation Report (10 pages HTML)
    zip.file('LIBERATION_REPORT_FULL.html', generateFullLiberationReport(projectName, manifest, owaspReport, securityAudit));
    
    // PHASE 7: Architecture Diagrams
    const edgeFunctionNames = detectedEdgeFunctions?.map((f: EdgeFunctionInfo) => f.name) || [];
    docsFolder.file('ARCHITECTURE.md', generateArchitectureDiagram(projectName, includeBackend, includeDatabase, edgeFunctionNames));
    
    // PHASE 9: Secrets Vault Integration
    const secretsFolder = zip.folder('secrets')!;
    secretsFolder.file('vault-policy.hcl', generateVaultPolicy(projectName, envVarsArray));
    secretsFolder.file('import-to-vault.sh', generateVaultImportScript(projectName, envVarsArray));
    secretsFolder.file('doppler.yaml', generateDopplerConfig(projectName));
    
    console.log('[generate-liberation-pack] NCS V2.0 - All phases completed');

    // README
    const readme = `# ${projectName} - Liberation Pack üõ°Ô∏è

## Score de Souverainet√©: ${sovereigntyCheck.score}%

Ce pack contient votre application compl√®tement lib√©r√©e des d√©pendances propri√©taires,
pr√™te √† √™tre d√©ploy√©e sur votre propre infrastructure.

---

## üöÄ D√©ploiement Rapide (5 minutes)

\`\`\`bash
# 1. Transf√©rez ce dossier sur votre VPS
scp -r liberation-pack root@VOTRE_IP:/opt/apps/

# 2. Connectez-vous et ex√©cutez
ssh root@VOTRE_IP
cd /opt/apps/${safeName}
sudo ./scripts/quick-deploy.sh
\`\`\`

**C'est tout!** Votre app est accessible sur http://VOTRE_IP

---

## üìñ Documentation

| Fichier | Description |
|---------|-------------|
| \`DEPLOY_GUIDE.html\` | Guide interactif complet |
| \`SOVEREIGNTY_REPORT.md\` | D√©tails du nettoyage effectu√© |
| \`OPEN_SOURCE_SERVICES.md\` | Guide des alternatives open source |

---

## üìÅ Structure

\`\`\`
${safeName}/
‚îú‚îÄ‚îÄ src/                    # Code source React
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai-client.ts    # Client IA configurable
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ public/                 # Assets statiques
‚îú‚îÄ‚îÄ package.json            # D√©pendances
‚îú‚îÄ‚îÄ vite.config.ts          # Configuration Vite
‚îú‚îÄ‚îÄ tailwind.config.ts      # Configuration Tailwind
‚îú‚îÄ‚îÄ index.html              # Point d'entr√©e HTML
‚îú‚îÄ‚îÄ Dockerfile              # Build + Nginx
‚îú‚îÄ‚îÄ Caddyfile               # Alternative Caddy (auto-SSL)
‚îú‚îÄ‚îÄ .env.example            # Variables d'environnement
‚îú‚îÄ‚îÄ docker-compose.yml      # Stack principale
‚îú‚îÄ‚îÄ docker-compose.full.yml # Stack avec tous les services
${includeBackend ? `‚îú‚îÄ‚îÄ backend/                # API Express (depuis Edge Functions)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/         # Routes converties
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware/     # Auth middleware
‚îÇ   ‚îú‚îÄ‚îÄ _original-edge-functions/  # Code original pour r√©f√©rence
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
` : ''}${includeDatabase ? `‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ migrations/         # Sch√©ma SQL
‚îÇ   ‚îî‚îÄ‚îÄ FULL_DATABASE_EXPORT.sql  # Export complet
` : ''}‚îú‚îÄ‚îÄ services/               # üÜï Services Open Source optionnels
‚îÇ   ‚îú‚îÄ‚îÄ ollama/             # IA locale (remplace OpenAI)
‚îÇ   ‚îú‚îÄ‚îÄ meilisearch/        # Recherche (remplace Algolia)
‚îÇ   ‚îî‚îÄ‚îÄ minio/              # Stockage (remplace S3)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ quick-deploy.sh     # Script de d√©ploiement automatique
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îú‚îÄ‚îÄ reports/                # Rapports d'audit
‚îú‚îÄ‚îÄ tests/                  # Tests g√©n√©r√©s
‚îú‚îÄ‚îÄ DEPLOY_GUIDE.html       # Guide interactif
‚îú‚îÄ‚îÄ OPEN_SOURCE_SERVICES.md # Guide des alternatives
‚îú‚îÄ‚îÄ SOVEREIGNTY_REPORT.md   # Rapport de nettoyage
‚îî‚îÄ‚îÄ README.md
\`\`\`

---

## üîß Commandes Utiles

\`\`\`bash
docker compose up -d        # D√©marrer
docker compose down         # Arr√™ter
docker compose logs -f      # Logs temps r√©el
docker compose restart      # Red√©marrer
docker compose ps           # Statut
\`\`\`

---

## ü§ñ IA Open Source

Ce pack inclut un client IA configurable supportant:
- **Ollama** (local, gratuit)
- **OpenRouter** (cloud, √©conomique)
- **OpenAI** (si n√©cessaire)

Voir \`OPEN_SOURCE_SERVICES.md\` pour les d√©tails.

---

## üõ°Ô∏è Souverainet√©

Ce code est **100% lib√©r√©** des d√©pendances propri√©taires:
- ‚úÖ Aucune t√©l√©m√©trie
- ‚úÖ Aucun tracking
- ‚úÖ Aucune d√©pendance cloud obligatoire
- ‚úÖ Backend auto-h√©bergeable
- ‚úÖ Alternatives IA open source incluses

---

*G√©n√©r√© par **InoPay** - [inopay.fr](https://inopay.fr)*
*Lib√©rez votre code, reprenez le contr√¥le!*
`;
    zip.file('README.md', readme);

    // .gitignore
    zip.file('.gitignore', `# Dependencies
node_modules/
.pnp
.pnp.js

# Build
dist/
build/
.next/

# Environment
.env
.env.local
.env.*.local

# Logs
*.log
npm-debug.log*

# OS
.DS_Store
Thumbs.db

# IDE
.idea/
.vscode/
*.swp
*.swo

# Docker
.docker/

# Secrets
*.pem
*.key
`);

    // ==========================================
    // 6. GENERATE ZIP
    // ==========================================
    const zipBuffer = await zip.generateAsync({ 
      type: 'uint8array',
      compression: 'DEFLATE',
      compressionOptions: { level: 9 }
    });

    // PHASE 10: Cryptographic ZIP Signature
    const zipSignature = await generateZipSignature(zipBuffer);
    console.log(`[generate-liberation-pack] NCS V2.0 - ZIP signed: ${zipSignature.slice(0, 16)}...`);
    
    // Add checksum file to a new zip with the signature
    const finalZip = new JSZip();
    await finalZip.loadAsync(zipBuffer);
    finalZip.file('CHECKSUM.sha256', generateChecksumFile(zipSignature, Object.keys(doubleCleanedFiles)));
    
    const finalZipBuffer = await finalZip.generateAsync({ 
      type: 'uint8array',
      compression: 'DEFLATE',
      compressionOptions: { level: 9 }
    });

    // Upload to storage
    const fileName = `${safeName}_liberation_pack_v4_${Date.now()}.zip`;
    const filePath = `${user.id}/${fileName}`;


    const { error: uploadError } = await supabaseAdmin.storage
      .from('cleaned-archives')
      .upload(filePath, finalZipBuffer, {
        contentType: 'application/zip',
        upsert: true
      });

    if (uploadError) {
      console.error('[generate-liberation-pack] Upload error:', uploadError);
      throw new Error(`Erreur upload: ${uploadError.message}`);
    }

    const { data: urlData } = await supabaseAdmin.storage
      .from('cleaned-archives')
      .createSignedUrl(filePath, 3600 * 24 * 7);

    console.log(`[generate-liberation-pack] Pack v4 generated successfully: ${fileName}`);

    return new Response(JSON.stringify({
      success: true,
      downloadUrl: urlData?.signedUrl,
      fileName,
      filePath,
      summary: {
        frontendFiles: Object.keys(doubleCleanedFiles).filter(p => !p.startsWith('supabase/')).length,
        backendRoutes: backendRoutes.length,
        envVars: envVarsArray.length,
        hasDatabase: includeDatabase,
        hasBackend: includeBackend && detectedEdgeFunctions?.length > 0,
        hasAIServices: hasAIUsage,
        sovereigntyScore: sovereigntyCheck.score,
        isClean: sovereigntyCheck.isClean,
        criticalIssues: sovereigntyCheck.criticalIssues.length,
        warnings: sovereigntyCheck.warnings.length,
        serverSideChanges: totalServerChanges,
        schemaExtraction: {
          source: extractedSchema.source,
          tablesFound: extractedSchema.tables.length,
          tables: extractedSchema.tables,
          validation: (extractedSchema as any).validation ? {
            isValid: (extractedSchema as any).validation.isValid,
            errors: (extractedSchema as any).validation.errors.length,
            warnings: (extractedSchema as any).validation.warnings.length,
            stats: (extractedSchema as any).validation.stats
          } : null
        },
        // PRODUCTION READY - NEW FIELDS
        productionReady: {
          isReady: productionReadyReport.isProductionReady,
          overallScore: productionReadyReport.overallScore,
          criticalBlockers: productionReadyReport.criticalBlockers,
          warnings: productionReadyReport.warnings.slice(0, 5),
          certifications: productionReadyReport.certifications,
          checklist: {
            build: productionReadyReport.checklist.build.passed,
            runtime: productionReadyReport.checklist.runtime.passed,
            database: productionReadyReport.checklist.database.passed,
            api: productionReadyReport.checklist.api.passed,
            security: productionReadyReport.checklist.security.passed,
            coolify: productionReadyReport.checklist.coolify.passed,
            integrity: productionReadyReport.checklist.integrity.passed,
            documentation: productionReadyReport.checklist.documentation.passed,
          }
        },
        version: '5.0',
        features: [
          'Complete Edge Function conversion',
          'Open Source services templates (Ollama, Meilisearch, MinIO)',
          'Configurable AI client',
          'Enhanced deployment guide with webhooks section',
          'Auto-generated secrets',
          'Docker Compose with healthchecks',
          'Automatic SQL schema extraction from migrations/types',
          'SQL schema validator with dependency analysis',
          'Downloaded assets integration',
          'Coolify-compatible Dockerfile with build args',
          'Centralized polyfills for TypeScript compatibility',
          'Production Ready validation (8 tests)',
          'ZIP integrity verification',
          'Coolify Deployment Compliance (CDC)'
        ],
        assetsIncluded: assetCount,
        polyfillsAdded: polyfillResult.added
      }
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });

  } catch (error) {
    console.error('[generate-liberation-pack] Error:', error);
    return new Response(JSON.stringify({ 
      error: error instanceof Error ? error.message : 'Erreur interne' 
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});
