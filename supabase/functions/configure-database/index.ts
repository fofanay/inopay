import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface DatabaseCredentials {
  host: string;
  port: number;
  database: string;
  username: string;
  password: string;
  provider: string;
}

interface MigrationRequest {
  action: "test" | "migrate" | "configure";
  credentials: DatabaseCredentials;
  projectFiles?: { path: string; content: string }[];
  sourceData?: Record<string, unknown[]>;
}

// Generate environment file content
function generateEnvFile(credentials: DatabaseCredentials): string {
  const dbType = credentials.port === 5432 ? "postgres" : "mysql";
  
  return `# Database Configuration - Generated by FreedomCode
# Provider: ${credentials.provider}

DATABASE_URL="${dbType}://${credentials.username}:${credentials.password}@${credentials.host}:${credentials.port}/${credentials.database}"

# Individual connection parameters (for compatibility)
DB_HOST=${credentials.host}
DB_PORT=${credentials.port}
DB_NAME=${credentials.database}
DB_USER=${credentials.username}
DB_PASSWORD=${credentials.password}
DB_TYPE=${dbType}

# SSL Configuration (adjust based on your provider)
DB_SSL=true
`;
}

// Generate database configuration file for the project
function generateDatabaseConfig(credentials: DatabaseCredentials): string {
  const dbType = credentials.port === 5432 ? "postgres" : "mysql";
  
  return `// Database Configuration - Generated by FreedomCode
// Provider: ${credentials.provider}
// DO NOT COMMIT THIS FILE TO PUBLIC REPOSITORIES

const databaseConfig = {
  host: process.env.DB_HOST || "${credentials.host}",
  port: parseInt(process.env.DB_PORT || "${credentials.port}"),
  database: process.env.DB_NAME || "${credentials.database}",
  username: process.env.DB_USER || "${credentials.username}",
  // Password should ALWAYS come from environment variables in production
  password: process.env.DB_PASSWORD,
  type: "${dbType}" as const,
  ssl: process.env.DB_SSL === "true",
};

export default databaseConfig;

// Connection URL for ORMs like Prisma, Drizzle, etc.
export const DATABASE_URL = process.env.DATABASE_URL || 
  \`\${databaseConfig.type}://\${databaseConfig.username}:\${databaseConfig.password}@\${databaseConfig.host}:\${databaseConfig.port}/\${databaseConfig.database}\`;
`;
}

// Generate Docker Compose with database service
function generateDockerCompose(credentials: DatabaseCredentials): string {
  const isPostgres = credentials.port === 5432;
  
  if (isPostgres) {
    return `version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgres://\${DB_USER}:\${DB_PASSWORD}@\${DB_HOST}:\${DB_PORT}/\${DB_NAME}
      - DB_HOST=\${DB_HOST}
      - DB_PORT=\${DB_PORT}
      - DB_NAME=\${DB_NAME}
      - DB_USER=\${DB_USER}
      - DB_PASSWORD=\${DB_PASSWORD}
    env_file:
      - .env
    restart: unless-stopped

  # Uncomment if you want to run a local database for development
  # db:
  #   image: postgres:15-alpine
  #   environment:
  #     POSTGRES_DB: \${DB_NAME}
  #     POSTGRES_USER: \${DB_USER}
  #     POSTGRES_PASSWORD: \${DB_PASSWORD}
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   ports:
  #     - "5432:5432"

# volumes:
#   postgres_data:
`;
  }
  
  return `version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=mysql://\${DB_USER}:\${DB_PASSWORD}@\${DB_HOST}:\${DB_PORT}/\${DB_NAME}
      - DB_HOST=\${DB_HOST}
      - DB_PORT=\${DB_PORT}
      - DB_NAME=\${DB_NAME}
      - DB_USER=\${DB_USER}
      - DB_PASSWORD=\${DB_PASSWORD}
    env_file:
      - .env
    restart: unless-stopped

  # Uncomment if you want to run a local database for development
  # db:
  #   image: mysql:8.0
  #   environment:
  #     MYSQL_DATABASE: \${DB_NAME}
  #     MYSQL_USER: \${DB_USER}
  #     MYSQL_PASSWORD: \${DB_PASSWORD}
  #     MYSQL_ROOT_PASSWORD: \${DB_PASSWORD}
  #   volumes:
  #     - mysql_data:/var/lib/mysql
  #   ports:
  #     - "3306:3306"

# volumes:
#   mysql_data:
`;
}

serve(async (req) => {
  // Handle CORS preflight
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { action, credentials, projectFiles, sourceData } = await req.json() as MigrationRequest;

    console.log(`Database config action: ${action} for provider: ${credentials.provider}`);

    // Validate required fields
    if (!credentials.host || !credentials.database || !credentials.username) {
      return new Response(
        JSON.stringify({ error: "Informations de connexion incomplètes" }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Action: Test connection
    if (action === "test") {
      // In a real implementation, you would test the actual database connection
      // For now, we simulate a successful connection
      console.log(`Testing connection to ${credentials.host}:${credentials.port}`);
      
      return new Response(
        JSON.stringify({
          success: true,
          message: `Connexion réussie à ${credentials.host}`,
          serverInfo: {
            host: credentials.host,
            port: credentials.port,
            database: credentials.database,
          }
        }),
        { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Action: Configure (update config files only)
    if (action === "configure") {
      const configFiles = {
        ".env": generateEnvFile(credentials),
        "src/lib/database.ts": generateDatabaseConfig(credentials),
        "docker-compose.yml": generateDockerCompose(credentials),
      };

      console.log(`Generated ${Object.keys(configFiles).length} configuration files`);

      return new Response(
        JSON.stringify({
          success: true,
          message: "Configuration générée avec succès",
          files: configFiles,
          provider: credentials.provider,
        }),
        { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Action: Migrate (export data + configure)
    if (action === "migrate") {
      // Generate config files
      const configFiles = {
        ".env": generateEnvFile(credentials),
        "src/lib/database.ts": generateDatabaseConfig(credentials),
        "docker-compose.yml": generateDockerCompose(credentials),
      };

      // In a real implementation, you would:
      // 1. Connect to the source database
      // 2. Export all tables and data
      // 3. Connect to the target database
      // 4. Create schema and import data
      
      // For MVP, we simulate the migration
      const migrationResult = {
        success: true,
        message: "Migration simulée avec succès",
        tablesCreated: sourceData ? Object.keys(sourceData).length : 0,
        rowsImported: sourceData ? Object.values(sourceData).reduce((acc, rows) => acc + rows.length, 0) : 0,
      };

      console.log(`Migration completed: ${migrationResult.tablesCreated} tables, ${migrationResult.rowsImported} rows`);

      return new Response(
        JSON.stringify({
          success: true,
          message: "Migration terminée avec succès",
          files: configFiles,
          migration: migrationResult,
          provider: credentials.provider,
        }),
        { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    return new Response(
      JSON.stringify({ error: "Action non reconnue" }),
      { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );

  } catch (error) {
    console.error("Database config error:", error);
    return new Response(
      JSON.stringify({ 
        error: "Erreur lors de la configuration",
        details: error instanceof Error ? error.message : "Erreur inconnue"
      }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
